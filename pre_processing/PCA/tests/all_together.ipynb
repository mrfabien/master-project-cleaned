{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"storm_dates = pd.read_csv('pre_processing/tracks/storm_dates.csv')\\npath_tracks_1h_EU = 'pre_processing/tracks/ALL_TRACKS/tracks_1h_EU'\\npath_tracks_1h_non_EU = 'pre_processing/tracks/ALL_TRACKS/tracks_1h_non_EU'\\ndataset = 'datasets_1h_EU'\\ndataset_non_EU = 'datasets_1h_non_EU\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import extraction_squares\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import os \n",
    "import sys\n",
    "\n",
    "operating_system = 'mac'\n",
    "\n",
    "if operating_system == 'win':\n",
    "    os.chdir('C:/Users/fabau/OneDrive/Documents/GitHub/master-project-cleaned/')\n",
    "elif operating_system == 'curnagl':\n",
    "    os.chdir('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/')\n",
    "    path = os.getcwd()\n",
    "else:\n",
    "    os.chdir('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/')\n",
    "\n",
    "# Add the path to the custom library\n",
    "custom_library_path = os.path.abspath('util/processing/')\n",
    "sys.path.append(custom_library_path)\n",
    "\n",
    "import extraction_squares, time_series#, pca\n",
    "\n",
    "'''if operating_system == 'curnagl':\n",
    "    name_of_variable= pd.read_csv('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/DATASETS/variable_list_80_mean.csv')\n",
    "    path_data = '/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/DATASETS'\n",
    "else:'''\n",
    "variables= pd.read_csv('data/variable_list_levels.csv')\n",
    "path_data = 'data'\n",
    "path = os.getcwd()\n",
    "\n",
    "'''storm_dates = pd.read_csv('pre_processing/tracks/storm_dates.csv')\n",
    "path_tracks_1h_EU = 'pre_processing/tracks/ALL_TRACKS/tracks_1h_EU'\n",
    "path_tracks_1h_non_EU = 'pre_processing/tracks/ALL_TRACKS/tracks_1h_non_EU'\n",
    "dataset = 'datasets_1h_EU'\n",
    "dataset_non_EU = 'datasets_1h_non_EU'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storm indices for training: [0, 1, 2, 4, 6, 7, 10, 11, 12, 15, 18, 20, 25, 26, 30, 31, 33, 38, 43, 46, 48, 49, 50, 52, 53, 55, 57, 61, 62, 63, 64, 66, 67, 68, 71, 72, 75, 76, 78, 79, 80, 82, 84, 88, 89, 94]\n",
      "Storm indices for test: [5, 28, 37, 44, 47, 65, 85, 86, 92]\n",
      "Storm indices for validation: [32, 42, 45, 59, 60, 70, 77, 81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantaneous_10m_wind_gust is not taken into account, for obvious reasons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sea_surface_temperature is not taken into account\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fabau\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final datasets have been saved as 'final_train.csv', 'final_test.csv', and 'final_validation.csv'\n"
     ]
    }
   ],
   "source": [
    "def get_storms_data(data, storm_index):\n",
    "        return data.loc[data['storm_index'].isin(storm_index)]\n",
    "\n",
    "threshold = 0.98\n",
    "seed_number = 42\n",
    "\n",
    "#def to_pca_components(path, variables, seed_number, threshold=0.98):\n",
    "\n",
    "# Get the storm indices from a non-EU dataset\n",
    "x_storms = pd.read_csv(f'{path}/data/time_series_1h_non_EU/instantaneous_10m_wind_gust/instantaneous_10m_wind_gust_max.csv')\n",
    "index_storm_EU = x_storms['storm_index'].copy()\n",
    "# reduce by 1 to match the index of the storm in the EU dataset\n",
    "index_storm_EU = index_storm_EU - 1\n",
    "\n",
    "# Split the storm indices into training, test and validation based on the storm index\n",
    "storm_index_training, storm_index_test, storm_index_validation = extraction_squares.split_storm_numbers(index_storm_EU, 0.15, seed_number)\n",
    "\n",
    "# order the index of the storms\n",
    "try:\n",
    "    storm_index_training.sort_values()\n",
    "    storm_index_test.sort_values()\n",
    "    storm_index_validation.sort_values()\n",
    "except:\n",
    "    storm_index_training.sort()\n",
    "    storm_index_test.sort()\n",
    "    storm_index_validation.sort()\n",
    "\n",
    "print(\"Storm indices for training:\", storm_index_training)\n",
    "print(\"Storm indices for test:\", storm_index_test)\n",
    "print(\"Storm indices for validation:\", storm_index_validation)\n",
    "\n",
    "# add 1 to the storm index to match the index of the storm in the timeseries dataset\n",
    "storm_index_training = [x+1 for x in storm_index_training]\n",
    "storm_index_test = [x+1 for x in storm_index_test]\n",
    "storm_index_validation = [x+1 for x in storm_index_validation]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Function to reshape variable data into long format\n",
    "def reshape_variable_data(var_data, storm_index, variable_name, stat):\n",
    "    \"\"\"\n",
    "    Reshape variable data into long format and filter for specific storm indices.\n",
    "\n",
    "    Args:\n",
    "        var_data (pd.DataFrame): Raw data.\n",
    "        storm_index (list): List of storm indices to include.\n",
    "        variable_name (str): Name of the variable.\n",
    "        stat (str): Statistic type (mean, max, etc.).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Reshaped DataFrame with 'storm_number', 'step', and the variable.\n",
    "    \"\"\"\n",
    "    # Filter data for specified storm indices\n",
    "    var_data = var_data[var_data['storm_index'].isin(storm_index)]\n",
    "    \n",
    "    # Melt the DataFrame into long format\n",
    "    var_data_long = var_data.melt(\n",
    "        id_vars=['storm_index'],\n",
    "        value_vars=[str(i) for i in range(36)],\n",
    "        var_name='step',\n",
    "        value_name=f\"{variable_name}_{stat}\"\n",
    "    )\n",
    "\n",
    "    # Add a storm_number column\n",
    "    var_data_long['storm_number'] = 'storm_' + var_data_long['storm_index'].astype(str)\n",
    "\n",
    "    # Reorganize columns\n",
    "    var_data_long = var_data_long[['storm_number', 'step', f\"{variable_name}_{stat}\"]]\n",
    "\n",
    "    return var_data_long\n",
    "\n",
    "\n",
    "# Data is stored by statistics\n",
    "stats = ['max', 'min', 'mean', 'std']\n",
    "\n",
    "# Initialize empty DataFrames for the final combined sets\n",
    "final_train = pd.DataFrame()\n",
    "final_test = pd.DataFrame()\n",
    "final_validation = pd.DataFrame()\n",
    "\n",
    "# Load the data\n",
    "for var in variables['variables']:\n",
    "    if var == 'sea_surface_temperature':\n",
    "        print('sea_surface_temperature is not taken into account')\n",
    "        continue\n",
    "\n",
    "    if var == 'instantaneous_10m_wind_gust':\n",
    "        print('instantaneous_10m_wind_gust is not taken into account, for obvious reasons')\n",
    "        continue\n",
    "\n",
    "    # Process each statistic for the current variable\n",
    "    for stat in stats:\n",
    "        var_name = f\"{var}_{stat}\"\n",
    "        var_data = pd.read_csv(f\"{path}/data/time_series_1h_non_EU/{var}/{var}_{stat}.csv\")\n",
    "\n",
    "        # Reshape data for training, test, and validation sets\n",
    "        var_training = reshape_variable_data(var_data, storm_index_training, var, stat)\n",
    "        var_test = reshape_variable_data(var_data, storm_index_test, var, stat)\n",
    "        var_validation = reshape_variable_data(var_data, storm_index_validation, var, stat)\n",
    "\n",
    "        var_training['storm_number'] = var_training['storm_number'].str.replace('storm_', '').astype(int)\n",
    "        var_test['storm_number'] = var_test['storm_number'].str.replace('storm_', '').astype(int)\n",
    "        var_validation['storm_number'] = var_validation['storm_number'].str.replace('storm_', '').astype(int)\n",
    "\n",
    "        # Merge the reshaped data into the final combined sets\n",
    "        if final_train.empty:\n",
    "            final_train = var_training\n",
    "            final_test = var_test\n",
    "            final_validation = var_validation\n",
    "        else:\n",
    "            final_train = final_train.merge(var_training, on=['storm_number', 'step'], how='outer')\n",
    "            final_test = final_test.merge(var_test, on=['storm_number', 'step'], how='outer')\n",
    "            final_validation = final_validation.merge(var_validation, on=['storm_number', 'step'], how='outer')\n",
    "\n",
    "        var_all = pd.concat([var_training, var_test, var_validation]).reset_index(drop=True)\n",
    "\n",
    "        var_training_pre_scaler = var_training.drop(columns=['storm_number', 'step'])\n",
    "        var_test_pre_scaler = var_test.drop(columns=['storm_number', 'step'])\n",
    "        var_validation_pre_scaler = var_validation.drop(columns=['storm_number', 'step'])\n",
    "\n",
    "        var_all_pre_scaler = var_all.drop(columns=['storm_number', 'step'])\n",
    "\n",
    "        # standardize the data by row\n",
    "        #var_training = var_training.T\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(var_training_pre_scaler)\n",
    "        var_training_scaler = scaler.transform(var_training_pre_scaler)\n",
    "\n",
    "        #var_test = var_test.T\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(var_test_pre_scaler)\n",
    "        var_test_scaler = scaler.transform(var_test_pre_scaler)\n",
    "\n",
    "        #var_validation = var_validation.T\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(var_validation_pre_scaler)\n",
    "        var_validation_scaler = scaler.transform(var_validation_pre_scaler)\n",
    "\n",
    "        #var_all = var_all.T\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(var_all_pre_scaler)\n",
    "        var_all_scaler = scaler.transform(var_all_pre_scaler)\n",
    "\n",
    "        # add the storm number and step back to the data\n",
    "        var_all_scaler = pd.DataFrame(var_all_scaler)\n",
    "        var_all_scaler.rename(columns=lambda x: var_name, inplace=True)\n",
    "        var_all_scaler['storm_number'] = var_all['storm_number']\n",
    "        var_all_scaler['step'] = var_all['step']\n",
    "\n",
    "        # add the storm number and step back to the data\n",
    "        var_training_scaler = pd.DataFrame(var_training_scaler)\n",
    "        var_training_scaler.rename(columns=lambda x: var_name, inplace=True)\n",
    "        var_training_scaler['storm_number'] = var_training['storm_number']\n",
    "        var_training_scaler['step'] = var_training['step']\n",
    "        \n",
    "        var_test_scaler = pd.DataFrame(var_test_scaler)\n",
    "        var_test_scaler.rename(columns=lambda x: var_name, inplace=True)\n",
    "        var_test_scaler['storm_number'] = var_test['storm_number']\n",
    "        var_test_scaler['step'] = var_test['step']\n",
    "\n",
    "        var_validation_scaler = pd.DataFrame(var_validation_scaler)\n",
    "        var_validation_scaler.rename(columns=lambda x: var_name, inplace=True)\n",
    "        var_validation_scaler['storm_number'] = var_validation['storm_number']\n",
    "        var_validation_scaler['step'] = var_validation['step']\n",
    "        \n",
    "\n",
    "        # Train the PCA model\n",
    "        pca = PCA()\n",
    "        pca_test = PCA()\n",
    "        pca_validation = PCA()\n",
    "\n",
    "        # fit the PCA per storms\n",
    "        pca.fit(var_training_scaler.T)\n",
    "        explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "        pca_test.fit(var_test_scaler)\n",
    "        explained_variance_test = pca_test.explained_variance_ratio_.cumsum()\n",
    "\n",
    "        pca_validation.fit(var_validation_scaler)\n",
    "        explained_variance_validation = pca_validation.explained_variance_ratio_.cumsum()\n",
    "\n",
    "        pca_all = PCA()\n",
    "        pca_all.fit(var_all_scaler.drop(columns=['storm_number','step']).T)\n",
    "        explained_variance_all = pca_all.explained_variance_ratio_.cumsum()\n",
    "\n",
    "        break\n",
    "        # get the number of components needed to explain x% of the variance\n",
    "        explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "        explained_variance_test = pca_test.explained_variance_ratio_.cumsum()\n",
    "        explained_variance_validation = pca_validation.explained_variance_ratio_.cumsum()\n",
    "\n",
    "        # Find the index of the first value meeting the threshold\n",
    "        first_above_idx = np.argmax(explained_variance >= threshold)\n",
    "        first_above_idx_test = np.argmax(explained_variance_test >= threshold)\n",
    "        first_above_idx_validation = np.argmax(explained_variance_validation >= threshold)\n",
    "\n",
    "        # Filter values\n",
    "        n_components = explained_variance[(explained_variance < threshold) | (np.arange(len(explained_variance)) == first_above_idx)]\n",
    "        n_components = explained_variance[:len(n_components)]\n",
    "\n",
    "        n_components_test = explained_variance_test[(explained_variance_test < threshold) | (np.arange(len(explained_variance_test)) == first_above_idx_test)]\n",
    "        n_components_test = explained_variance_test[:len(n_components_test)]\n",
    "\n",
    "        n_components_validation = explained_variance_validation[(explained_variance_validation < threshold) | (np.arange(len(explained_variance_validation)) == first_above_idx_validation)]\n",
    "        n_components_validation = explained_variance_validation[:len(n_components_validation)]\n",
    "\n",
    "        print('We want to keep', threshold*100,'% of the variance, so we need', n_components.shape[0], 'components')\n",
    "\n",
    "        # Transform the data\n",
    "        scores = pca.transform(var_training_scaler)\n",
    "        scores_threshold = scores[:, :n_components.shape[0]]\n",
    "\n",
    "        scores_test = pca_test.transform(var_test_scaler)\n",
    "        scores_threshold_test = scores_test[:, :n_components_test.shape[0]]\n",
    "\n",
    "        scores_validation = pca_validation.transform(var_validation_scaler)\n",
    "        scores_threshold_validation = scores_validation[:, :n_components_validation.shape[0]]\n",
    "\n",
    "        # what we keep for the input of ML model is the scores_98\n",
    "        scores_threshold = pd.DataFrame(scores_threshold)\n",
    "        scores_threshold.rename(columns=lambda x: 'PCA_'+str(x+1), inplace=True)\n",
    "        scores_threshold.to_csv(f'{path}/data/PCA_scores/training_{var_name}.csv')\n",
    "\n",
    "        scores_threshold_test = pd.DataFrame(scores_threshold_test)\n",
    "        scores_threshold_test.rename(columns=lambda x: 'PCA_'+str(x+1), inplace=True)\n",
    "        scores_threshold_test.to_csv(f'{path}/data/PCA_scores/test_{var_name}.csv')\n",
    "\n",
    "        scores_threshold_validation = pd.DataFrame(scores_threshold_validation)\n",
    "        scores_threshold_validation.rename(columns=lambda x: 'PCA_'+str(x+1), inplace=True)\n",
    "        scores_threshold_validation.to_csv(f'{path}/data/PCA_scores/validation_{var_name}.csv')\n",
    "\n",
    "        print(f'PCA scores for {var_name} have been saved')\n",
    "\n",
    "# Save the final combined datasets\n",
    "final_train.to_csv(r'pre_processing\\time_series_i10fg_before_eu/final_train.csv', index=False)\n",
    "final_test.to_csv(r'pre_processing\\time_series_i10fg_before_eu/final_test.csv', index=False)\n",
    "final_validation.to_csv(r'pre_processing\\time_series_i10fg_before_eu/final_validation.csv', index=False)\n",
    "\n",
    "# merge all the data into one dataset\n",
    "final_all = pd.concat([final_train, final_test, final_validation])\n",
    "final_all.to_csv(r'pre_processing\\time_series_i10fg_before_eu/final_all.csv', index=False)\n",
    "\n",
    "print(\"Final datasets have been saved as 'final_train.csv', 'final_test.csv', and 'final_validation.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 5 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 5 components.\n",
      "To retain 80.0% of the variance, we need 5 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 6 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 5 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "instantaneous_10m_wind_gust is not taken into account, for obvious reasons\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 6 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 6 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 6 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 5 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "sea_surface_temperature is not taken into account\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:559: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 1 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 6 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 5 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 5 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 5 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 2 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 4 components.\n",
      "To retain 80.0% of the variance, we need 3 components.\n"
     ]
    }
   ],
   "source": [
    "# Data is stored by statistics\n",
    "stats = ['max', 'min', 'mean', 'std']\n",
    "\n",
    "# Initialize empty DataFrames for the final combined sets\n",
    "final_train = pd.DataFrame()\n",
    "final_test = pd.DataFrame()\n",
    "final_validation = pd.DataFrame()\n",
    "\n",
    "all_pca = pd.DataFrame()\n",
    "\n",
    "# Load the data\n",
    "for var in variables['variables']:\n",
    "    if var == 'sea_surface_temperature':\n",
    "        print('sea_surface_temperature is not taken into account')\n",
    "        continue\n",
    "\n",
    "    if var == 'instantaneous_10m_wind_gust':\n",
    "        print('instantaneous_10m_wind_gust is not taken into account, for obvious reasons')\n",
    "        continue\n",
    "\n",
    "    # Process each statistic for the current variable\n",
    "    for stat in stats:\n",
    "        var_name = f\"{var}_{stat}\"\n",
    "        var_data = pd.read_csv(f\"{path}/data/time_series_1h_non_EU/{var}/{var}_{stat}.csv\")\n",
    "        test_var_data = var_data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "        # Threshold for variance retention\n",
    "        threshold = 0.8  # 98% variance\n",
    "        seed_number = 42\n",
    "\n",
    "        # Assume var_all_scaler has columns: storm_number, step_1, step_2, ..., step_n\n",
    "\n",
    "        # Step 1: Extract numerical data (exclude storm_number for scaling)\n",
    "        storm_numbers = test_var_data['storm_index']\n",
    "        data_to_scale = test_var_data.drop(columns=['storm_index'])\n",
    "\n",
    "        # TO DISCUSS, standardize by storms per variable or just by variable ?\n",
    "\n",
    "        # Step 2: Scale the entire dataset\n",
    "        scaler = StandardScaler()\n",
    "        #data_flattened = data_to_scale.values.flatten().reshape(-1, 1)\n",
    "        data_scaled_flattened = scaler.fit_transform(data_to_scale)\n",
    "        #data_scaled = data_scaled_flattened.reshape(data_to_scale.shape)\n",
    "        data_scaled = data_scaled_flattened\n",
    "\n",
    "        # Convert scaled data back to DataFrame with storm_number\n",
    "        data_scaled_df = pd.DataFrame(data_scaled)#, columns=data_to_scale.columns)\n",
    "        #data_scaled_df['storm_index'] = storm_numbers.values\n",
    "\n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=threshold, random_state=seed_number)\n",
    "        data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "        # Calculate cumulative explained variance\n",
    "        explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "        # Find the number of components to explain 'threshold' variance\n",
    "        #n_components_idx = np.argmax(explained_variance >= threshold) + 1  # +1 to convert to count\n",
    "        n_components = len(explained_variance)\n",
    "        print(f\"To retain {threshold*100}% of the variance, we need {n_components} components.\")\n",
    "\n",
    "        # Transform the data to the reduced number of components\n",
    "        #data_pca = pca.transform(data_scaled)[:, :n_components_idx]\n",
    "\n",
    "        # Convert back to DataFrame\n",
    "        data_pca_df = pd.DataFrame(data_pca, columns=[f'PCA_{i+1}' for i in range(n_components)])\n",
    "        #data_pca_df = pd.DataFrame(data_pca)\n",
    "\n",
    "        # Add storm_number back for reference if needed\n",
    "        data_pca_df['storm_number'] = storm_numbers.values\n",
    "\n",
    "        # put the storm number in the first column\n",
    "        cols = data_pca_df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        data_pca_df = data_pca_df[cols]\n",
    "\n",
    "        # add the variable name and stat to the data\n",
    "        data_pca_df['variable'] = var_name\n",
    "\n",
    "        # and set it as the second column\n",
    "        cols = data_pca_df.columns.tolist()\n",
    "        cols = cols[:1] + cols[-1:] + cols[1:-1]\n",
    "        data_pca_df = data_pca_df[cols]\n",
    "        \n",
    "        # Append to results\n",
    "        #all_storms_pca.append(storm_pca_df)\n",
    "\n",
    "        # Step 4: Combine results into a single DataFrame\n",
    "        #final_pca_df = pd.concat(all_storms_pca, axis=0)\n",
    "        \n",
    "        data_pca_df.to_csv(f'{path}/data/PCA_scores/{var_name}.csv', index=False)\n",
    "        all_pca = pd.concat([all_pca, data_pca_df], axis=0)\n",
    "\n",
    "        # Save the PCA loadings\n",
    "        loadings = pd.DataFrame(pca.components_, columns=data_to_scale.columns)\n",
    "        loadings.to_csv(f'{path}/data/PCA_loadings/{var_name}_loadings.csv', index=False)\n",
    "\n",
    "# Save the final combined datasets\n",
    "all_pca.to_csv(r'data/PCA_scores/all_pca.csv', index=False)\n",
    "all_pca.to_csv(r'pre_processing/nestedMLR/all_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85397508, 0.95899359, 0.9783166 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.cumsum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
