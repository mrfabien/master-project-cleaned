{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0moAoFIzCFV"
      },
      "source": [
        "# Code to process winter storm information\n",
        "\n",
        "$\\textbf{Introduction}$: The notebook contains code to process the input and output data for the European winter storm severe winds project. Specifically, we introduce a basic nested PC (Principal Components) Regression model with dropouts, and a Variational Encoder-Decoder (VEDs) to predict the quantile function (inversed CDF) of maximum surface wind gusts\n",
        "\n",
        "The quantile function can be calculated from a given Cumulative Distribution Function (CDF) with the following equation:\n",
        "\n",
        "$ Q = log_{10} (1 - CDF) $\n",
        "\n",
        "The quantile function is particularly useful for our project because it accentuates the difference in distribution tail values. This property is useful in our context of predicting probabilities of rare severe winds in winter storms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcmreaBi3Q5x"
      },
      "source": [
        "## Import relevant packages and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa4qlthVI1tr",
        "outputId": "cbc13a30-9a19-40cf-ecac-946c71861d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (4.1.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from optuna) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "! pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AygV5YB0yXjq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import optuna\n",
        "import os\n",
        "import sys\n",
        "\n",
        "operating_system = 'mac'\n",
        "\n",
        "if operating_system == 'win':\n",
        "    os.chdir('C:/Users/fabau/OneDrive/Documents/GitHub/master-project-cleaned/')\n",
        "elif operating_system == 'curnagl':\n",
        "    os.chdir('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/')\n",
        "else:\n",
        "    os.chdir('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/')\n",
        "\n",
        "util_perso = os.path.abspath('util/processing')\n",
        "sys.path.append(util_perso)\n",
        "util_perso = os.path.abspath('util/feature_selection')\n",
        "sys.path.append(util_perso)\n",
        "\n",
        "from extraction_squares import split_storm_numbers\n",
        "from selection_vars import prepare_training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5UqGTOD13nMA"
      },
      "outputs": [],
      "source": [
        "# Read the csv files for training time series (inputs)\n",
        "all_loadings = pd.read_csv('pre_processing/nestedMLR/all_loadings.csv', header=0)\n",
        "\n",
        "cdf = '_cdf_'\n",
        "n_vars = 40\n",
        "selected_var = pd.read_csv(f'pre_processing/feature_selection/selected_vars_loadings/selected_vars_custom{cdf}{n_vars}.csv')['0'].to_list()\n",
        "\n",
        "# Read the csv files for processed quantile function outputs\n",
        "output_quantile = pd.read_csv('pre_processing/nestedMLR/log_cdf_max_combined.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/01/5ryz4pnn581dj9gk6r1nn5qr0000gn/T/ipykernel_18981/3925337382.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  transposed_data_5['storm_number'] = storm_numbers\n"
          ]
        }
      ],
      "source": [
        "# Extract variable names and storm data\n",
        "variables = all_loadings['variable']  # First column\n",
        "storm_data = all_loadings.iloc[:, 1:]  # All columns from the second onward\n",
        "\n",
        "# Transpose storm data and set variable names as columns\n",
        "transposed_data = storm_data.T\n",
        "transposed_data.columns = variables\n",
        "\n",
        "# Optionally reset index to name storms\n",
        "transposed_data.index.name = 'storm_number'\n",
        "transposed_data.reset_index(inplace=True)\n",
        "\n",
        "# extract the storm number\n",
        "storm_numbers = transposed_data['storm_number'].copy().to_numpy().astype(int)\n",
        "\n",
        "updated_columns = []\n",
        "pca_tracker = {}\n",
        "# for 20 variables\n",
        "for var in transposed_data.columns:\n",
        "    if var not in pca_tracker:\n",
        "        pca_tracker[var] = 1\n",
        "    else:\n",
        "        pca_tracker[var] += 1\n",
        "    # Append PCA number to the variable name\n",
        "    updated_columns.append(f\"{var}_PCA_{pca_tracker[var]}\")\n",
        "# Update the column names\n",
        "transposed_data.columns = updated_columns\n",
        "# rename the first column to storm_number\n",
        "transposed_data = transposed_data.rename(columns={'storm_number_PCA_1': 'storm_number'})\n",
        "transposed_data['storm_number'] = transposed_data['storm_number'].astype(int)\n",
        "\n",
        "# Extract variables most correlated with the target and leaving the storm number\n",
        "columns_to_select_5 = [col for col in selected_var if col in transposed_data.columns]\n",
        "transposed_data_5 = transposed_data[columns_to_select_5]\n",
        "\n",
        "# separate the data in training and testing\n",
        "storm_index_training, storm_index_test, storm_index_validation = split_storm_numbers(storm_numbers, 0.12, 42, 'number')\n",
        "\n",
        "# Sort the storm indices\n",
        "storm_index_training.sort()\n",
        "storm_index_test.sort()\n",
        "storm_index_validation.sort()\n",
        "\n",
        "# add the storm number to the transposed data\n",
        "transposed_data_5['storm_number'] = storm_numbers\n",
        "columns_with_storm = transposed_data_5.columns\n",
        "\n",
        "X_train = prepare_training_data(transposed_data_5, storm_index_training, columns_with_storm)\n",
        "X_test = prepare_training_data(transposed_data_5, storm_index_test, columns_with_storm)\n",
        "X_validation = prepare_training_data(transposed_data_5, storm_index_validation, columns_with_storm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qENqnFDQ54tY"
      },
      "source": [
        "## Check data\n",
        "Let's do a prelimiary check to familiarize ourselves with the data first. What informations are stored in the csv files?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3PKgyyw52e2",
        "outputId": "742aa67e-d363-4b45-9ad0-5515f93877a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 894 entries, 0 to 893\n",
            "Data columns (total 64 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   variable  894 non-null    object \n",
            " 1   1         894 non-null    float64\n",
            " 2   2         894 non-null    float64\n",
            " 3   3         894 non-null    float64\n",
            " 4   5         894 non-null    float64\n",
            " 5   6         894 non-null    float64\n",
            " 6   7         894 non-null    float64\n",
            " 7   8         894 non-null    float64\n",
            " 8   11        894 non-null    float64\n",
            " 9   12        894 non-null    float64\n",
            " 10  13        894 non-null    float64\n",
            " 11  16        894 non-null    float64\n",
            " 12  19        894 non-null    float64\n",
            " 13  21        894 non-null    float64\n",
            " 14  26        894 non-null    float64\n",
            " 15  27        894 non-null    float64\n",
            " 16  29        894 non-null    float64\n",
            " 17  31        894 non-null    float64\n",
            " 18  32        894 non-null    float64\n",
            " 19  33        894 non-null    float64\n",
            " 20  34        894 non-null    float64\n",
            " 21  38        894 non-null    float64\n",
            " 22  39        894 non-null    float64\n",
            " 23  43        894 non-null    float64\n",
            " 24  44        894 non-null    float64\n",
            " 25  45        894 non-null    float64\n",
            " 26  46        894 non-null    float64\n",
            " 27  47        894 non-null    float64\n",
            " 28  48        894 non-null    float64\n",
            " 29  49        894 non-null    float64\n",
            " 30  50        894 non-null    float64\n",
            " 31  51        894 non-null    float64\n",
            " 32  53        894 non-null    float64\n",
            " 33  54        894 non-null    float64\n",
            " 34  56        894 non-null    float64\n",
            " 35  58        894 non-null    float64\n",
            " 36  60        894 non-null    float64\n",
            " 37  61        894 non-null    float64\n",
            " 38  62        894 non-null    float64\n",
            " 39  63        894 non-null    float64\n",
            " 40  64        894 non-null    float64\n",
            " 41  65        894 non-null    float64\n",
            " 42  66        894 non-null    float64\n",
            " 43  67        894 non-null    float64\n",
            " 44  68        894 non-null    float64\n",
            " 45  69        894 non-null    float64\n",
            " 46  71        894 non-null    float64\n",
            " 47  72        894 non-null    float64\n",
            " 48  73        894 non-null    float64\n",
            " 49  76        894 non-null    float64\n",
            " 50  77        894 non-null    float64\n",
            " 51  78        894 non-null    float64\n",
            " 52  79        894 non-null    float64\n",
            " 53  80        894 non-null    float64\n",
            " 54  81        894 non-null    float64\n",
            " 55  82        894 non-null    float64\n",
            " 56  83        894 non-null    float64\n",
            " 57  85        894 non-null    float64\n",
            " 58  86        894 non-null    float64\n",
            " 59  87        894 non-null    float64\n",
            " 60  89        894 non-null    float64\n",
            " 61  90        894 non-null    float64\n",
            " 62  93        894 non-null    float64\n",
            " 63  95        894 non-null    float64\n",
            "dtypes: float64(63), object(1)\n",
            "memory usage: 447.1+ KB\n"
          ]
        }
      ],
      "source": [
        "all_loadings.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWlEFGVO6ufF"
      },
      "source": [
        "The input csv files contain entries of different PC loadings associated with a particular physical variable. In this case, we see 3 different loadings associated with maximum 1000 hPa geopotential heights. Each row entry represents the time series shape characteristics for 1 storm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5QwneCW16SEd",
        "outputId": "645126af-512a-456c-e676-d086bdae6eff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storm_number</th>\n",
              "      <th>storm_name</th>\n",
              "      <th>cluster_0</th>\n",
              "      <th>cluster_1</th>\n",
              "      <th>cluster_2</th>\n",
              "      <th>cluster_3</th>\n",
              "      <th>cluster_4</th>\n",
              "      <th>cluster_5</th>\n",
              "      <th>cluster_6</th>\n",
              "      <th>cluster_7</th>\n",
              "      <th>cluster_8</th>\n",
              "      <th>cluster_9</th>\n",
              "      <th>cluster_10</th>\n",
              "      <th>cluster_11</th>\n",
              "      <th>cluster_12</th>\n",
              "      <th>cluster_13</th>\n",
              "      <th>cluster_14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82</td>\n",
              "      <td>C3S_STORM_TRACKS_ERA5</td>\n",
              "      <td>2.242762</td>\n",
              "      <td>1.441315</td>\n",
              "      <td>1.452814</td>\n",
              "      <td>1.705352</td>\n",
              "      <td>1.482131</td>\n",
              "      <td>2.280985</td>\n",
              "      <td>4.591923</td>\n",
              "      <td>1.618292</td>\n",
              "      <td>3.075134</td>\n",
              "      <td>0.556794</td>\n",
              "      <td>1.619725</td>\n",
              "      <td>2.903208</td>\n",
              "      <td>3.807250</td>\n",
              "      <td>0.856282</td>\n",
              "      <td>0.391914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>C3S_STORM_TRACKS_ERA5</td>\n",
              "      <td>2.549915</td>\n",
              "      <td>0.631354</td>\n",
              "      <td>1.490921</td>\n",
              "      <td>3.063364</td>\n",
              "      <td>0.401477</td>\n",
              "      <td>0.314291</td>\n",
              "      <td>3.869775</td>\n",
              "      <td>0.122579</td>\n",
              "      <td>0.081556</td>\n",
              "      <td>0.006147</td>\n",
              "      <td>1.818020</td>\n",
              "      <td>1.396851</td>\n",
              "      <td>1.348957</td>\n",
              "      <td>0.248937</td>\n",
              "      <td>0.762328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>C3S_STORM_TRACKS_ERA5</td>\n",
              "      <td>0.388078</td>\n",
              "      <td>0.111882</td>\n",
              "      <td>2.341128</td>\n",
              "      <td>0.081180</td>\n",
              "      <td>0.461070</td>\n",
              "      <td>0.290018</td>\n",
              "      <td>1.320162</td>\n",
              "      <td>0.097615</td>\n",
              "      <td>0.172890</td>\n",
              "      <td>0.229829</td>\n",
              "      <td>1.615095</td>\n",
              "      <td>2.983414</td>\n",
              "      <td>4.470059</td>\n",
              "      <td>0.174978</td>\n",
              "      <td>0.238000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95</td>\n",
              "      <td>AIDEN</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>0.788324</td>\n",
              "      <td>0.375771</td>\n",
              "      <td>2.405377</td>\n",
              "      <td>0.633807</td>\n",
              "      <td>0.136090</td>\n",
              "      <td>3.773348</td>\n",
              "      <td>0.226815</td>\n",
              "      <td>0.507296</td>\n",
              "      <td>0.007835</td>\n",
              "      <td>0.227672</td>\n",
              "      <td>0.907070</td>\n",
              "      <td>0.734044</td>\n",
              "      <td>0.023960</td>\n",
              "      <td>1.022132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>HERTA</td>\n",
              "      <td>1.176497</td>\n",
              "      <td>2.152701</td>\n",
              "      <td>0.839556</td>\n",
              "      <td>4.972494</td>\n",
              "      <td>0.238821</td>\n",
              "      <td>0.338416</td>\n",
              "      <td>2.370679</td>\n",
              "      <td>0.979826</td>\n",
              "      <td>0.835825</td>\n",
              "      <td>0.509907</td>\n",
              "      <td>0.669523</td>\n",
              "      <td>2.056866</td>\n",
              "      <td>1.313424</td>\n",
              "      <td>1.460252</td>\n",
              "      <td>4.788285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>12</td>\n",
              "      <td>C3S_STORM_TRACKS_ERA5</td>\n",
              "      <td>0.644110</td>\n",
              "      <td>0.095139</td>\n",
              "      <td>3.364392</td>\n",
              "      <td>2.349703</td>\n",
              "      <td>0.614161</td>\n",
              "      <td>0.211642</td>\n",
              "      <td>2.991942</td>\n",
              "      <td>0.103584</td>\n",
              "      <td>0.010931</td>\n",
              "      <td>0.295994</td>\n",
              "      <td>1.274047</td>\n",
              "      <td>1.759591</td>\n",
              "      <td>2.270806</td>\n",
              "      <td>0.463708</td>\n",
              "      <td>1.908599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>73</td>\n",
              "      <td>XAVER</td>\n",
              "      <td>9.164017</td>\n",
              "      <td>1.967819</td>\n",
              "      <td>2.317177</td>\n",
              "      <td>5.309236</td>\n",
              "      <td>2.678723</td>\n",
              "      <td>0.285856</td>\n",
              "      <td>6.795611</td>\n",
              "      <td>0.631347</td>\n",
              "      <td>0.524138</td>\n",
              "      <td>0.308713</td>\n",
              "      <td>1.864410</td>\n",
              "      <td>3.644108</td>\n",
              "      <td>4.920953</td>\n",
              "      <td>0.273122</td>\n",
              "      <td>0.432820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>8</td>\n",
              "      <td>C3S_STORM_TRACKS_ERA5</td>\n",
              "      <td>2.425189</td>\n",
              "      <td>1.976442</td>\n",
              "      <td>0.632020</td>\n",
              "      <td>2.847837</td>\n",
              "      <td>0.553720</td>\n",
              "      <td>0.094339</td>\n",
              "      <td>6.995991</td>\n",
              "      <td>0.857006</td>\n",
              "      <td>0.069633</td>\n",
              "      <td>0.164015</td>\n",
              "      <td>0.917848</td>\n",
              "      <td>1.430968</td>\n",
              "      <td>0.757042</td>\n",
              "      <td>0.510893</td>\n",
              "      <td>1.421436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>83</td>\n",
              "      <td>C3S_STORM_TRACKS_ERA5</td>\n",
              "      <td>2.600947</td>\n",
              "      <td>1.348670</td>\n",
              "      <td>0.844972</td>\n",
              "      <td>4.010580</td>\n",
              "      <td>0.809561</td>\n",
              "      <td>0.128716</td>\n",
              "      <td>4.218259</td>\n",
              "      <td>0.902120</td>\n",
              "      <td>0.365990</td>\n",
              "      <td>0.426293</td>\n",
              "      <td>1.721566</td>\n",
              "      <td>1.772529</td>\n",
              "      <td>1.847808</td>\n",
              "      <td>0.122705</td>\n",
              "      <td>2.275047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>43</td>\n",
              "      <td>C3S_STORM_TRACKS_ERA5</td>\n",
              "      <td>1.058049</td>\n",
              "      <td>1.236552</td>\n",
              "      <td>0.289159</td>\n",
              "      <td>2.254326</td>\n",
              "      <td>0.810320</td>\n",
              "      <td>1.549956</td>\n",
              "      <td>3.443604</td>\n",
              "      <td>1.579309</td>\n",
              "      <td>0.194101</td>\n",
              "      <td>0.072695</td>\n",
              "      <td>0.527556</td>\n",
              "      <td>1.218760</td>\n",
              "      <td>0.658943</td>\n",
              "      <td>1.477242</td>\n",
              "      <td>0.070396</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows Ã— 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    storm_number             storm_name  cluster_0  cluster_1  cluster_2  \\\n",
              "0             82  C3S_STORM_TRACKS_ERA5   2.242762   1.441315   1.452814   \n",
              "1              1  C3S_STORM_TRACKS_ERA5   2.549915   0.631354   1.490921   \n",
              "2             13  C3S_STORM_TRACKS_ERA5   0.388078   0.111882   2.341128   \n",
              "3             95                 AIDEN    0.090794   0.788324   0.375771   \n",
              "4              7                  HERTA   1.176497   2.152701   0.839556   \n",
              "..           ...                    ...        ...        ...        ...   \n",
              "58            12  C3S_STORM_TRACKS_ERA5   0.644110   0.095139   3.364392   \n",
              "59            73                  XAVER   9.164017   1.967819   2.317177   \n",
              "60             8  C3S_STORM_TRACKS_ERA5   2.425189   1.976442   0.632020   \n",
              "61            83  C3S_STORM_TRACKS_ERA5   2.600947   1.348670   0.844972   \n",
              "62            43  C3S_STORM_TRACKS_ERA5   1.058049   1.236552   0.289159   \n",
              "\n",
              "    cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  cluster_8  \\\n",
              "0    1.705352   1.482131   2.280985   4.591923   1.618292   3.075134   \n",
              "1    3.063364   0.401477   0.314291   3.869775   0.122579   0.081556   \n",
              "2    0.081180   0.461070   0.290018   1.320162   0.097615   0.172890   \n",
              "3    2.405377   0.633807   0.136090   3.773348   0.226815   0.507296   \n",
              "4    4.972494   0.238821   0.338416   2.370679   0.979826   0.835825   \n",
              "..        ...        ...        ...        ...        ...        ...   \n",
              "58   2.349703   0.614161   0.211642   2.991942   0.103584   0.010931   \n",
              "59   5.309236   2.678723   0.285856   6.795611   0.631347   0.524138   \n",
              "60   2.847837   0.553720   0.094339   6.995991   0.857006   0.069633   \n",
              "61   4.010580   0.809561   0.128716   4.218259   0.902120   0.365990   \n",
              "62   2.254326   0.810320   1.549956   3.443604   1.579309   0.194101   \n",
              "\n",
              "    cluster_9  cluster_10  cluster_11  cluster_12  cluster_13  cluster_14  \n",
              "0    0.556794    1.619725    2.903208    3.807250    0.856282    0.391914  \n",
              "1    0.006147    1.818020    1.396851    1.348957    0.248937    0.762328  \n",
              "2    0.229829    1.615095    2.983414    4.470059    0.174978    0.238000  \n",
              "3    0.007835    0.227672    0.907070    0.734044    0.023960    1.022132  \n",
              "4    0.509907    0.669523    2.056866    1.313424    1.460252    4.788285  \n",
              "..        ...         ...         ...         ...         ...         ...  \n",
              "58   0.295994    1.274047    1.759591    2.270806    0.463708    1.908599  \n",
              "59   0.308713    1.864410    3.644108    4.920953    0.273122    0.432820  \n",
              "60   0.164015    0.917848    1.430968    0.757042    0.510893    1.421436  \n",
              "61   0.426293    1.721566    1.772529    1.847808    0.122705    2.275047  \n",
              "62   0.072695    0.527556    1.218760    0.658943    1.477242    0.070396  \n",
              "\n",
              "[63 rows x 17 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_quantile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znZ0ZtutCwx2"
      },
      "source": [
        "The output csv files contain entries of quantile functions for 94 storms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2RLDoYRDmkV"
      },
      "source": [
        "## Combine input csvs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''var1 = input_1000_Z_max.to_numpy()[:,1:]\n",
        "var3 = input_800_rh_max.to_numpy()[:,1:]\n",
        "var2 = input_2m_dew_max.to_numpy()[:,1:]'''\n",
        "\n",
        "# Create and Normalize INPUT_TRAIN\n",
        "#INPUT_TRAIN = np.concatenate((var1, var2, var3), axis=1)\n",
        "#scaler = StandardScaler()  # or MinMaxScaler()\n",
        "#INPUT_TRAIN_NORMALIZED = np.asarray(scaler.fit_transform(INPUT_TRAIN), dtype=np.float32)\n",
        "# TO DO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KwHsU5JgC26B"
      },
      "outputs": [],
      "source": [
        "# Convert the filtered DataFrame to a NumPy array (if needed, retain specific columns)\n",
        "INPUT_TRAIN = X_train.to_numpy(dtype=np.float32)\n",
        "scaler = StandardScaler()  # or MinMaxScaler()\n",
        "INPUT_TRAIN_NORMALIZED = np.asarray(scaler.fit_transform(INPUT_TRAIN), dtype=np.float32)\n",
        "\n",
        "# Create ML outputs\n",
        "filtered_output = output_quantile[output_quantile['storm_number'].isin(storm_index_training)]\n",
        "filtered_output = filtered_output.drop(columns=['storm_name', 'storm_number'])\n",
        "\n",
        "# Convert the filtered DataFrame to a NumPy array (if needed, retain specific columns)\n",
        "OUTPUT_TRAIN = filtered_output.to_numpy(dtype=np.float32)\n",
        "\n",
        "filtered_input_np = INPUT_TRAIN.T#.to_numpy(dtype=np.float32)\n",
        "var1 = filtered_input_np[:2, 1:]\n",
        "var2 = filtered_input_np[2:3, 1:]\n",
        "var3 = filtered_input_np[3:4, 1:]\n",
        "brchsize = [0] + [varobj.shape[1] for varobj in [var1,var2,var3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Wpdxj5uOK8YO"
      },
      "outputs": [],
      "source": [
        "brchsize = [0] + [varobj.shape[1] for varobj in [var1,var2,var3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45]\n"
          ]
        }
      ],
      "source": [
        "# Convert DataFrame to numpy array with transpose:\n",
        "#  - Rows in this array correspond to original columns of the DataFrame\n",
        "filtered_input_np = filtered_input.T.to_numpy(dtype=np.float32)\n",
        "\n",
        "# Build a dictionary where keys are the actual column names, \n",
        "# and values are lists of *row indices in the transposed array* \n",
        "# that correspond to that column name.\n",
        "grouped_columns = {}\n",
        "for i, col_name in enumerate(filtered_input.columns):\n",
        "    grouped_columns.setdefault(col_name, []).append(i)\n",
        "\n",
        "# Now compute 'brchsize' for each unique column name:\n",
        "brchsize = [0]  # start with 0 as in your snippet\n",
        "for col_name, row_indices in grouped_columns.items():\n",
        "    # Slice rows in the transposed matrix\n",
        "    # e.g. taking [:, 1:] if you want to drop the first column as in your code\n",
        "    var_data = filtered_input_np[row_indices, 1:]\n",
        "    brchsize.append(var_data.shape[1])\n",
        "\n",
        "print(brchsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMv77celI_oG"
      },
      "source": [
        "## Baseline ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vcCLiVevIX6v"
      },
      "outputs": [],
      "source": [
        "# Convert NumPy arrays to PyTorch tensors\n",
        "x_tensor = torch.tensor(INPUT_TRAIN_NORMALIZED)\n",
        "y_tensor = torch.tensor(OUTPUT_TRAIN)\n",
        "\n",
        "# Create a DataLoader\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sopFvxwQJzH5"
      },
      "outputs": [],
      "source": [
        "class baseline_ts_drop(torch.nn.Module):\n",
        "    def __init__(self,droprate,brchindices,num_vars):\n",
        "        super(baseline_ts_drop, self).__init__()\n",
        "        self.brchindices = brchindices\n",
        "        self.num_vars = num_vars\n",
        "        ############################################################\n",
        "        # Create regression layers dynamically for each input\n",
        "        ############################################################\n",
        "        brchsize = self.brchindices[1:]\n",
        "        self.input_layers = torch.nn.ModuleDict({\n",
        "            f\"input{i+1}\": torch.nn.Linear(int(brchsize[i]), 1) for i in range(self.num_vars)\n",
        "        })\n",
        "        ############################################################\n",
        "        # Create dropout layers\n",
        "        ############################################################\n",
        "        self.dropout_layers = torch.nn.ModuleDict({\n",
        "            f\"dropout{i+1}\": torch.nn.Dropout(droprate) for i in range(self.num_vars)\n",
        "        })\n",
        "        self.dropout_end = torch.nn.Dropout(droprate)\n",
        "        ############################################################\n",
        "        # Final Dense Layer\n",
        "        ############################################################\n",
        "        self.denseout = torch.nn.Linear(self.num_vars,15)\n",
        "\n",
        "    def forward(self,X):\n",
        "        brchindex = list(np.asarray(self.brchindices).cumsum())\n",
        "        ############################################################\n",
        "        # First regression layer\n",
        "        ############################################################\n",
        "        inputs = []\n",
        "        for i in range(self.num_vars):\n",
        "            # Extract the relevant branch input\n",
        "            X_branch = X[:, brchindex[i]:brchindex[i+1]]\n",
        "            # Apply dropout and linear layer\n",
        "            X_branch = self.dropout_layers[f\"dropout{i+1}\"](X_branch)\n",
        "            input_layer = self.input_layers[f\"input{i+1}\"](X_branch)\n",
        "\n",
        "            inputs.append(input_layer)\n",
        "        ############################################################\n",
        "        # Concat\n",
        "        ############################################################\n",
        "        bestPC = torch.cat(inputs,1)\n",
        "        ############################################################\n",
        "        # Prediction layer\n",
        "        ############################################################\n",
        "        bestPC = self.dropout_end(bestPC)\n",
        "        outpred = self.denseout(bestPC)\n",
        "        return outpred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EfF1fgbLBUE"
      },
      "source": [
        "### Hyperparameter tuning with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xOSsz-QWLGRs"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  # Model Parameters\n",
        "  brchindices = brchsize\n",
        "  numvars = len(brchsize[1:])\n",
        "\n",
        "  # Initiatlize model\n",
        "  models,losses = [],[]\n",
        "  droprate = trial.suggest_float(\"droprate\",0.05,0.45)\n",
        "  model = baseline_ts_drop(droprate, brchindices, numvars)\n",
        "  lr = trial.suggest_float(\"lr\",1e-6,1e-3)#,log=True)\n",
        "\n",
        "  # Training parameters\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "  criterion = torch.nn.L1Loss()\n",
        "  n_epochs = trial.suggest_int(\"n_epochs\",500,5000)\n",
        "  #n_epochs = 500\n",
        "\n",
        "  scheduler_baselr = trial.suggest_float(\"base_lr\",1e-8,1e-4)\n",
        "  scheduler_maxlr = trial.suggest_float(\"max_lr\",1e-4,1e-2)\n",
        "  scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=scheduler_baselr, max_lr=scheduler_maxlr, cycle_momentum=False)\n",
        "\n",
        "  train_losses = []\n",
        "  for epoch in range(1,n_epochs+1):\n",
        "    loss = 0\n",
        "    for features, labels in dataloader:\n",
        "      optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
        "      output = model(features)\n",
        "      batch_loss = criterion(output, labels)\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "      loss += batch_loss.item()\n",
        "    scheduler.step()\n",
        "    loss = loss/len(dataloader)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    #val_loss = ts_models.eval_model(model,\n",
        "    #                                val_loader,\n",
        "    #                                criterion,\n",
        "    #                         l2_lambda)\n",
        "    #    val_losses.append(val_loss)\n",
        "    if epoch%100 == 0:\n",
        "      print('Epoch: {}/{}.............'.format(epoch, n_epochs))\n",
        "      print(\"Loss: {:.4f}\".format(loss))\n",
        "    #if val_loss <= min(val_losses):\n",
        "    #    torch.save(model,'best_model'+str(trial.number))\n",
        "    #torch.save(model,'./tmp/bayesian/best_model.8.'+str(trial.number)+'.pt')\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNF8hvRiOOI-",
        "outputId": "f3df2406-dfee-411e-ea61-ef82dede6add"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-12-26 18:59:17,783] A new study created in memory with name: no-name-9e950976-2ac6-485e-ab3d-231483e6d338\n",
            "[W 2024-12-26 18:59:18,328] Trial 0 failed with parameters: {'droprate': 0.3317938717394394, 'lr': 0.000750291841584646, 'n_epochs': 2428, 'base_lr': 8.838029880773306e-05, 'max_lr': 0.0006963222966271213} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (10x5 and 49x1)').\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/var/folders/01/5ryz4pnn581dj9gk6r1nn5qr0000gn/T/ipykernel_18981/3204683608.py\", line 27, in objective\n",
            "    output = model(features)\n",
            "  File \"/Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/var/folders/01/5ryz4pnn581dj9gk6r1nn5qr0000gn/T/ipykernel_18981/2651539214.py\", line 36, in forward\n",
            "    input_layer = self.input_layers[f\"input{i+1}\"](X_branch)\n",
            "  File \"/Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (10x5 and 49x1)\n",
            "[W 2024-12-26 18:59:18,329] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (10x5 and 49x1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(directions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[24], line 27\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m features, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     26\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Clears existing gradients from previous epoch\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m   batch_loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[1;32m     29\u001b[0m   batch_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[23], line 36\u001b[0m, in \u001b[0;36mbaseline_ts_drop.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Apply dropout and linear layer\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     X_branch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_layers[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m](X_branch)\n\u001b[0;32m---> 36\u001b[0m     input_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_branch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mappend(input_layer)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m############################################################\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Concat\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m############################################################\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x5 and 49x1)"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(directions=[\"minimize\"])\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIGUizShPEnV",
        "outputId": "9d6d0e40-0bab-448d-b11f-d9e461a2896f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'droprate': 0.056681679723688316,\n",
              " 'lr': 0.0009680581183772895,\n",
              " 'n_epochs': 4334,\n",
              " 'base_lr': 6.290614167935168e-05,\n",
              " 'max_lr': 0.007615186512161224}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the tuned hyperparameters\n",
        "study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGC88QnUOPT1"
      },
      "source": [
        "### Train model with tuned hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "RFza2tBZWH2V"
      },
      "outputs": [],
      "source": [
        "def training_loop(model, criterion, optimizer, scheduler, train_loader, epoch):\n",
        "  train_losses = []\n",
        "  for epoch in range(epoch):\n",
        "    model.train()\n",
        "    training_loss = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "      # Forward pass\n",
        "      predictions = model(inputs)\n",
        "      loss = criterion(predictions, targets)\n",
        "      # Zero out existing gradients\n",
        "      optimizer.zero_grad()\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      training_loss += loss.item()\n",
        "    # Adjust learning rates after every epoch\n",
        "    scheduler.step()\n",
        "    # Check overall training loss\n",
        "    training_loss = training_loss/len(train_loader)\n",
        "    train_losses.append(training_loss)\n",
        "    # Print training loss\n",
        "    if epoch % 100 == 0:\n",
        "      print(training_loss)\n",
        "  return model, train_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "wBfxpOiWOukh"
      },
      "outputs": [],
      "source": [
        "# Parameter setup\n",
        "droprate = study.best_params['droprate']\n",
        "brchindices = brchsize\n",
        "numvars = len(brchsize[1:])\n",
        "# Initialize model\n",
        "model = baseline_ts_drop(droprate, brchindices, numvars)\n",
        "# Define a loss function and optimizer\n",
        "loss_fn = torch.nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=study.best_params['lr'])\n",
        "# Use cyclical LR scheduler\n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=study.best_params['base_lr'], max_lr=study.best_params['max_lr'], cycle_momentum=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZJL2ExbOylS",
        "outputId": "e5c367cb-41c3-4ea0-a1d7-264ec570db78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.6265590906143188\n",
            "1.470196533203125\n",
            "1.1311089038848876\n",
            "0.8458157896995544\n",
            "0.778405225276947\n",
            "0.7046789765357971\n",
            "0.6653524756431579\n",
            "0.6913981795310974\n",
            "0.7012088179588318\n",
            "0.6256799280643464\n",
            "0.6464447855949402\n",
            "0.6128641366958618\n",
            "0.6636952519416809\n",
            "0.6607899367809296\n",
            "0.6205216646194458\n",
            "0.6555574297904968\n",
            "0.6927797675132752\n",
            "0.6128554582595825\n",
            "0.6833025813102722\n",
            "0.6570084929466248\n",
            "0.6367743134498596\n",
            "0.676402747631073\n",
            "0.6970734059810638\n",
            "0.6297924160957337\n",
            "0.7226609706878662\n",
            "0.6744549930095672\n",
            "0.6131468534469604\n",
            "0.6352802515029907\n",
            "0.6888851881027221\n",
            "0.6288867115974426\n",
            "0.6560128331184387\n",
            "0.6508706927299499\n",
            "0.5963697016239167\n",
            "0.6256826639175415\n",
            "0.6800871133804322\n",
            "0.6747231960296631\n",
            "0.6088108777999878\n",
            "0.6200833320617676\n",
            "0.6646770358085632\n",
            "0.6594496250152588\n",
            "0.6062576532363891\n",
            "0.6276357173919678\n",
            "0.6409727334976196\n",
            "0.6788089394569397\n"
          ]
        }
      ],
      "source": [
        "model, train_loss = training_loop(model,loss_fn,optimizer,scheduler,dataloader,study.best_params['n_epochs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "HhYe1zbVaqEv",
        "outputId": "8c34aa4b-9234-45ec-c56c-3fb295381c6f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_loss)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensor_flow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
