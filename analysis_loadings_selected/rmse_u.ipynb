{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import genextreme\n",
    "import os\n",
    "import sys\n",
    "\n",
    "operating_system = 'mac'\n",
    "\n",
    "if operating_system == 'win':\n",
    "    os.chdir('C:/Users/fabau/OneDrive/Documents/GitHub/master-project-cleaned/')\n",
    "elif operating_system == 'curnagl':\n",
    "    os.chdir('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/')\n",
    "else:\n",
    "    os.chdir('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/')\n",
    "\n",
    "util_perso = os.path.abspath('util/gev')\n",
    "sys.path.append(util_perso)\n",
    "util_perso = os.path.abspath('util/processing')\n",
    "sys.path.append(util_perso)\n",
    "\n",
    "import time_series\n",
    "from data_processing import depickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.3.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.3.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3291882530691065 train\n",
      "1.6871164314924083 valid\n",
      "4.174823860300746 test\n",
      "[0.3291882530691065, 1.6871164314924083, 4.174823860300746]\n",
      "0.8626883312784542 train\n",
      "2.027217922270463 valid\n",
      "3.7032676569426 test\n",
      "[0.8626883312784542, 2.027217922270463, 3.7032676569426]\n",
      "0.6568383885954976 train\n",
      "1.4466826445973477 valid\n",
      "3.984300717135744 test\n",
      "[0.6568383885954976, 1.4466826445973477, 3.984300717135744]\n",
      "1.2434957545494063 train\n",
      "1.114004798504074 valid\n",
      "3.786855439671143 test\n",
      "[1.2434957545494063, 1.114004798504074, 3.786855439671143]\n",
      "0.7475709706741228 train\n",
      "2.0615189437123127 valid\n",
      "3.9706468485022683 test\n",
      "[0.7475709706741228, 2.0615189437123127, 3.9706468485022683]\n",
      "0.9216536835012549 train\n",
      "1.2386099491246823 valid\n",
      "4.039098882148495 test\n",
      "[0.9216536835012549, 1.2386099491246823, 4.039098882148495]\n",
      "0.6134415435195443 train\n",
      "1.221375460166585 valid\n",
      "3.971516779085708 test\n",
      "[0.6134415435195443, 1.221375460166585, 3.971516779085708]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/fabienaugsburger/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nplt.plot(rmses_z_all_averaged, label='Z_gust', marker='o', linestyle='None')\\n#plt.plot(rmses_u_all_averaged, label='U_gust', marker='s', linestyle='None')\\nplt.xticks(range(3), ['train', 'validation', 'test'])\\nplt.xlabel('Dataset')\\nplt.ylabel('RMSE in m/s')\\nplt.grid()\\nplt.legend()\\n#plt.savefig('analysis_loadings_selected/figures/rmse_z_u_gust.png', dpi=300)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = '_final'\n",
    "\n",
    "model_u = depickle(f'analysis_loadings_selected/u_gust{final}/best_linear_max_model.pkl')\n",
    "\n",
    "pcaall = depickle(f'analysis_loadings_selected/PCA_fred{final}/pcaall.pkl')\n",
    "\n",
    "pcsall_train = depickle(f'analysis_loadings_selected/PCA_fred{final}/pcsall_train.pkl')\n",
    "pcsall_test = depickle(f'analysis_loadings_selected/PCA_fred{final}/pcsall_test.pkl')\n",
    "pcsall_valid = depickle(f'analysis_loadings_selected/PCA_fred{final}/pcsall_valid.pkl')\n",
    "\n",
    "# the storm number linked to the index\n",
    "train_number = pd.read_csv('ml_scripts/new_feature_selection/seed_42/X_train_ts_all.csv')['storm_index']\n",
    "valid_number = pd.read_csv('ml_scripts/new_feature_selection/seed_42/X_validation_ts_all.csv')['storm_index']\n",
    "train_valid = pd.concat([train_number, valid_number], axis=0).reset_index(drop=True)\n",
    "\n",
    "test_number = pd.read_csv('ml_scripts/new_feature_selection/seed_42/X_test_ts_all.csv')['storm_index']\n",
    "\n",
    "#rmses_u_all = []\n",
    "rmses_u_all = []\n",
    "for a in range(7):\n",
    "\n",
    "    train_set_vivian =  depickle('analysis_loadings_selected/PCA_fred_final/train_sets.pkl')[0]\n",
    "    pcs0_vivian = pcsall_train[0] #pd.read_csv(f'analysis_loadings_selected/PCA_fred_final/yn/ytrain_split_{a}.pkl')#pcsall_train[a]\n",
    "    pcs0_lothar = pcsall_test[0]\n",
    "\n",
    "    # loadings on the train set, validation set and test set\n",
    "    train_sets = depickle('analysis_loadings_selected/PCA_fred_final/train_sets.pkl')[a]\n",
    "    val_sets = depickle('analysis_loadings_selected/PCA_fred_final/val_sets.pkl')[a]\n",
    "\n",
    "    pcs0_train = pcsall_train[a] #pd.read_csv(f'analysis_loadings_selected/PCA_fred_final/yn/ytrain_split_{a}.pkl')#pcsall_train[a]\n",
    "    pcs0_valid = pcsall_valid[a]# pd.read_csv(f'analysis_loadings_selected/PCA_fred_final/yn/yvalid_split_{a}.pkl')#pcsall_valid[a]\n",
    "    pcs0_test = pcsall_test[a]\n",
    "\n",
    "    output_type = ['max']\n",
    "\n",
    "    for out in output_type:\n",
    "        if out == 'max':\n",
    "            folder = f'u_gust{final}'\n",
    "        else:\n",
    "            folder = f'z_gust{final}'\n",
    "\n",
    "        var_selected = features = pd.DataFrame(depickle(f'analysis_loadings_selected/{folder}/best_linear_{out}_feature.pkl'),\n",
    "                            columns = ['var_name', 'PC'])\n",
    "        var_selected ['var_name_pca'] = var_selected ['var_name']+ '_PC'+ var_selected ['PC'].astype(str)\n",
    "\n",
    "        loading_train = []\n",
    "        loading_valid = []\n",
    "        loading_test = []\n",
    "\n",
    "        loading_vivian = []\n",
    "        loading_lothar = []\n",
    "    \n",
    "        eigenvectors = {}\n",
    "\n",
    "        for var in var_selected['var_name']:\n",
    "\n",
    "            pcn = var_selected[var_selected['var_name']==var]['PC'].values[0]\n",
    "            #print(var)\n",
    "\n",
    "            # combine all loadings for the selected variables in one dataframe with the variable names as index and the storm number as columns\n",
    "            temp_loading_allpcn_train = pcs0_train[var][:]\n",
    "            temp_loading_seppcn_train = temp_loading_allpcn_train[:,pcn]\n",
    "            loading_train.append(temp_loading_seppcn_train)\n",
    "\n",
    "            temp_loading_allpcn_valid = pcs0_valid[var][:]\n",
    "            temp_loading_seppcn_valid = temp_loading_allpcn_valid[:,pcn]\n",
    "            loading_valid.append(temp_loading_seppcn_valid)\n",
    "\n",
    "            temp_loading_allpcn_test = pcs0_test[var][:]\n",
    "            temp_loading_seppcn_test = temp_loading_allpcn_test[:,pcn]\n",
    "            loading_test.append(temp_loading_seppcn_test)\n",
    "\n",
    "            temp_loading_allpcn_vivian = pcs0_vivian[var][:]\n",
    "            temp_loading_seppcn_vivian = temp_loading_allpcn_vivian[:,pcn]\n",
    "            loading_vivian.append(temp_loading_seppcn_vivian)\n",
    "\n",
    "            temp_loading_allpcn_lothar = pcs0_lothar[var][:]\n",
    "            temp_loading_seppcn_lothar = temp_loading_allpcn_lothar[:,pcn]\n",
    "            loading_lothar.append(temp_loading_seppcn_lothar)\n",
    "\n",
    "            # extract the scores from pcaall\n",
    "            scores = {}  # dictionary to store dataframes\n",
    "\n",
    "            #if  var.startswith('10m_'):\n",
    "            #    continue\n",
    "            #if var.startswith('mean_sea_level_pressure_min'):\n",
    "            #    continue\n",
    "            #loadings[var] = pd.read_csv(f'data/PCA/PCA_loadings_1000/{var}.csv')#.drop(columns=['variable'])\n",
    "            eigenvectors[var] = pcaall[var].components_[pcn,:] # or vector\n",
    "            #explained_variance_10 = pcaall[var].explained_variance_[:10] # or value\n",
    "            #loadings[var] = pd.DataFrame(loadings_10, columns=[f'PCA_{i+1}' for i in range(10)])\n",
    "            #scores[var] = pd.read_csv(f'data/PCA/PCA_scores_1000/{var}.csv').drop(columns=['variable'])\n",
    "\n",
    "    loading_train = np.array(loading_train)\n",
    "    loading_train = pd.DataFrame(loading_train, \n",
    "                                index=var_selected['var_name_pca'],\n",
    "                                columns=train_sets)\n",
    "    loading_valid = np.array(loading_valid)\n",
    "    loading_valid = pd.DataFrame(loading_valid, \n",
    "                                index=var_selected['var_name_pca'],\n",
    "                                columns=val_sets)\n",
    "    loading_test = np.array(loading_test)\n",
    "    loading_test = pd.DataFrame(loading_test, \n",
    "                                index=var_selected['var_name_pca'],\n",
    "                                columns=test_number)\n",
    "    loading_test_clean = loading_test.T\n",
    "    loading_test_clean = loading_test_clean[loading_test_clean.iloc[:, 0] != 'storm_index']\n",
    "\n",
    "    loadings_train_valid = pd.concat([loading_train, loading_valid], axis=1)\n",
    "\n",
    "    loadings_train_valid = loadings_train_valid.rename(columns=train_valid)\n",
    "\n",
    "    loadings_all = pd.concat([loadings_train_valid, loading_test], axis=1).T\n",
    "\n",
    "    # storm specific loadings\n",
    "    loading_vivian = np.array(loading_vivian)\n",
    "    loading_vivian = pd.DataFrame(loading_vivian, \n",
    "                                index=var_selected['var_name_pca'],\n",
    "                                columns=train_set_vivian)\n",
    "    \n",
    "    loading_lothar = np.array(loading_lothar)\n",
    "    loading_lothar = pd.DataFrame(loading_lothar,\n",
    "                                index=var_selected['var_name_pca'],\n",
    "                                columns=test_number)\n",
    "\n",
    "    #prediction_z_train = model_u.predict(loading_train.T)\n",
    "    prediction_u_train = model_u.predict(loading_train.T)\n",
    "    #prediction_z_valid = model_z.predict(loading_valid.T)\n",
    "    prediction_u_valid = model_u.predict(loading_valid.T)\n",
    "    #prediction_z_test = model_z.predict(loading_test_clean)\n",
    "    prediction_u_test = model_u.predict(loading_test_clean)\n",
    "\n",
    "    prediction_vivian = model_u.predict(loading_vivian.T)\n",
    "    prediction_lothar = model_u.predict(loading_lothar.T)\n",
    "\n",
    "    #prediction_z_train_valid = model_z.predict(loadings_train_valid.T)\n",
    "    prediction_u_train_valid = model_u.predict(loadings_train_valid.T)\n",
    "    true_winds = pd.read_csv('data/climatology_dm_winter_per_cluster/EVENT_max/max_event_dm_combined.csv', index_col=0)\n",
    "    \n",
    "    #rmses_z = []\n",
    "    rmses_u = []\n",
    "\n",
    "    # for i in range(len(15)):  # Assuming all lists/arrays have the same length\n",
    "    #     prediction_z_train = prediction_z_train[i]  # Access individual elements\n",
    "    #     #prediction_u_train = prediction_u_train[i], prediction_u_valid[i], prediction_u_test[i])  # Access individual elements\n",
    "    #     prediction_z_valid = prediction_z_valid[i]  # Access individual elements\n",
    "    #     #prediction_u_valid = prediction_u_valid[i]  # Access individual elements\n",
    "    #     prediction_z_test = prediction_z_test[i]  # Access individual elements\n",
    "    #     #prediction_u_test = prediction_u_test[i]  # Access individual elements\n",
    "\n",
    "    true_winds_Vivian = true_winds[true_winds['storm_name'] == 'VIVIAN']\n",
    "    true_winds_Lothar = true_winds[true_winds['storm_name'] == 'LOTHAR']\n",
    "    #for n in range(3):\n",
    "    n = 3\n",
    "    n_lothar = 2\n",
    "\n",
    "    #cluster_z = prediction_z[n,:]\n",
    "    cluster_u = prediction_vivian[n,:]\n",
    "    cluster_u_lothar = prediction_lothar[n_lothar,:]\n",
    "\n",
    "    true_winds_mean = np.mean(true_winds.drop(columns='storm_name'), axis=0)\n",
    "\n",
    "    prediction_u_train_mean = np.mean(prediction_u_train, axis=0)\n",
    "    prediction_u_valid_mean = np.mean(prediction_u_valid, axis=0)\n",
    "    prediction_u_test_mean = np.mean(prediction_u_test, axis=0)\n",
    "\n",
    "    #prediction_u_mean = np.mean(prediction_u, axis=0)\n",
    "\n",
    "    cluster_u = pd.DataFrame(cluster_u, columns=['cluster_u'])\n",
    "    cluster_u_lothar = pd.DataFrame(cluster_u_lothar, columns=['cluster_u_lothar'])\n",
    "\n",
    "    '''max_cluster_z = np.max(cluster_z)\n",
    "    min_cluster_z = np.min(cluster_z)\n",
    "\n",
    "    max_cluster_u = np.max(cluster_u)\n",
    "    min_cluster_u = np.min(cluster_u)'''\n",
    "\n",
    "    # cluster_z_3 = cluster_z[3]\n",
    "    # cluster_u_3 = cluster_u[3]\n",
    "\n",
    "    #cluster_u_wind = []\n",
    "\n",
    "    # cluster_z_train_wind_mean = []\n",
    "    # cluster_z_valid_wind_mean = []\n",
    "    # cluster_z_test_wind_mean = []\n",
    "\n",
    "    # for i in range(15):\n",
    "\n",
    "    #     #cluster_z_3 = cluster_z[i]\n",
    "\n",
    "    #     cluster_train_mean_z = prediction_u_train_mean[i]\n",
    "    #     cluster_valid_mean_z = prediction_u_valid_mean[i]\n",
    "    #     cluster_test_mean_z = prediction_u_test_mean[i]\n",
    "\n",
    "\n",
    "    #     # for cluster nÂ°3\n",
    "    #     param = pd.read_csv(f'data/climatology_dm_winter_per_cluster/GEV_parameters/GEV_parameters_cluster_{n+1}.csv', index_col=0)\n",
    "    #     shape_param= param.iloc[0].values\n",
    "    #     loc_param = param.iloc[1].values\n",
    "    #     scale_param = param.iloc[2].values\n",
    "\n",
    "    #     #max_cluster_z_perc = 1-np.exp(-cluster_z_3)\n",
    "    #     cluster_train_mean_z_perc = 1-np.exp(-cluster_train_mean_z)\n",
    "    #     cluster_valid_mean_z_perc = 1-np.exp(-cluster_valid_mean_z)\n",
    "    #     cluster_test_mean_z_perc = 1-np.exp(-cluster_test_mean_z)\n",
    "    #     # Percentile (e.g., 90%)\n",
    "    #     #percentile = max_cluster_z_perc\n",
    "\n",
    "    #     # Calculate wind speed at the given percentile\n",
    "    #     #wind_speed_z = genextreme.ppf(percentile, c=shape_param, loc=loc_param, scale=scale_param)\n",
    "    #     wind_speed_train_z_mean = genextreme.ppf(cluster_train_mean_z_perc, c=shape_param, loc=loc_param, scale=scale_param)\n",
    "    #     wind_speed_valid_z_mean = genextreme.ppf(cluster_valid_mean_z_perc, c=shape_param, loc=loc_param, scale=scale_param)\n",
    "    #     wind_speed_test_z_mean = genextreme.ppf(cluster_test_mean_z_perc, c=shape_param, loc=loc_param, scale=scale_param)\n",
    "\n",
    "    #     #cluster_z_wind.append(wind_speed_z)\n",
    "    #     cluster_z_train_wind_mean.append(wind_speed_train_z_mean)\n",
    "    #     cluster_z_valid_wind_mean.append(wind_speed_valid_z_mean)\n",
    "    #     cluster_z_test_wind_mean.append(wind_speed_test_z_mean)\n",
    "\n",
    "    #cluster_u_wind = pd.DataFrame(cluster_u_wind, columns=['cluster_u_wind'])\n",
    "    cluster_u_train_wind_mean = pd.DataFrame(prediction_u_train_mean, columns=['cluster_u_train_wind_mean'])\n",
    "    cluster_u_valid_wind_mean = pd.DataFrame(prediction_u_valid_mean, columns=['cluster_u_valid_wind_mean'])\n",
    "    cluster_u_test_wind_mean = pd.DataFrame(prediction_u_test_mean, columns=['cluster_u_test_wind_mean'])\n",
    "\n",
    "    true_winds_Vivian = true_winds_Vivian.T[1:].reset_index(drop=True)\n",
    "    true_winds_Vivian = true_winds_Vivian.rename(columns={5: 'true_winds_Vivian'})\n",
    "\n",
    "    true_winds_Lothar = true_winds_Lothar.T[1:].reset_index(drop=True)\n",
    "    true_winds_Lothar = true_winds_Lothar.rename(columns={38: 'true_winds_Lothar'})\n",
    "\n",
    "    true_winds_mean = pd.DataFrame(true_winds_mean, columns=['true_winds_mean']).reset_index(drop=True)\n",
    "    #prediction_u_mean = pd.DataFrame(prediction_u_mean, columns=['prediction_u_mean'])\n",
    "\n",
    "    winds_vivian = pd.concat([true_winds_Vivian, cluster_u], axis=1)\n",
    "    winds_vivian.to_csv('analysis_loadings_selected/figures/winds_vivian_u.csv')\n",
    "\n",
    "    winds_lothar = pd.concat([true_winds_Lothar, cluster_u_lothar], axis=1)\n",
    "    winds_lothar.to_csv('analysis_loadings_selected/figures/winds_lothar_u.csv')\n",
    "\n",
    "    winds_cluster_train_mean = pd.concat([true_winds_mean, cluster_u_train_wind_mean], axis=1) # prediction_u_mean\n",
    "    winds_cluster_valid_mean = pd.concat([true_winds_mean, cluster_u_valid_wind_mean], axis=1) # prediction_u_mean \n",
    "    winds_cluster_test_mean = pd.concat([true_winds_mean, cluster_u_test_wind_mean], axis=1) # prediction_u_mean\n",
    "\n",
    "    winds_error_train_u = winds_cluster_train_mean['true_winds_mean'] - winds_cluster_train_mean['cluster_u_train_wind_mean']\n",
    "    winds_error_valid_u = winds_cluster_valid_mean['true_winds_mean'] - winds_cluster_valid_mean['cluster_u_valid_wind_mean']\n",
    "    winds_error_test_u = winds_cluster_test_mean['true_winds_mean'] - winds_cluster_test_mean['cluster_u_test_wind_mean']\n",
    "\n",
    "    #winds_error_u = winds_cluster_mean['true_winds_mean'] - winds_cluster_mean['prediction_u_mean']\n",
    "\n",
    "    rmse_u_train = np.sqrt(np.mean(winds_error_train_u**2))\n",
    "    rmse_u_valid = np.sqrt(np.mean(winds_error_valid_u**2))\n",
    "    rmse_u_test = np.sqrt(np.mean(winds_error_test_u**2))\n",
    "\n",
    "    #rmse_u = np.sqrt(np.mean(winds_error_u**2))\n",
    "\n",
    "    #print(rmse_z)\n",
    "    #print(rmse_u)\n",
    "\n",
    "    rmses_u.append(rmse_u_train)\n",
    "    print(rmse_u_train, 'train')\n",
    "    rmses_u.append(rmse_u_valid)\n",
    "    print(rmse_u_valid, 'valid')\n",
    "    rmses_u.append(rmse_u_test)\n",
    "    print(rmse_u_test, 'test')\n",
    "\n",
    "    print(rmses_u)\n",
    "\n",
    "    #rmses_u.append(rmse_u)\n",
    "\n",
    "#rmses_u_all.append(rmses_u)\n",
    "    rmses_u_all.append(rmses_u)\n",
    "\n",
    "#winds_vivian = pd.concat([true_winds_Vivian, cluster_z_wind], axis=1) # cluster_u\n",
    "\n",
    "\n",
    "#rmses_z_all_averaged = np.mean(rmses_z_all, axis=0)\n",
    "rmses_u_all_averaged = np.mean(rmses_u_all, axis=0)\n",
    "\n",
    "#pd.DataFrame(rmses_z_all_averaged).to_csv('analysis_loadings_selected/figures/rmse_z_all.csv')\n",
    "pd.DataFrame(rmses_u_all_averaged).to_csv('analysis_loadings_selected/figures/rmse_u_all.csv')\n",
    "'''\n",
    "plt.plot(rmses_z_all_averaged, label='Z_gust', marker='o', linestyle='None')\n",
    "#plt.plot(rmses_u_all_averaged, label='U_gust', marker='s', linestyle='None')\n",
    "plt.xticks(range(3), ['train', 'validation', 'test'])\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('RMSE in m/s')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "#plt.savefig('analysis_loadings_selected/figures/rmse_z_u_gust.png', dpi=300)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
