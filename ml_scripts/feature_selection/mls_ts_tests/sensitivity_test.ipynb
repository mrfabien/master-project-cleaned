{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from math import sqrt\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "operating_system = 'mac'\n",
    "\n",
    "if operating_system == 'win':\n",
    "    os.chdir('C:/Users/fabau/OneDrive/Documents/GitHub/master-project-cleaned/')\n",
    "elif operating_system == 'curnagl':\n",
    "    os.chdir('/work/FAC/FGSE/IDyST/tbeucler/default/fabien/repos/cleaner_version/')\n",
    "else:\n",
    "    os.chdir('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/')\n",
    "\n",
    "# Add the path to the custom library\n",
    "custom_library_path = os.path.abspath('util/processing/')\n",
    "sys.path.append(custom_library_path)\n",
    "custom_library_path = os.path.abspath('util/gev/')\n",
    "sys.path.append(custom_library_path)\n",
    "custom_library_path = os.path.abspath('util/feature_selection/')\n",
    "sys.path.append(custom_library_path)\n",
    "custom_library_path = os.path.abspath('util/ml/')\n",
    "sys.path.append(custom_library_path)\n",
    "\n",
    "import extraction_squares, pre_processing_data, data_processing, selection_vars, sensitivity_test\n",
    "\n",
    "'''if operating_system == 'curnagl':\n",
    "    name_of_variable= pd.read_csv('/work/FAC/FGSE/IDyST/tbeucler/default/fabien/repos/curnagl/DATASETS/variable_list_80_mean.csv')\n",
    "    path_data = '/work/FAC/FGSE/IDyST/tbeucler/default/fabien/repos/curnagl/DATASETS'\n",
    "else:'''\n",
    "name_of_variable_20 = pd.read_csv('ml_scripts/feature_selection/corr_timeseries/corr_inst_max_20.csv')['Unnamed: 0']#('data/variable_list_levels.csv')\n",
    "name_of_variable_30 = pd.read_csv('ml_scripts/feature_selection/corr_timeseries/corr_inst_max_30.csv')['Unnamed: 0']#('data/variable_list_levels.csv')\n",
    "name_of_variable_40 = pd.read_csv('ml_scripts/feature_selection/corr_timeseries/corr_inst_max_40.csv')['Unnamed: 0']#('data/variable_list_levels.csv')\n",
    "\n",
    "path_data = 'data'\n",
    "\n",
    "storm_dates = pd.read_csv('pre_processing/tracks/storm_dates.csv')\n",
    "#path_tracks_1h_non_EU = 'pre_processing/tracks/ALL_TRACKS/tracks_1h_non_EU'\n",
    "#dataset = 'datasets_1h'\n",
    "#dataset_non_EU = 'datasets_1h_non_EU'\n",
    "levels = pd.read_csv('data/levels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/5ryz4pnn581dj9gk6r1nn5qr0000gn/T/ipykernel_32269/1028226845.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transposed_data_20['storm_number'] = storm_numbers\n",
      "/var/folders/01/5ryz4pnn581dj9gk6r1nn5qr0000gn/T/ipykernel_32269/1028226845.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transposed_data_30['storm_number'] = storm_numbers\n",
      "/var/folders/01/5ryz4pnn581dj9gk6r1nn5qr0000gn/T/ipykernel_32269/1028226845.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transposed_data_40['storm_number'] = storm_numbers\n"
     ]
    }
   ],
   "source": [
    "# import the all_loadings data\n",
    "all_loadings = pd.read_csv('ml_scripts/nestedMLR/all_loadings_1000.csv')\n",
    "\n",
    "# Extract variable names and storm data\n",
    "variables = all_loadings['variable']  # First column\n",
    "storm_data = all_loadings.iloc[:, 1:]  # All columns from the second onward\n",
    "\n",
    "# Transpose storm data and set variable names as columns\n",
    "transposed_data = storm_data.T\n",
    "transposed_data.columns = variables\n",
    "\n",
    "# Optionally reset index to name storms\n",
    "transposed_data.index.name = 'storm_number'\n",
    "transposed_data.reset_index(inplace=True)\n",
    "\n",
    "# extract the storm number\n",
    "storm_numbers = transposed_data['storm_number'].copy()\n",
    "\n",
    "# Extract variables most correlated with the target and leaving the storm number\n",
    "columns_to_select_20 = [col for col in name_of_variable_20.tolist() if col in transposed_data.columns]\n",
    "transposed_data_20 = transposed_data[columns_to_select_20]\n",
    "columns_to_select_30 = [col for col in name_of_variable_30.tolist() if col in transposed_data.columns]\n",
    "transposed_data_30 = transposed_data[columns_to_select_30]\n",
    "columns_to_select_40 = [col for col in name_of_variable_40.tolist() if col in transposed_data.columns]\n",
    "transposed_data_40 = transposed_data[columns_to_select_40]\n",
    "\n",
    "# add the storm number to the transposed data\n",
    "transposed_data_20['storm_number'] = storm_numbers\n",
    "transposed_data_30['storm_number'] = storm_numbers\n",
    "transposed_data_40['storm_number'] = storm_numbers\n",
    "\n",
    "'''original_data = transposed_data.copy()\n",
    "original_columns = transposed_data.columns\n",
    "original_data['storm_number'] = original_data['storm_number'].astype(int)'''\n",
    "\n",
    "# Add PCA numbers to each variable to differentiate modes\n",
    "\n",
    "# Count how many times each variable appears in the column names\n",
    "variable_counts_20 = transposed_data_20.columns.value_counts()\n",
    "# Create a mapping with PCA numbers appended to each variable\n",
    "updated_columns_20 = []\n",
    "pca_tracker_20 = {}\n",
    "# for 20 variables\n",
    "for var in transposed_data_20.columns:\n",
    "    if var not in pca_tracker_20:\n",
    "        pca_tracker_20[var] = 1\n",
    "    else:\n",
    "        pca_tracker_20[var] += 1\n",
    "    # Append PCA number to the variable name\n",
    "    updated_columns_20.append(f\"{var}_PCA_{pca_tracker_20[var]}\")\n",
    "# Update the column names\n",
    "transposed_data_20.columns = updated_columns_20\n",
    "# rename the first column to storm_number\n",
    "transposed_data_20 = transposed_data_20.rename(columns={'storm_number_PCA_1': 'storm_number'})\n",
    "transposed_data_20['storm_number'] = transposed_data_20['storm_number'].astype(int)\n",
    "\n",
    "# for 30 variables\n",
    "updated_columns_30 = []\n",
    "pca_tracker_30 = {}\n",
    "for var in transposed_data_30.columns:\n",
    "    if var not in pca_tracker_30:\n",
    "        pca_tracker_30[var] = 1\n",
    "    else:\n",
    "        pca_tracker_30[var] += 1\n",
    "    # Append PCA number to the variable name\n",
    "    updated_columns_30.append(f\"{var}_PCA_{pca_tracker_30[var]}\")\n",
    "# Update the column names\n",
    "transposed_data_30.columns = updated_columns_30\n",
    "# rename the first column to storm_number\n",
    "transposed_data_30 = transposed_data_30.rename(columns={'storm_number_PCA_1': 'storm_number'})\n",
    "transposed_data_30['storm_number'] = transposed_data_30['storm_number'].astype(int)\n",
    "\n",
    "# for 40 variables\n",
    "updated_columns_40 = []\n",
    "pca_tracker_40 = {}\n",
    "for var in transposed_data_40.columns:\n",
    "    if var not in pca_tracker_40:\n",
    "        pca_tracker_40[var] = 1\n",
    "    else:\n",
    "        pca_tracker_40[var] += 1\n",
    "    # Append PCA number to the variable name\n",
    "    updated_columns_40.append(f\"{var}_PCA_{pca_tracker_40[var]}\")\n",
    "# Update the column names\n",
    "transposed_data_40.columns = updated_columns_40\n",
    "# rename the first column to storm_number\n",
    "transposed_data_40 = transposed_data_40.rename(columns={'storm_number_PCA_1': 'storm_number'})\n",
    "transposed_data_40['storm_number'] = transposed_data_40['storm_number'].astype(int)\n",
    "\n",
    "# load the actual y values\n",
    "\n",
    "y_all_cdf = pd.read_csv('data/climatology_dm_winter_per_cluster/GEV_CDF_max/log_cdf_max_combined.csv')\n",
    "y_all_max = pd.read_csv('data/climatology_dm_winter_per_cluster/EVENT_max/max_event_combined.csv')\n",
    "\n",
    "# Extract storm indices\n",
    "storm_indices = transposed_data_20['storm_number'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 26, 27, 31, 32, 34, 39, 43, 45, 46, 49, 50, 51, 53, 54, 56, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Valid: [21, 33, 44, 47, 58, 83]\n",
      "y is already a numpy array\n",
      "Selected features: Index(['mean_surface_latent_heat_flux_std_PCA_2',\n",
      "       'mean_surface_latent_heat_flux_std_PCA_3', 'geopotential_500_max_PCA_1',\n",
      "       'surface_pressure_max_PCA_2', 'geopotential_1000_std_PCA_2'],\n",
      "      dtype='object')\n",
      "Target: cdf, Variables: 20\n",
      "RMSE: 1.6723358439700844, MAE: 1.1508057535607916\n",
      "Selected Features: Index(['mean_surface_latent_heat_flux_std_PCA_2',\n",
      "       'mean_surface_latent_heat_flux_std_PCA_3', 'geopotential_500_max_PCA_1',\n",
      "       'surface_pressure_max_PCA_2', 'geopotential_1000_std_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 68\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     62\u001b[0m param_grid_xgb \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m],\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m40\u001b[39m],\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     66\u001b[0m }\n\u001b[0;32m---> 68\u001b[0m results \u001b[38;5;241m=\u001b[39m sensitivity_test\u001b[38;5;241m.\u001b[39mprocess_xgboost_workflow(\n\u001b[1;32m     69\u001b[0m     X_train_pca\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;241m20\u001b[39m: X_train_pca_20,\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;241m30\u001b[39m: X_train_pca_30,\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;241m40\u001b[39m: X_train_pca_40,\n\u001b[1;32m     73\u001b[0m     },\n\u001b[1;32m     74\u001b[0m     X_validation_pca\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;241m20\u001b[39m: X_validation_pca_20,\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;241m30\u001b[39m: X_validation_pca_30,\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;241m40\u001b[39m: X_validation_pca_40,\n\u001b[1;32m     78\u001b[0m     },\n\u001b[1;32m     79\u001b[0m     y_train\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m: y_train_cdf,\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: y_train_max,\n\u001b[1;32m     82\u001b[0m     },\n\u001b[1;32m     83\u001b[0m     y_validation\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m: y_validation_cdf,\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: y_validation_max,\n\u001b[1;32m     86\u001b[0m     },\n\u001b[1;32m     87\u001b[0m     variable_counts\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m],\n\u001b[1;32m     88\u001b[0m     target_types\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m# 'max' is out of scope for now\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid_xgb\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/master-project-cleaned/util/ml/sensitivity_test.py:45\u001b[0m, in \u001b[0;36mprocess_xgboost_workflow\u001b[0;34m(X_train_pca, X_validation_pca, y_train, y_validation, variable_counts, target_types, param_grid)\u001b[0m\n\u001b[1;32m     42\u001b[0m results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m search\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Feature Selection\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m selected_vars \u001b[38;5;241m=\u001b[39m selection_vars\u001b[38;5;241m.\u001b[39mfeature_selection(\n\u001b[1;32m     46\u001b[0m     X_train_pca[var_count],\n\u001b[1;32m     47\u001b[0m     X_train_np,\n\u001b[1;32m     48\u001b[0m     y_train[target_type],\n\u001b[1;32m     49\u001b[0m     model\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     51\u001b[0m results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m selected_vars\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Log results\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/master-project-cleaned/util/feature_selection/selection_vars.py:85\u001b[0m, in \u001b[0;36mfeature_selection\u001b[0;34m(df_X_all_vars, scaled_X, df_y, model)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my is already a numpy array\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m sfs\u001b[38;5;241m.\u001b[39mfit(scaled_X, df_y)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Get the selected feature indices\u001b[39;00m\n\u001b[1;32m     88\u001b[0m selected_indices \u001b[38;5;241m=\u001b[39m sfs\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:251\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    249\u001b[0m is_auto_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 251\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_best_new_feature_score(\n\u001b[1;32m    252\u001b[0m         cloned_estimator, X, y, cv, current_mask\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:282\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[1;32m    280\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[1;32m    281\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 282\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m cross_val_score(\n\u001b[1;32m    283\u001b[0m         estimator,\n\u001b[1;32m    284\u001b[0m         X_new,\n\u001b[1;32m    285\u001b[0m         y,\n\u001b[1;32m    286\u001b[0m         cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    287\u001b[0m         scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring,\n\u001b[1;32m    288\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    289\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    290\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    732\u001b[0m )\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    432\u001b[0m         clone(estimator),\n\u001b[1;32m    433\u001b[0m         X,\n\u001b[1;32m    434\u001b[0m         y,\n\u001b[1;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    448\u001b[0m )\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seeds = [42, 1996, 45319, 43709]\n",
    "\n",
    "for seed in seeds:\n",
    "    # separate the data in training and testing\n",
    "    storm_index_training, storm_index_test, storm_index_validation = extraction_squares.split_storm_numbers(storm_indices, 0.12, seed, 'number')\n",
    "\n",
    "    # order the index of the storms\n",
    "\n",
    "    storm_index_training.sort()\n",
    "    storm_index_test.sort()\n",
    "    storm_index_validation.sort()\n",
    "\n",
    "    # add +1 to the storm index to match the storm index in the storm_dates dataframe (it's actually storm index for this set, so +1 is needed)\n",
    "    #storm_index_training = [x+1 for x in storm_index_training]\n",
    "    #storm_index_test = [x+1 for x in storm_index_test]\n",
    "    #storm_index_validation = [x+1 for x in storm_index_validation]\n",
    "\n",
    "    print(\"Storm Training:\", storm_index_training)\n",
    "    print(\"Storm Test:\", storm_index_test)\n",
    "    print(\"Storm Valid:\", storm_index_validation) \n",
    "\n",
    "    # remove the variable convective_rain_rate and vertical_velocity\n",
    "    #columns_to_drop = transposed_data.columns[transposed_data.columns.str.startswith(('convective_rain_rate', 'vertical_velocity'))]\n",
    "    #transposed_data = transposed_data.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Update the column names\n",
    "    #updated_columns = transposed_data.columns\n",
    "\n",
    "    X_train_pca_20 = selection_vars.prepare_training_data(transposed_data_20, storm_index_training, updated_columns_20)\n",
    "    X_test_pca_20 = selection_vars.prepare_training_data(transposed_data_20, storm_index_test, updated_columns_20)\n",
    "    X_validation_pca_20 = selection_vars.prepare_training_data(transposed_data_20, storm_index_validation, updated_columns_20)\n",
    "\n",
    "    X_train_pca_30 = selection_vars.prepare_training_data(transposed_data_30, storm_index_training, updated_columns_30)\n",
    "    X_test_pca_30 = selection_vars.prepare_training_data(transposed_data_30, storm_index_test, updated_columns_30)\n",
    "    X_validation_pca_30 = selection_vars.prepare_training_data(transposed_data_30, storm_index_validation, updated_columns_30)\n",
    "\n",
    "    X_train_pca_40 = selection_vars.prepare_training_data(transposed_data_40, storm_index_training, updated_columns_40)\n",
    "    X_test_pca_40 = selection_vars.prepare_training_data(transposed_data_40, storm_index_test, updated_columns_40)\n",
    "    X_validation_pca_40 = selection_vars.prepare_training_data(transposed_data_40, storm_index_validation, updated_columns_40)\n",
    "\n",
    "    # without the PCA in the names :\n",
    "\n",
    "    '''X_train_original = prepare_training_data(original_data, storm_index_training, original_columns)\n",
    "    X_validation_original = prepare_training_data(original_data, storm_index_validation, original_columns)\n",
    "    X_test_original = prepare_training_data(original_data, storm_index_test, original_columns)\n",
    "\n",
    "    X_train_original = X_train_original[columns_to_select]\n",
    "    X_validation_original = X_validation_original[columns_to_select]\n",
    "    X_test_original = X_test_original[columns_to_select]'''\n",
    "\n",
    "    # load the actual y values\n",
    "\n",
    "    y_train_cdf = selection_vars.process_y_data(y_all_cdf, storm_index_training)\n",
    "    y_test_cdf = selection_vars.process_y_data(y_all_cdf, storm_index_test)\n",
    "    y_validation_cdf = selection_vars.process_y_data(y_all_cdf, storm_index_validation)\n",
    "\n",
    "    y_train_max = selection_vars.process_y_data(y_all_max, storm_index_training)\n",
    "    y_test_max = selection_vars.process_y_data(y_all_max, storm_index_test)\n",
    "    y_validation_max = selection_vars.process_y_data(y_all_max, storm_index_validation)\n",
    "\n",
    "        # Example usage\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [50, 100, 200, 500],\n",
    "        'max_depth': [3, 5, 10, 20, 40],\n",
    "        'learning_rate': np.linspace(0.05, 0.2, 4)\n",
    "    }\n",
    "\n",
    "    results = sensitivity_test.process_xgboost_workflow(\n",
    "        X_train_pca={\n",
    "            20: X_train_pca_20,\n",
    "            30: X_train_pca_30,\n",
    "            40: X_train_pca_40,\n",
    "        },\n",
    "        X_validation_pca={\n",
    "            20: X_validation_pca_20,\n",
    "            30: X_validation_pca_30,\n",
    "            40: X_validation_pca_40,\n",
    "        },\n",
    "        y_train={\n",
    "            'cdf': y_train_cdf,\n",
    "            'max': y_train_max,\n",
    "        },\n",
    "        y_validation={\n",
    "            'cdf': y_validation_cdf,\n",
    "            'max': y_validation_max,\n",
    "        },\n",
    "        variable_counts=[20, 30, 40],\n",
    "        target_types=['cdf'], # 'max' is out of scope for now\n",
    "        param_grid=param_grid_xgb\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 2\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 10\n",
      "max_resources_: 50\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 80\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "y is already a numpy array\n",
      "Selected features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_mean_PCA_2',\n",
      "       'geopotential_500_max_PCA_1', 'mean_sea_level_pressure_max_PCA_2',\n",
      "       'convective_precipitation_mean_PCA_1'],\n",
      "      dtype='object')\n",
      "Target: cdf, Variables: 20\n",
      "RMSE: 2.013381796243133, MAE: 1.3409397456685754\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_mean_PCA_2',\n",
      "       'geopotential_500_max_PCA_1', 'mean_sea_level_pressure_max_PCA_2',\n",
      "       'convective_precipitation_mean_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "n_iterations: 2\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 10\n",
      "max_resources_: 50\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 80\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "y is already a numpy array\n",
      "Selected features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_mean_PCA_2',\n",
      "       'mean_sea_level_pressure_max_PCA_2',\n",
      "       'convective_precipitation_mean_PCA_1', 'surface_pressure_min_PCA_2'],\n",
      "      dtype='object')\n",
      "Target: cdf, Variables: 30\n",
      "RMSE: 1.6907028504017425, MAE: 1.104081940301722\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_mean_PCA_2',\n",
      "       'mean_sea_level_pressure_max_PCA_2',\n",
      "       'convective_precipitation_mean_PCA_1', 'surface_pressure_min_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "n_iterations: 2\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 10\n",
      "max_resources_: 50\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 80\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "y is already a numpy array\n",
      "Selected features: Index(['mean_sea_level_pressure_min_PCA_1',\n",
      "       'surface_latent_heat_flux_min_PCA_3', 'surface_pressure_std_PCA_4',\n",
      "       'large_scale_snowfall_max_PCA_1', 'large_scale_snowfall_max_PCA_3'],\n",
      "      dtype='object')\n",
      "Target: cdf, Variables: 40\n",
      "RMSE: 1.6658822646928704, MAE: 1.147089796745763\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1',\n",
      "       'surface_latent_heat_flux_min_PCA_3', 'surface_pressure_std_PCA_4',\n",
      "       'large_scale_snowfall_max_PCA_1', 'large_scale_snowfall_max_PCA_3'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "n_iterations: 2\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 10\n",
      "max_resources_: 50\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 80\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "y is already a numpy array\n",
      "Selected features: Index(['10m_u_component_of_wind_std_PCA_2',\n",
      "       'mean_sea_level_pressure_mean_PCA_1', 'surface_pressure_mean_PCA_1',\n",
      "       'convective_precipitation_mean_PCA_1',\n",
      "       'convective_precipitation_mean_PCA_2'],\n",
      "      dtype='object')\n",
      "Target: max, Variables: 20\n",
      "RMSE: 7.296714260105329, MAE: 5.584415413861757\n",
      "Selected Features: Index(['10m_u_component_of_wind_std_PCA_2',\n",
      "       'mean_sea_level_pressure_mean_PCA_1', 'surface_pressure_mean_PCA_1',\n",
      "       'convective_precipitation_mean_PCA_1',\n",
      "       'convective_precipitation_mean_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "n_iterations: 2\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 10\n",
      "max_resources_: 50\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 80\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "y is already a numpy array\n",
      "Selected features: Index(['mean_sea_level_pressure_mean_PCA_1',\n",
      "       '10m_v_component_of_wind_max_PCA_2',\n",
      "       'convective_precipitation_mean_PCA_2', '2m_temperature_std_PCA_2',\n",
      "       '10m_v_component_of_wind_min_PCA_1'],\n",
      "      dtype='object')\n",
      "Target: max, Variables: 30\n",
      "RMSE: 6.759196097478498, MAE: 5.2129290071809775\n",
      "Selected Features: Index(['mean_sea_level_pressure_mean_PCA_1',\n",
      "       '10m_v_component_of_wind_max_PCA_2',\n",
      "       'convective_precipitation_mean_PCA_2', '2m_temperature_std_PCA_2',\n",
      "       '10m_v_component_of_wind_min_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "n_iterations: 2\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 10\n",
      "max_resources_: 50\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 80\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "y is already a numpy array\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m param_grid_xgb \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m40\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m sensitivity_test\u001b[38;5;241m.\u001b[39mprocess_xgboost_workflow(\n\u001b[1;32m      9\u001b[0m     X_train_pca\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;241m20\u001b[39m: X_train_pca_20,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;241m30\u001b[39m: X_train_pca_30,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;241m40\u001b[39m: X_train_pca_40,\n\u001b[1;32m     13\u001b[0m     },\n\u001b[1;32m     14\u001b[0m     X_validation_pca\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;241m20\u001b[39m: X_validation_pca_20,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;241m30\u001b[39m: X_validation_pca_30,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;241m40\u001b[39m: X_validation_pca_40,\n\u001b[1;32m     18\u001b[0m     },\n\u001b[1;32m     19\u001b[0m     y_train\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m: y_train_cdf,\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: y_train_max,\n\u001b[1;32m     22\u001b[0m     },\n\u001b[1;32m     23\u001b[0m     y_validation\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m: y_validation_cdf,\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: y_validation_max,\n\u001b[1;32m     26\u001b[0m     },\n\u001b[1;32m     27\u001b[0m     variable_counts\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m],\n\u001b[1;32m     28\u001b[0m     target_types\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     29\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid_xgb\n\u001b[1;32m     30\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/master-project-cleaned/util/ml/sensitivity_test.py:45\u001b[0m, in \u001b[0;36mprocess_xgboost_workflow\u001b[0;34m(X_train_pca, X_validation_pca, y_train, y_validation, variable_counts, target_types, param_grid)\u001b[0m\n\u001b[1;32m     42\u001b[0m results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m search\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Feature Selection\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m selected_vars \u001b[38;5;241m=\u001b[39m selection_vars\u001b[38;5;241m.\u001b[39mfeature_selection(\n\u001b[1;32m     46\u001b[0m     X_train_pca[var_count],\n\u001b[1;32m     47\u001b[0m     X_train_np,\n\u001b[1;32m     48\u001b[0m     y_train[target_type],\n\u001b[1;32m     49\u001b[0m     model\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     51\u001b[0m results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m selected_vars\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Log results\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/master-project-cleaned/util/feature_selection/selection_vars.py:85\u001b[0m, in \u001b[0;36mfeature_selection\u001b[0;34m(df_X_all_vars, scaled_X, df_y, model)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my is already a numpy array\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m sfs\u001b[38;5;241m.\u001b[39mfit(scaled_X, df_y)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Get the selected feature indices\u001b[39;00m\n\u001b[1;32m     88\u001b[0m selected_indices \u001b[38;5;241m=\u001b[39m sfs\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:251\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    249\u001b[0m is_auto_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 251\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_best_new_feature_score(\n\u001b[1;32m    252\u001b[0m         cloned_estimator, X, y, cv, current_mask\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:282\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[1;32m    280\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[1;32m    281\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 282\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m cross_val_score(\n\u001b[1;32m    283\u001b[0m         estimator,\n\u001b[1;32m    284\u001b[0m         X_new,\n\u001b[1;32m    285\u001b[0m         y,\n\u001b[1;32m    286\u001b[0m         cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    287\u001b[0m         scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring,\n\u001b[1;32m    288\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    289\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    290\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    732\u001b[0m )\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    432\u001b[0m         clone(estimator),\n\u001b[1;32m    433\u001b[0m         X,\n\u001b[1;32m    434\u001b[0m         y,\n\u001b[1;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    448\u001b[0m )\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Default usage\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [3, 5, 10, 20, 40],\n",
    "    'learning_rate': np.linspace(0.05, 0.2, 4)\n",
    "}\n",
    "\n",
    "results = sensitivity_test.process_xgboost_workflow(\n",
    "    X_train_pca={\n",
    "        20: X_train_pca_20,\n",
    "        30: X_train_pca_30,\n",
    "        40: X_train_pca_40,\n",
    "    },\n",
    "    X_validation_pca={\n",
    "        20: X_validation_pca_20,\n",
    "        30: X_validation_pca_30,\n",
    "        40: X_validation_pca_40,\n",
    "    },\n",
    "    y_train={\n",
    "        'cdf': y_train_cdf,\n",
    "        'max': y_train_max,\n",
    "    },\n",
    "    y_validation={\n",
    "        'cdf': y_validation_cdf,\n",
    "        'max': y_validation_max,\n",
    "    },\n",
    "    variable_counts=[20, 30, 40],\n",
    "    target_types=['cdf', 'max'],\n",
    "    param_grid=param_grid_xgb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for seed: 42\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 26, 27, 31, 32, 34, 39, 43, 45, 46, 49, 50, 51, 53, 54, 56, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 33, 44, 47, 58, 83]\n",
      "Data saved for count: 20 and seed: 42\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 26, 27, 31, 32, 34, 39, 43, 45, 46, 49, 50, 51, 53, 54, 56, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 33, 44, 47, 58, 83]\n",
      "Data saved for count: 30 and seed: 42\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 26, 27, 31, 32, 34, 39, 43, 45, 46, 49, 50, 51, 53, 54, 56, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 33, 44, 47, 58, 83]\n",
      "Data saved for count: 40 and seed: 42\n",
      "\n",
      "Processing for seed: 1996\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 5, 7, 8, 11, 12, 13, 16, 19, 21, 26, 27, 31, 32, 33, 34, 39, 43, 45, 46, 47, 49, 50, 51, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 77, 78, 79, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [3, 44, 53, 54, 76, 80]\n",
      "Data saved for count: 20 and seed: 1996\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 5, 7, 8, 11, 12, 13, 16, 19, 21, 26, 27, 31, 32, 33, 34, 39, 43, 45, 46, 47, 49, 50, 51, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 77, 78, 79, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [3, 44, 53, 54, 76, 80]\n",
      "Data saved for count: 30 and seed: 1996\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 5, 7, 8, 11, 12, 13, 16, 19, 21, 26, 27, 31, 32, 33, 34, 39, 43, 45, 46, 47, 49, 50, 51, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 77, 78, 79, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [3, 44, 53, 54, 76, 80]\n",
      "Data saved for count: 40 and seed: 1996\n",
      "\n",
      "Processing for seed: 45319\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 26, 27, 31, 33, 34, 39, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 64, 67, 68, 69, 71, 73, 76, 78, 79, 80, 81, 82, 83, 85, 87, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 32, 65, 72, 77, 89]\n",
      "Data saved for count: 20 and seed: 45319\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 26, 27, 31, 33, 34, 39, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 64, 67, 68, 69, 71, 73, 76, 78, 79, 80, 81, 82, 83, 85, 87, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 32, 65, 72, 77, 89]\n",
      "Data saved for count: 30 and seed: 45319\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 26, 27, 31, 33, 34, 39, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 64, 67, 68, 69, 71, 73, 76, 78, 79, 80, 81, 82, 83, 85, 87, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 32, 65, 72, 77, 89]\n",
      "Data saved for count: 40 and seed: 45319\n",
      "\n",
      "Processing for seed: 43709\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 12, 13, 16, 19, 26, 27, 31, 32, 33, 34, 39, 43, 44, 45, 46, 47, 49, 50, 51, 53, 58, 60, 61, 62, 64, 65, 67, 68, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [11, 21, 54, 56, 63, 69]\n",
      "Data saved for count: 20 and seed: 43709\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 12, 13, 16, 19, 26, 27, 31, 32, 33, 34, 39, 43, 44, 45, 46, 47, 49, 50, 51, 53, 58, 60, 61, 62, 64, 65, 67, 68, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [11, 21, 54, 56, 63, 69]\n",
      "Data saved for count: 30 and seed: 43709\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 12, 13, 16, 19, 26, 27, 31, 32, 33, 34, 39, 43, 44, 45, 46, 47, 49, 50, 51, 53, 58, 60, 61, 62, 64, 65, 67, 68, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [11, 21, 54, 56, 63, 69]\n",
      "Data saved for count: 40 and seed: 43709\n",
      "\n",
      "Processing for seed: 19961106\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 7, 8, 11, 13, 16, 19, 21, 26, 27, 31, 32, 33, 34, 39, 43, 44, 46, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 65, 67, 68, 69, 71, 73, 76, 77, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [5, 12, 45, 64, 72, 78]\n",
      "Data saved for count: 20 and seed: 19961106\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 7, 8, 11, 13, 16, 19, 21, 26, 27, 31, 32, 33, 34, 39, 43, 44, 46, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 65, 67, 68, 69, 71, 73, 76, 77, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [5, 12, 45, 64, 72, 78]\n",
      "Data saved for count: 30 and seed: 19961106\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 7, 8, 11, 13, 16, 19, 21, 26, 27, 31, 32, 33, 34, 39, 43, 44, 46, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 65, 67, 68, 69, 71, 73, 76, 77, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [5, 12, 45, 64, 72, 78]\n",
      "Data saved for count: 40 and seed: 19961106\n",
      "\n",
      "Processing for seed: 28012025\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [2, 3, 5, 7, 8, 11, 12, 13, 16, 21, 26, 27, 31, 32, 33, 34, 39, 43, 45, 46, 47, 49, 51, 54, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [1, 19, 44, 50, 53, 95]\n",
      "Data saved for count: 20 and seed: 28012025\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [2, 3, 5, 7, 8, 11, 12, 13, 16, 21, 26, 27, 31, 32, 33, 34, 39, 43, 45, 46, 47, 49, 51, 54, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [1, 19, 44, 50, 53, 95]\n",
      "Data saved for count: 30 and seed: 28012025\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [2, 3, 5, 7, 8, 11, 12, 13, 16, 21, 26, 27, 31, 32, 33, 34, 39, 43, 45, 46, 47, 49, 51, 54, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [1, 19, 44, 50, 53, 95]\n",
      "Data saved for count: 40 and seed: 28012025\n",
      "\n",
      "Processing for seed: 15012025\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 21, 26, 27, 31, 33, 34, 39, 43, 44, 46, 49, 51, 53, 54, 56, 58, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [32, 45, 47, 50, 62, 77]\n",
      "Data saved for count: 20 and seed: 15012025\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 21, 26, 27, 31, 33, 34, 39, 43, 44, 46, 49, 51, 53, 54, 56, 58, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [32, 45, 47, 50, 62, 77]\n",
      "Data saved for count: 30 and seed: 15012025\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 21, 26, 27, 31, 33, 34, 39, 43, 44, 46, 49, 51, 53, 54, 56, 58, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [32, 45, 47, 50, 62, 77]\n",
      "Data saved for count: 40 and seed: 15012025\n",
      "\n",
      "Processing for seed: 2019\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 27, 31, 32, 33, 34, 39, 44, 45, 46, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 63, 64, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 26, 43, 62, 65, 67]\n",
      "Data saved for count: 20 and seed: 2019\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 27, 31, 32, 33, 34, 39, 44, 45, 46, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 63, 64, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 26, 43, 62, 65, 67]\n",
      "Data saved for count: 30 and seed: 2019\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 27, 31, 32, 33, 34, 39, 44, 45, 46, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 63, 64, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 26, 43, 62, 65, 67]\n",
      "Data saved for count: 40 and seed: 2019\n",
      "\n",
      "Processing for seed: 111194\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 21, 27, 31, 32, 33, 34, 39, 43, 44, 45, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 76, 78, 79, 80, 81, 82, 85, 87, 89, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [26, 46, 69, 77, 83, 90]\n",
      "Data saved for count: 20 and seed: 111194\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 21, 27, 31, 32, 33, 34, 39, 43, 44, 45, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 76, 78, 79, 80, 81, 82, 85, 87, 89, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [26, 46, 69, 77, 83, 90]\n",
      "Data saved for count: 30 and seed: 111194\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 21, 27, 31, 32, 33, 34, 39, 43, 44, 45, 47, 49, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 76, 78, 79, 80, 81, 82, 85, 87, 89, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [26, 46, 69, 77, 83, 90]\n",
      "Data saved for count: 40 and seed: 111194\n",
      "\n",
      "Processing for seed: 19052024\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 5, 7, 8, 11, 12, 13, 16, 19, 21, 26, 27, 32, 33, 34, 39, 43, 44, 45, 46, 47, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 64, 67, 69, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [3, 31, 49, 65, 68, 73]\n",
      "Data saved for count: 20 and seed: 19052024\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 5, 7, 8, 11, 12, 13, 16, 19, 21, 26, 27, 32, 33, 34, 39, 43, 44, 45, 46, 47, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 64, 67, 69, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [3, 31, 49, 65, 68, 73]\n",
      "Data saved for count: 30 and seed: 19052024\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 5, 7, 8, 11, 12, 13, 16, 19, 21, 26, 27, 32, 33, 34, 39, 43, 44, 45, 46, 47, 50, 51, 53, 54, 56, 58, 60, 61, 62, 63, 64, 67, 69, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [3, 31, 49, 65, 68, 73]\n",
      "Data saved for count: 40 and seed: 19052024\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 1996, 45319, 43709, 19961106, 28012025, 15012025, 2019, 111194, 19052024]\n",
    "for seed in seeds:\n",
    "    print(f\"\\nProcessing for seed: {seed}\")\n",
    "\n",
    "    for count in [20, 30, 40]:\n",
    "    \n",
    "        # Split the data\n",
    "        storm_index_training, storm_index_test, storm_index_validation = extraction_squares.split_storm_numbers(\n",
    "            storm_indices, 0.12, seed, 'number'\n",
    "        )\n",
    "        storm_index_training.sort()\n",
    "        storm_index_test.sort()\n",
    "        storm_index_validation.sort()\n",
    "        \n",
    "        print(\"Storm Training:\", storm_index_training)\n",
    "        print(\"Storm Test:\", storm_index_test)\n",
    "        print(\"Storm Validation:\", storm_index_validation)\n",
    "\n",
    "        X_train = selection_vars.prepare_training_data(\n",
    "            locals()[f'transposed_data_{count}'], storm_index_training, locals()[f'updated_columns_{count}'])\n",
    "        X_test = selection_vars.prepare_training_data(\n",
    "            locals()[f'transposed_data_{count}'], storm_index_test, locals()[f'updated_columns_{count}'])\n",
    "        X_validation = selection_vars.prepare_training_data(\n",
    "            locals()[f'transposed_data_{count}'], storm_index_validation, locals()[f'updated_columns_{count}'])\n",
    "        \n",
    "        # Load the actual y values\n",
    "        y_train_cdf = selection_vars.process_y_data(y_all_cdf, storm_index_training)\n",
    "        y_test_cdf = selection_vars.process_y_data(y_all_cdf, storm_index_test)\n",
    "        y_validation_cdf = selection_vars.process_y_data(y_all_cdf, storm_index_validation)\n",
    "\n",
    "        y_train_max = selection_vars.process_y_data(y_all_max, storm_index_training)\n",
    "        y_test_max = selection_vars.process_y_data(y_all_max, storm_index_test)\n",
    "        y_validation_max = selection_vars.process_y_data(y_all_max, storm_index_validation)\n",
    "\n",
    "        # Save the data\n",
    "        X_train.to_csv(f'data/sensitivity_test/X_train_{count}_{seed}.csv', index=False)\n",
    "        X_test.to_csv(f'data/sensitivity_test/X_test_{count}_{seed}.csv', index=False)\n",
    "        X_validation.to_csv(f'data/sensitivity_test/X_validation_{count}_{seed}.csv', index=False)\n",
    "\n",
    "        pd.DataFrame(y_train_cdf).to_csv(f'data/sensitivity_test/y_train_cdf_{seed}.csv', index=False)\n",
    "        pd.DataFrame(y_test_cdf).to_csv(f'data/sensitivity_test/y_test_cdf_{seed}.csv', index=False)\n",
    "        pd.DataFrame(y_validation_cdf).to_csv(f'data/sensitivity_test/y_validation_cdf_{seed}.csv', index=False)\n",
    "\n",
    "        pd.DataFrame(y_train_max).to_csv(f'data/sensitivity_test/y_train_max_{seed}.csv', index=False)\n",
    "        pd.DataFrame(y_test_max).to_csv(f'data/sensitivity_test/y_test_max_{seed}.csv', index=False)\n",
    "        pd.DataFrame(y_validation_max).to_csv(f'data/sensitivity_test/y_validation_max_{seed}.csv', index=False)\n",
    "\n",
    "        print(f\"Data saved for count: {count} and seed: {seed}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def sensitivity_analysis(seeds, split_function, process_workflow, data_dict):\n",
    "    sensitivity_results = defaultdict(list)\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"\\nProcessing for seed: {seed}\")\n",
    "        \n",
    "        # Split the data\n",
    "        storm_index_training, storm_index_test, storm_index_validation = split_function(\n",
    "            data_dict['storm_indices'], 0.12, seed, 'number'\n",
    "        )\n",
    "        storm_index_training.sort()\n",
    "        storm_index_test.sort()\n",
    "        storm_index_validation.sort()\n",
    "        \n",
    "        print(\"Storm Training:\", storm_index_training)\n",
    "        print(\"Storm Test:\", storm_index_test)\n",
    "        print(\"Storm Validation:\", storm_index_validation)\n",
    "        \n",
    "        # Prepare PCA datasets\n",
    "        X_train_pca = {count: selection_vars.prepare_training_data(\n",
    "            data_dict[f'transposed_data_{count}'], storm_index_training, data_dict[f'updated_columns_{count}']\n",
    "        ) for count in [20, 30, 40]}\n",
    "        \n",
    "        X_validation_pca = {count: selection_vars.prepare_training_data(\n",
    "            data_dict[f'transposed_data_{count}'], storm_index_validation, data_dict[f'updated_columns_{count}']\n",
    "        ) for count in [20, 30, 40]}\n",
    "\n",
    "        # Prepare y data\n",
    "        y_train = {\n",
    "            'cdf': data_dict['selection_vars'].process_y_data(data_dict['y_all_cdf'], storm_index_training),\n",
    "            'max': data_dict['selection_vars'].process_y_data(data_dict['y_all_max'], storm_index_training),\n",
    "        }\n",
    "        y_validation = {\n",
    "            'cdf': data_dict['selection_vars'].process_y_data(data_dict['y_all_cdf'], storm_index_validation),\n",
    "            'max': data_dict['selection_vars'].process_y_data(data_dict['y_all_max'], storm_index_validation),\n",
    "        }\n",
    "\n",
    "        # Process the workflow for this seed\n",
    "        results = process_workflow(\n",
    "            X_train_pca=X_train_pca,\n",
    "            X_validation_pca=X_validation_pca,\n",
    "            y_train=y_train,\n",
    "            y_validation=y_validation,\n",
    "            variable_counts=[20, 30, 40],\n",
    "            target_types=['cdf', 'max'],  # or ['cdf', 'max']\n",
    "            param_grid=data_dict['param_grid']\n",
    "        )\n",
    "\n",
    "        # Collect selected features for each variable count and target type\n",
    "        for key, res in results.items():\n",
    "            sensitivity_results[key].append(set(res['selected_features']))\n",
    "\n",
    "    return sensitivity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for seed: 42\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "Storm Training: [1, 2, 3, 5, 7, 8, 11, 12, 13, 16, 19, 26, 27, 31, 32, 34, 39, 43, 45, 46, 49, 50, 51, 53, 54, 56, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 85, 87, 89, 90, 95]\n",
      "Storm Test: [6, 29, 38, 48, 66, 86, 93]\n",
      "Storm Validation: [21, 33, 44, 47, 58, 83]\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 20\n",
      "RMSE Before Tuning: 1.6723358439700844, MAE Before Tuning: 1.1508057535607916\n",
      "RMSE After Tuning: 1.1320325711600632, MAE After Tuning: 0.8733677808698516\n",
      "R2 Before Tuning: -5.938676235281977, R2 After Tuning: -0.9791489956587122\n",
      "Relative Variance on validation set: 0.7341266511692504\n",
      "Relative Variance on training set: 1.2214691375806768\n",
      "Residuals before tuning: [[ 1.75762396e-01 -9.76407129e-01 -3.85941587e-01  3.87975267e-01\n",
      "   1.53126661e+00  8.58302988e-01  4.94792376e-01 -5.99794963e-01\n",
      "  -3.77176906e-03  2.75567629e-02  7.52682370e-02 -1.49154404e+00\n",
      "  -2.12262314e-01 -4.00642304e-02 -1.35830280e+00]\n",
      " [-1.23915047e+00  2.21833323e+00 -1.33590948e+00  1.29234362e+00\n",
      "  -9.01386600e-01 -1.31496934e+00  4.31076581e-01  3.39623476e-01\n",
      "  -5.22746233e-01 -2.13253046e-01 -1.84414942e+00 -1.04165642e+00\n",
      "  -1.84425237e+00  2.86999148e-01  6.17540788e-01]\n",
      " [ 2.00249716e+00  1.87808098e+00  4.76786106e-01  1.24523981e+00\n",
      "   1.19120750e+00 -7.00438441e-01  3.34998022e+00 -3.56211402e-01\n",
      "  -3.84973784e-01 -9.09650187e+00  1.37666412e-01 -2.22550377e-01\n",
      "  -5.17336780e-01 -7.85669526e-01 -1.49695124e+00]\n",
      " [ 3.45888080e+00 -1.59666367e+00  2.26097145e+00  1.51222999e+00\n",
      "   4.38368995e-01  1.03000218e+00  1.91673227e+00 -1.01696325e+00\n",
      "   2.82629993e-01 -3.89451095e-01  1.62300302e+00  5.61085214e-01\n",
      "   1.64390572e+00 -2.71152636e-01 -3.22585692e+00]\n",
      " [ 2.00213966e+00 -1.23034686e+00  1.41609827e+00 -2.84808160e+00\n",
      "   1.18976146e+00  8.64219380e-01 -3.74050709e-01 -7.24929959e-01\n",
      "   9.69497333e-01  4.93397596e-01  1.25800482e+00  3.24816975e+00\n",
      "   3.64532516e+00 -4.09625622e-01 -3.71435454e+00]\n",
      " [ 7.00913791e-01 -9.24240315e-01  1.79241846e-02  3.23666484e-01\n",
      "  -7.01086057e-01 -4.96435993e-01  5.97707252e-01 -5.74455728e-01\n",
      "  -1.65795946e-01 -3.95065534e-01  7.41612424e-01 -9.31183616e-01\n",
      "  -7.67590296e-01 -8.55854077e-01 -1.85859092e+00]], Residuals after tuning: [[ 0.46067784  0.22674243 -1.10837217  0.6395114   0.98976342  0.34977873\n",
      "   0.08205644  0.16314974 -0.34621392 -0.54619668 -0.4137452  -1.19811229\n",
      "  -0.94755892  1.13295184 -1.60633502]\n",
      " [ 0.20259958  1.66098289 -1.03511083  0.57160616 -0.93335496 -1.00990502\n",
      "   0.45623356  0.0995967  -0.81995025  0.22235522 -1.09334583 -0.15108101\n",
      "  -0.93217673 -0.17830186  0.76333649]\n",
      " [ 1.4182926   1.68100525  0.19663873  0.18455799  1.46124432 -0.85694403\n",
      "   3.43018804 -0.02821217 -0.7817057  -2.9979432  -0.08412748  0.01330616\n",
      "  -0.06657344 -0.53706606 -0.90903534]\n",
      " [ 3.50340249 -0.18259461  1.83834722  1.66509087  0.41064628  0.73568922\n",
      "   2.58975263 -0.97219778  0.61411401 -0.7257636   1.06881829  0.08609353\n",
      "   0.539005   -0.78321083 -1.37193205]\n",
      " [ 1.60264894 -1.71040219  1.10922554 -1.36112929  1.6546765   0.68734242\n",
      "  -0.61264047 -0.75093165  0.72530712  0.54185373  0.728964    2.40207538\n",
      "   2.59759376 -0.59240064 -0.80639222]\n",
      " [ 0.60521377 -0.32783254 -0.3695798   1.02300206 -0.59951736 -0.87903767\n",
      "   0.09087489 -0.37528419 -0.47766873 -0.37237995  0.48939352 -0.54986648\n",
      "  -0.34930993 -1.10019819  1.03575531]]\n",
      "Best Params: {'learning_rate': 0.15714285714285717, 'max_depth': 1, 'n_estimators': 10}\n",
      "Selected Features: Index(['mean_surface_latent_heat_flux_std_PCA_3',\n",
      "       'surface_latent_heat_flux_std_PCA_3',\n",
      "       'mean_sea_level_pressure_max_PCA_2', 'surface_pressure_max_PCA_2',\n",
      "       'geopotential_1000_std_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 20\n",
      "RMSE Before Tuning: 1.0987106242721834, MAE Before Tuning: 0.8367391146254601\n",
      "RMSE After Tuning: 1.006226146973622, MAE After Tuning: 0.7658111178780265\n",
      "R2 Before Tuning: -0.5186310842868577, R2 After Tuning: -0.19591707822209647\n",
      "Relative Variance on validation set: 0.7341266511692504\n",
      "Relative Variance on training set: 1.2214691375806768\n",
      "Residuals before tuning: [[ 0.10116747  0.0094351  -0.82844192  0.10616641  0.95525547  0.40751824\n",
      "  -0.2111417   0.45764719  0.01419925 -0.56943652 -0.18952086 -1.13042541\n",
      "  -1.07926553  1.53857911 -1.5352732 ]\n",
      " [ 0.81816496  1.60039495 -1.33309297  0.34034931 -1.00663951 -0.76365046\n",
      "   0.33394952  0.06287565 -0.70355085  0.23156068 -1.22851604 -1.47454926\n",
      "  -2.03727415  0.04341304  0.44735348]\n",
      " [ 0.96299588  1.26122648  0.15131589 -0.1432122   1.3148363  -0.23571792\n",
      "   2.68452568 -0.05633329 -0.29952479 -0.56938142 -0.05073389 -0.167134\n",
      "  -0.1732829  -0.52679921 -0.7441816 ]\n",
      " [ 2.7277124  -0.62084482  2.09526284  1.19752828  0.29737263  1.08380242\n",
      "   2.14370204 -1.17398712  0.71104889 -0.4231751   1.09627889  0.19492155\n",
      "   0.56513716 -0.68691966 -0.98617421]\n",
      " [ 0.82072938 -1.75406135  1.61582277 -2.20431774  1.80330225  0.90567773\n",
      "  -0.44409034 -0.73950311  1.00095271  0.79047394  1.04255018  3.05546266\n",
      "   3.53909151 -0.38558905 -0.80324865]\n",
      " [ 0.21824831 -0.34074922 -0.2198731   0.93033669 -0.53915513 -0.81906883\n",
      "  -0.49040835 -0.28649525 -0.49464881 -0.33857714  0.60405269 -0.43573189\n",
      "  -0.03157449 -0.80680433  0.94204502]], Residuals after tuning: [[ 0.21137493  0.21459577 -0.71370124  0.27018865  0.92443944  0.39666855\n",
      "  -1.16918214  0.39533059  0.00808113 -0.4354653  -0.00575235 -1.22684509\n",
      "  -1.099852    1.59715451 -1.16641177]\n",
      " [ 0.78995839  1.28114168 -1.01092342 -0.05222571 -0.97102112 -0.64411605\n",
      "   0.23306642 -0.02586593 -0.61851211  0.31793375 -1.04928659 -0.79915972\n",
      "  -1.35146704  0.02932737  0.5769925 ]\n",
      " [ 1.24603641  1.4357161   0.11671244  0.01091642  1.42426381 -0.30648506\n",
      "   2.79345881 -0.04524127 -0.3638716  -0.47826914 -0.03445255 -0.36746302\n",
      "  -0.4136251  -0.5280993  -0.80861127]\n",
      " [ 2.9130975  -0.09173904  1.72783785  1.75449037  0.57656217  1.1024292\n",
      "   2.41354766 -0.84415252  0.81438283 -0.49556085  0.98014122 -0.10387471\n",
      "   0.00996591 -0.64877276 -0.76847796]\n",
      " [ 1.34134746 -1.01165812  1.07100558 -1.26142955  2.08966334  0.85429526\n",
      "  -0.48029625 -0.35308667  1.00159256  0.68774677  0.70833876  2.4354826\n",
      "   2.7408363  -0.14067806 -0.84108669]\n",
      " [ 0.36663675 -0.23387338 -0.46294692  1.05489456 -0.41509306 -0.55283624\n",
      "  -0.17417579 -0.11754986 -0.26014575 -0.15729279  0.44999066 -0.55428673\n",
      "  -0.23930986 -0.62795406  1.03317408]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 200}\n",
      "Selected Features: Index(['surface_pressure_mean_PCA_1', 'geopotential_500_mean_PCA_2',\n",
      "       'surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_sea_level_pressure_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 20\n",
      "RMSE Before Tuning: 1.0987106242721834, MAE Before Tuning: 0.8367391146254601\n",
      "RMSE After Tuning: 1.0185590976597831, MAE After Tuning: 0.77199306248441\n",
      "R2 Before Tuning: -0.5186310842868577, R2 After Tuning: -0.22249552530421504\n",
      "Relative Variance on validation set: 0.7341266511692504\n",
      "Relative Variance on training set: 1.2214691375806768\n",
      "Residuals before tuning: [[ 0.10116747  0.0094351  -0.82844192  0.10616641  0.95525547  0.40751824\n",
      "  -0.2111417   0.45764719  0.01419925 -0.56943652 -0.18952086 -1.13042541\n",
      "  -1.07926553  1.53857911 -1.5352732 ]\n",
      " [ 0.81816496  1.60039495 -1.33309297  0.34034931 -1.00663951 -0.76365046\n",
      "   0.33394952  0.06287565 -0.70355085  0.23156068 -1.22851604 -1.47454926\n",
      "  -2.03727415  0.04341304  0.44735348]\n",
      " [ 0.96299588  1.26122648  0.15131589 -0.1432122   1.3148363  -0.23571792\n",
      "   2.68452568 -0.05633329 -0.29952479 -0.56938142 -0.05073389 -0.167134\n",
      "  -0.1732829  -0.52679921 -0.7441816 ]\n",
      " [ 2.7277124  -0.62084482  2.09526284  1.19752828  0.29737263  1.08380242\n",
      "   2.14370204 -1.17398712  0.71104889 -0.4231751   1.09627889  0.19492155\n",
      "   0.56513716 -0.68691966 -0.98617421]\n",
      " [ 0.82072938 -1.75406135  1.61582277 -2.20431774  1.80330225  0.90567773\n",
      "  -0.44409034 -0.73950311  1.00095271  0.79047394  1.04255018  3.05546266\n",
      "   3.53909151 -0.38558905 -0.80324865]\n",
      " [ 0.21824831 -0.34074922 -0.2198731   0.93033669 -0.53915513 -0.81906883\n",
      "  -0.49040835 -0.28649525 -0.49464881 -0.33857714  0.60405269 -0.43573189\n",
      "  -0.03157449 -0.80680433  0.94204502]], Residuals after tuning: [[ 0.2189616   0.20804709 -0.72841694  0.27027564  0.92671851  0.40029751\n",
      "  -1.08593632  0.40486328  0.01444198 -0.45646213 -0.01824516 -1.20683768\n",
      "  -1.09308221  1.59562461 -1.17683654]\n",
      " [ 0.70292646  1.3032537  -1.07270887 -0.00835581 -1.00162095 -0.64716078\n",
      "   0.28087782  0.01494798 -0.63554052  0.36899869 -1.09839201 -0.90478445\n",
      "  -1.47666104  0.05548223  0.68340825]\n",
      " [ 1.26480349  1.44191608  0.11276892  0.01262036  1.42770169 -0.30073743\n",
      "   2.84835634 -0.02722952 -0.36082556 -0.46841702 -0.03275184 -0.34665458\n",
      "  -0.39684762 -0.51744314 -0.80276826]\n",
      " [ 2.91817834 -0.10560773  1.76476969  1.72636048  0.5870702   1.11194169\n",
      "   2.42744477 -0.84130944  0.81729609 -0.49573724  1.01111895 -0.01983071\n",
      "   0.08930626 -0.64323833 -0.7772258 ]\n",
      " [ 1.3551273  -1.01961529  1.10082115 -1.28111653  2.10318445  0.85733865\n",
      "  -0.42998323 -0.35522618  1.00533841  0.68154883  0.7346745   2.51951113\n",
      "   2.83177336 -0.14403274 -0.85237923]\n",
      " [ 0.38994028 -0.26368102 -0.4217572   1.01126784 -0.40535711 -0.56067567\n",
      "  -0.11212771 -0.13511012 -0.26513201 -0.18880648  0.47699155 -0.45080891\n",
      "  -0.12450856 -0.64621558  0.99688027]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 100}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'geopotential_1000_min_PCA_2',\n",
      "       'mean_surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_sea_level_pressure_max_PCA_2', 'surface_pressure_max_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 30\n",
      "RMSE Before Tuning: 1.4572715628731858, MAE Before Tuning: 1.0185885697695138\n",
      "RMSE After Tuning: 1.0881632951394717, MAE After Tuning: 0.8357884904664875\n",
      "R2 Before Tuning: -3.2911958172144327, R2 After Tuning: -0.6018727581065662\n",
      "Relative Variance on validation set: 0.7341266511692504\n",
      "Relative Variance on training set: 1.2214691375806768\n",
      "Residuals before tuning: [[-7.47293729e-01 -9.50812895e-01 -7.29414068e-01  1.23846298e+00\n",
      "   1.57495818e+00  6.73235498e-01  1.43581573e+00 -3.81127694e-01\n",
      "  -1.91367494e-01  4.35651921e-03  8.64467305e-02 -1.08707515e+00\n",
      "  -4.13217824e-01  1.84419975e-01 -3.50039424e-01]\n",
      " [ 1.06211691e+00  1.30751721e+00 -6.63733601e-01  1.47915995e+00\n",
      "  -3.98121636e-01 -1.36631445e+00 -4.98541301e-01 -2.74889146e-01\n",
      "  -1.08780309e+00  3.24039673e-01 -3.43392624e-01 -8.44010759e-01\n",
      "  -1.02082993e+00 -4.34617279e-02 -2.50453759e-01]\n",
      " [ 1.22166892e+00  1.84278120e+00  3.19113521e-01  6.74993831e-01\n",
      "   2.02788225e+00 -6.94295467e-01  3.18186198e+00 -1.12437822e-01\n",
      "  -6.82215948e-01 -6.47832922e+00  3.75848778e-01 -7.43710841e-02\n",
      "  -2.13365490e-01 -7.25174388e-01 -3.48636199e+00]\n",
      " [ 4.21693780e+00 -9.24515298e-02  2.03024301e+00  1.60797841e+00\n",
      "   2.38649447e-01  7.08414614e-01  2.37762590e+00 -3.28340239e-01\n",
      "   5.34707751e-01 -5.21929421e-01  1.48242243e+00  5.74479093e-01\n",
      "   1.63600220e+00 -1.63140555e-01 -2.09708394e+00]\n",
      " [ 1.21362135e+00 -1.67841977e+00  1.79235193e+00 -1.70043136e+00\n",
      "   1.50904483e+00  1.10209720e+00 -4.50264545e-01 -1.09687772e+00\n",
      "   8.86414240e-01  6.84955480e-01  1.34109280e+00  3.71429571e+00\n",
      "   3.82038323e+00 -4.28051444e-01 -1.12773052e+00]\n",
      " [ 2.17174534e-01 -1.71453678e-01  6.11251543e-02  1.02833071e+00\n",
      "  -5.40431631e-01 -4.46315818e-01  1.02217001e-02 -5.47175874e-01\n",
      "  -5.78900481e-01 -2.27520930e-01  1.02771251e+00  2.78981408e-01\n",
      "   8.78294218e-01 -7.65335364e-01  6.14427245e-01]], Residuals after tuning: [[ 0.20979331 -0.08387883 -1.1537629   1.38275175  0.956502    0.38771906\n",
      "  -0.02205595  0.30308177 -0.03099261 -0.41767691 -0.50188139 -1.23521808\n",
      "  -0.54915778  1.17763112 -1.13315377]\n",
      " [ 1.04562479  1.2133979  -1.21519673  1.02655411 -0.85888873 -0.8934677\n",
      "   0.39408594 -0.07742277 -0.74250301  0.33276055 -0.83413477 -0.14751117\n",
      "  -0.97431149 -0.06864701  0.59568221]\n",
      " [ 1.73087629  1.36353804  0.33821383  0.41700752  1.4279829  -0.73008639\n",
      "   3.5482298   0.09684356 -0.71257641 -1.95859269  0.0720113   0.016876\n",
      "   0.08134002 -0.48039003 -0.79308618]\n",
      " [ 3.62128319  0.14191513  1.97992232  1.18254597  0.48314734  0.95123786\n",
      "   2.68632837 -0.81659103  0.56513777 -0.51301471  1.14236231  0.04898774\n",
      "   0.68691846 -0.73166438 -0.72352459]\n",
      " [ 1.72642538 -1.0641858   1.3619074  -1.09117104  2.03188723  0.8671713\n",
      "  -0.52844534 -0.58044866  0.69593067  0.6703735   0.90854863  1.90025195\n",
      "   2.19053123 -0.54317865 -0.82551112]\n",
      " [ 0.57335973  0.14890293 -0.11689795  1.4349772  -0.3280691  -1.14167254\n",
      "   0.02872727 -0.43719267 -0.52664497 -0.14571022  0.66897814 -0.38093142\n",
      "  -0.04118932 -1.23742811  1.01663641]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 5}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_max_PCA_2',\n",
      "       'geopotential_1000_std_PCA_2',\n",
      "       'mean_surface_sensible_heat_flux_std_PCA_2',\n",
      "       'surface_pressure_min_PCA_4'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 30\n",
      "RMSE Before Tuning: 1.0598909783529862, MAE Before Tuning: 0.8129070787262441\n",
      "RMSE After Tuning: 1.0023354465515522, MAE After Tuning: 0.7588146549913976\n",
      "R2 Before Tuning: -0.36192050037470597, R2 After Tuning: -0.18547653236282655\n",
      "Relative Variance on validation set: 0.7341266511692504\n",
      "Relative Variance on training set: 1.2214691375806768\n",
      "Residuals before tuning: [[ 0.41101713  0.22273861 -0.87199524  0.60295396  0.90412775  0.51175112\n",
      "  -0.42597108  0.55260454  0.07738808 -0.53965051 -0.0258619  -1.11970785\n",
      "  -1.03647159  1.69597527 -1.22678622]\n",
      " [ 1.16096976  1.61384262 -1.01165306  0.46259966 -0.85989127 -0.78632668\n",
      "   0.18029537  0.12842719 -0.75515292  0.30980717 -0.95042306 -0.9913752\n",
      "  -1.48454863  0.0823907   0.67189236]\n",
      " [ 0.95962326  1.21657705  0.33664743 -0.1024      1.47137312 -0.29033987\n",
      "   2.47093633 -0.19294397 -0.39656497 -0.33208548  0.08982919 -0.10451674\n",
      "  -0.09650278 -0.52275395 -0.77188593]\n",
      " [ 3.43187088  0.25756199  1.91121188  2.02034802  0.84774843  1.17264554\n",
      "   2.55391705 -0.56355249  0.79847757 -0.37427506  1.32641121  0.3877984\n",
      "   0.48500089 -0.47531655 -0.64807369]\n",
      " [ 1.25855564 -1.27381406  1.29821761 -1.06713996  2.18103704  0.76949432\n",
      "  -0.66727023 -0.65775401  1.03137962  0.7384445   0.85428086  2.5952953\n",
      "   2.99949691 -0.36595432 -0.39170254]\n",
      " [ 0.39179216 -0.11130752 -0.04725905  0.79550446 -0.21390792 -0.90095455\n",
      "  -0.51626792 -0.2138983  -0.38804989 -0.04876041  0.75340246 -0.12484545\n",
      "   0.34947183 -0.84981862  1.02277338]], Residuals after tuning: [[ 3.46790057e-01  2.70861891e-01 -7.48169472e-01  3.77274823e-01\n",
      "   9.57763103e-01  3.97773684e-01 -1.07062681e+00  4.37991368e-01\n",
      "  -1.54195602e-03 -3.98378291e-01 -5.86348322e-03 -1.25121312e+00\n",
      "  -1.13934928e+00  1.62188920e+00 -1.11968631e+00]\n",
      " [ 9.48662879e-01  1.31118155e+00 -9.86147716e-01 -5.64450671e-03\n",
      "  -9.01378937e-01 -6.36249752e-01  3.50194615e-01 -6.58512500e-03\n",
      "  -6.21296225e-01  3.09569229e-01 -1.02863400e+00 -7.19052364e-01\n",
      "  -1.28280966e+00  3.43264592e-02  5.45967515e-01]\n",
      " [ 1.24347262e+00  1.41630116e+00  1.39565677e-01 -3.02790855e-02\n",
      "   1.43532855e+00 -3.05266436e-01  2.83044689e+00 -4.02901903e-02\n",
      "  -3.70973751e-01 -4.77936859e-01 -1.40344786e-02 -3.22569681e-01\n",
      "  -3.72001578e-01 -5.27739563e-01 -8.21394667e-01]\n",
      " [ 3.03505302e+00 -3.16876718e-02  1.74954608e+00  1.84964659e+00\n",
      "   6.46149862e-01  1.11212002e+00  2.56196481e+00 -7.87483010e-01\n",
      "   8.14762329e-01 -4.82753270e-01  1.02543291e+00  6.47624495e-02\n",
      "   1.50677450e-01 -6.22424579e-01 -7.32486266e-01]\n",
      " [ 1.42337468e+00 -9.60448969e-01  1.00807187e+00 -1.15684603e+00\n",
      "   2.08491149e+00  8.38165083e-01 -4.23383221e-01 -3.23938119e-01\n",
      "   1.01286878e+00  6.16352612e-01  6.69210005e-01  2.24873526e+00\n",
      "   2.56791805e+00 -1.49993724e-01 -8.26653343e-01]\n",
      " [ 4.30349128e-01 -2.89266732e-01 -3.37069669e-01  9.71605622e-01\n",
      "  -3.69005827e-01 -5.58680587e-01 -9.09264721e-02 -1.57310096e-01\n",
      "  -2.72942415e-01 -1.44748118e-01  5.50344280e-01 -2.63123542e-01\n",
      "   5.61698256e-02 -6.44910131e-01  9.98570376e-01]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 100}\n",
      "Selected Features: Index(['10m_v_component_of_wind_max_PCA_2',\n",
      "       'surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_sea_level_pressure_max_PCA_2', '2m_temperature_std_PCA_1',\n",
      "       'surface_pressure_min_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 30\n",
      "RMSE Before Tuning: 1.0598909783529864, MAE Before Tuning: 0.8129070787262441\n",
      "RMSE After Tuning: 0.9773709032705318, MAE After Tuning: 0.7413912693228004\n",
      "R2 Before Tuning: -0.36192050037470597, R2 After Tuning: -0.1398713103474277\n",
      "Relative Variance on validation set: 0.7341266511692504\n",
      "Relative Variance on training set: 1.2214691375806768\n",
      "Residuals before tuning: [[ 0.41101713  0.22273861 -0.87199524  0.60295396  0.90412775  0.51175112\n",
      "  -0.42597108  0.55260454  0.07738808 -0.53965051 -0.0258619  -1.11970785\n",
      "  -1.03647159  1.69597527 -1.22678622]\n",
      " [ 1.16096976  1.61384262 -1.01165306  0.46259966 -0.85989127 -0.78632668\n",
      "   0.18029537  0.12842719 -0.75515292  0.30980717 -0.95042306 -0.9913752\n",
      "  -1.48454863  0.0823907   0.67189236]\n",
      " [ 0.95962326  1.21657705  0.33664743 -0.1024      1.47137312 -0.29033987\n",
      "   2.47093633 -0.19294397 -0.39656497 -0.33208548  0.08982919 -0.10451674\n",
      "  -0.09650278 -0.52275395 -0.77188593]\n",
      " [ 3.43187088  0.25756199  1.91121188  2.02034802  0.84774843  1.17264554\n",
      "   2.55391705 -0.56355249  0.79847757 -0.37427506  1.32641121  0.3877984\n",
      "   0.48500089 -0.47531655 -0.64807369]\n",
      " [ 1.25855564 -1.27381406  1.29821761 -1.06713996  2.18103704  0.76949432\n",
      "  -0.66727023 -0.65775401  1.03137962  0.7384445   0.85428086  2.5952953\n",
      "   2.99949691 -0.36595432 -0.39170254]\n",
      " [ 0.39179216 -0.11130752 -0.04725905  0.79550446 -0.21390792 -0.90095455\n",
      "  -0.51626792 -0.2138983  -0.38804989 -0.04876041  0.75340246 -0.12484545\n",
      "   0.34947183 -0.84981862  1.02277338]], Residuals after tuning: [[ 2.79051752e-01  2.52276953e-01 -7.62479793e-01  3.68738385e-01\n",
      "   9.24981004e-01  4.01280601e-01 -1.12843775e+00  4.33610568e-01\n",
      "  -3.72617443e-05 -3.81951549e-01 -2.50614255e-02 -1.30866517e+00\n",
      "  -1.18607287e+00  1.62617940e+00 -1.10173874e+00]\n",
      " [ 9.41351811e-01  1.27798384e+00 -9.20171955e-01 -8.74716235e-02\n",
      "  -8.92838069e-01 -6.22844885e-01  2.27975200e-01 -3.74726121e-02\n",
      "  -6.04660253e-01  2.91263411e-01 -9.76255143e-01 -6.54241930e-01\n",
      "  -1.19993593e+00  1.96032595e-02  4.68421034e-01]\n",
      " [ 1.20566342e+00  1.41129057e+00  1.33649588e-01 -9.43083687e-03\n",
      "   1.41475744e+00 -3.01191567e-01  2.76830891e+00 -3.98706437e-02\n",
      "  -3.72973900e-01 -4.61233190e-01 -1.85494781e-02 -3.73573910e-01\n",
      "  -4.14251590e-01 -5.22507090e-01 -7.86345497e-01]\n",
      " [ 3.00807350e+00 -3.50773745e-02  1.74814476e+00  1.85540937e+00\n",
      "   6.28923327e-01  1.11659469e+00  2.50787360e+00 -7.79159952e-01\n",
      "   8.19371315e-01 -4.75914797e-01  1.02599414e+00  4.59833469e-03\n",
      "   1.10093975e-01 -6.22044632e-01 -7.13883957e-01]\n",
      " [ 1.34889423e+00 -9.30447660e-01  9.27774691e-01 -1.09177749e+00\n",
      "   2.02638580e+00  8.41038613e-01 -4.89231279e-01 -2.94761602e-01\n",
      "   1.00943203e+00  6.97938476e-01  5.97412744e-01  2.03383163e+00\n",
      "   2.35822563e+00 -1.21348388e-01 -7.23636892e-01]\n",
      " [ 3.60680494e-01 -2.93635679e-01 -3.45381726e-01  9.68544535e-01\n",
      "  -3.94350404e-01 -5.43444543e-01 -1.70693098e-01 -1.47875733e-01\n",
      "  -2.69185235e-01 -1.21619359e-01  5.43924233e-01 -3.26886671e-01\n",
      "  -6.02371340e-03 -6.29052883e-01  1.02396923e+00]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 500}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1',\n",
      "       'mean_surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_sea_level_pressure_max_PCA_2', 'surface_pressure_min_PCA_1',\n",
      "       'surface_pressure_min_PCA_4'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 40\n",
      "RMSE Before Tuning: 1.2531497124273712, MAE Before Tuning: 0.9447776332947754\n",
      "RMSE After Tuning: 1.2578233013532951, MAE After Tuning: 0.9362998027044758\n",
      "R2 Before Tuning: -1.311149388452327, R2 After Tuning: -1.3995576521917446\n",
      "Relative Variance on validation set: 0.7341266511692504\n",
      "Relative Variance on training set: 1.2214691375806768\n",
      "Residuals before tuning: [[-0.51732804 -0.44869598 -1.54373618  1.1829968   1.53161029 -0.67388902\n",
      "  -0.56813725 -1.18444238 -0.33376359  0.00677757 -0.09159616 -0.9505829\n",
      "  -1.3006386   0.06002198 -0.38635025]\n",
      " [ 0.39403182  1.78975384 -0.39201152  0.81461477 -0.77791403 -0.97638777\n",
      "  -0.45095104 -0.37967995 -0.65583583  0.54284299 -0.29707707 -0.03909092\n",
      "  -0.21245469 -0.01274233 -1.53732495]\n",
      " [ 1.31234976  1.60816265  0.57623795  0.74201854  1.14621184 -0.9366501\n",
      "   3.75361691  0.06919833 -0.69874903 -2.61299972 -0.15666323 -0.47145413\n",
      "  -0.53390234 -0.64171191 -1.94322277]\n",
      " [ 3.72396971  0.27591376  2.16775581  1.41915185  0.59184845  1.40265503\n",
      "   1.20948501 -0.3254369   0.48559501 -0.41826258  1.32777836  0.54697274\n",
      "   1.43768956 -0.16315492 -3.16326846]\n",
      " [ 1.16762373 -1.89651984  0.97116378 -1.35578371  1.06580073  1.0044495\n",
      "   0.45938602 -1.0766007   0.91381634  0.97539667  1.00078824  3.52015945\n",
      "   3.51908061 -0.84712681 -0.92728558]\n",
      " [ 0.24596835 -0.12386056  0.20318388  1.29453293  0.04095094 -0.27994325\n",
      "   1.08285902 -0.64294945  0.18504164 -0.02275999  0.91789668  1.09021433\n",
      "   0.95187109 -0.5231878   0.80841748]], Residuals after tuning: [[-0.52332761 -0.36424549 -1.43857702  1.18800621  1.54727898 -0.67043922\n",
      "  -0.57421717 -1.26853023 -0.60706125 -0.11312757 -0.10897473 -0.56525174\n",
      "  -1.43966977  0.2196983  -0.29908663]\n",
      " [ 0.3476327   1.74623899 -0.4424442   0.87662625 -0.82158194 -0.99854199\n",
      "  -0.42563481 -0.30034295 -0.32080704  0.63110513 -0.43251921 -0.42186515\n",
      "  -0.30115272 -0.02921586 -1.57190423]\n",
      " [ 1.39930042  1.52275277  0.42593416  0.62777026  1.31901667 -1.28652996\n",
      "   3.77991115 -0.0777534  -0.68714972 -2.85399608 -0.05994993 -0.06829809\n",
      "  -0.36541622 -0.66528412 -1.78526451]\n",
      " [ 4.13763155  0.17206804  2.0521616   1.47387917  0.6067458   0.96798611\n",
      "   1.20788523 -0.10157192  0.64941087 -0.37759186  1.64644911  0.37309443\n",
      "   0.85185714 -0.12725269 -2.58727898]\n",
      " [ 1.24014184 -1.8378312   1.18944565 -1.37851287  1.21343428  1.13070334\n",
      "   0.50289312 -0.97608736  1.0335436   1.12782993  0.66834405  3.37235233\n",
      "   3.69177291 -0.80919966 -0.89917853]\n",
      " [ 0.29147649  0.055396   -0.01731307  1.35174909 -0.0825326  -0.2127968\n",
      "   1.07899473 -0.75301134  0.04322398  0.18136367  1.08579587  0.87724336\n",
      "   1.16485589 -0.39184992  0.75581173]]\n",
      "Best Params: {'max_depth': 20, 'n_estimators': 20}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'geopotential_500_max_PCA_1',\n",
      "       'surface_pressure_std_PCA_3', 'large_scale_snowfall_max_PCA_1',\n",
      "       'large_scale_snowfall_max_PCA_3'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 40\n",
      "RMSE Before Tuning: 1.0838028966844266, MAE Before Tuning: 0.8151256615311266\n",
      "RMSE After Tuning: 0.9986244363680441, MAE After Tuning: 0.7562722109839959\n",
      "R2 Before Tuning: -0.3648591838616405, R2 After Tuning: -0.17512646191838932\n",
      "Relative Variance on validation set: 0.7341266511692504\n",
      "Relative Variance on training set: 1.2214691375806768\n",
      "Residuals before tuning: [[ 0.24057266  0.19720263 -0.88030386  0.73037436  0.84765562  0.23032603\n",
      "  -0.63123789  0.4038704  -0.05055436 -0.61649977 -0.13075738 -1.29838808\n",
      "  -1.2905714   1.54797242 -1.07525757]\n",
      " [ 1.37393847  1.55842196 -0.7577055   0.19128966 -0.75850372 -0.65470884\n",
      "   0.01823033  0.04092808 -0.70414762  0.07075907 -0.80839841 -0.43313833\n",
      "  -0.99198886  0.06392229  0.18181523]\n",
      " [ 1.2605564   1.28317608  0.2100977   0.01481427  1.48242212 -0.234057\n",
      "   3.1170925  -0.14485264 -0.41975987 -0.3600158   0.10254452 -0.32961661\n",
      "  -0.35245181 -0.5735379  -0.83234246]\n",
      " [ 3.40617435 -0.09327754  2.2007257   1.4441167   0.76573161  1.08656078\n",
      "   2.65604728 -0.83510564  0.77553242 -0.34840071  1.37861415  0.60364184\n",
      "   0.8836007  -0.64542274 -1.01225983]\n",
      " [ 1.4171551  -1.28804336  1.29912724 -1.41644659  2.1513728   0.91281672\n",
      "  -0.48539502 -0.56219736  1.11036536  0.54858686  0.8377052   2.68747685\n",
      "   3.04848433 -0.35051597 -0.80112195]\n",
      " [ 0.50784687 -0.22978792  0.00997849  0.85492583 -0.17622726 -0.51428163\n",
      "  -0.69844929 -0.12472652 -0.18915256 -0.25777046  0.77561162  0.19280756\n",
      "   0.65003643 -0.66524857  0.96565733]], Residuals after tuning: [[ 0.32583064  0.27932463 -0.78335014  0.39247746  0.94147318  0.40760249\n",
      "  -1.10115347  0.45091045  0.01246778 -0.37761585 -0.03055278 -1.32745786\n",
      "  -1.21708216  1.63462695 -1.10173233]\n",
      " [ 0.93190877  1.26353824 -0.85499448 -0.07025003 -0.86602013 -0.60951136\n",
      "   0.29566677 -0.01473033 -0.61024399  0.36590289 -0.93074789 -0.50849586\n",
      "  -1.05729701  0.05087211  0.59793612]\n",
      " [ 1.19291892  1.45050928  0.0487502   0.05668758  1.3917368  -0.32075283\n",
      "   2.85803475 -0.02416049 -0.3938909  -0.45460899 -0.09369032 -0.48035656\n",
      "  -0.54390455 -0.51144858 -0.74405862]\n",
      " [ 3.07159692 -0.02327263  1.79249453  1.83635713  0.66840423  1.10826716\n",
      "   2.55763859 -0.78235332  0.81288209 -0.48786826  1.05991594  0.12207731\n",
      "   0.21944859 -0.62120353 -0.74891411]\n",
      " [ 1.45051521 -0.95360828  0.98394799 -1.12726536  2.07525017  0.83227459\n",
      "  -0.35501053 -0.31190401  1.01984948  0.61017007  0.65448424  2.23239178\n",
      "   2.57710398 -0.15483626 -0.82155979]\n",
      " [ 0.44435732 -0.28883362 -0.28065816  0.93863376 -0.33370979 -0.54711826\n",
      "  -0.09767704 -0.15132629 -0.27084635 -0.12542481  0.6016049  -0.14547936\n",
      "   0.1644495  -0.63384762  0.9903826 ]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 100}\n",
      "Selected Features: Index(['geopotential_1000_min_PCA_2', 'geopotential_1000_std_PCA_1',\n",
      "       'geopotential_1000_std_PCA_2', 'surface_pressure_std_PCA_4',\n",
      "       'large_scale_snowfall_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 40\n",
      "RMSE Before Tuning: 1.0838028966844266, MAE Before Tuning: 0.8151256615311264\n",
      "RMSE After Tuning: 0.998624436368044, MAE After Tuning: 0.7562722109839959\n",
      "R2 Before Tuning: -0.36485918386164057, R2 After Tuning: -0.17512646191838915\n",
      "Relative Variance on validation set: 0.7341266511692504\n",
      "Relative Variance on training set: 1.2214691375806768\n",
      "Residuals before tuning: [[ 0.24057266  0.19720263 -0.88030386  0.73037436  0.84765562  0.23032603\n",
      "  -0.63123789  0.4038704  -0.05055436 -0.61649977 -0.13075738 -1.29838808\n",
      "  -1.2905714   1.54797242 -1.07525757]\n",
      " [ 1.37393847  1.55842196 -0.7577055   0.19128966 -0.75850372 -0.65470884\n",
      "   0.01823033  0.04092808 -0.70414762  0.07075907 -0.80839841 -0.43313833\n",
      "  -0.99198886  0.06392229  0.18181523]\n",
      " [ 1.2605564   1.28317608  0.2100977   0.01481427  1.48242212 -0.234057\n",
      "   3.1170925  -0.14485264 -0.41975987 -0.3600158   0.10254452 -0.32961661\n",
      "  -0.35245181 -0.5735379  -0.83234246]\n",
      " [ 3.40617435 -0.09327754  2.2007257   1.4441167   0.76573161  1.08656078\n",
      "   2.65604728 -0.83510564  0.77553242 -0.34840071  1.37861415  0.60364184\n",
      "   0.8836007  -0.64542274 -1.01225983]\n",
      " [ 1.4171551  -1.28804336  1.29912724 -1.41644659  2.1513728   0.91281672\n",
      "  -0.48539502 -0.56219736  1.11036536  0.54858686  0.8377052   2.68747685\n",
      "   3.04848433 -0.35051597 -0.80112195]\n",
      " [ 0.50784687 -0.22978792  0.00997849  0.85492583 -0.17622726 -0.51428163\n",
      "  -0.69844929 -0.12472652 -0.18915256 -0.25777046  0.77561162  0.19280756\n",
      "   0.65003643 -0.66524857  0.96565733]], Residuals after tuning: [[ 0.32583064  0.27932463 -0.78335014  0.39247746  0.94147318  0.40760249\n",
      "  -1.10115347  0.45091045  0.01246778 -0.37761585 -0.03055278 -1.32745786\n",
      "  -1.21708216  1.63462695 -1.10173233]\n",
      " [ 0.93190877  1.26353824 -0.85499448 -0.07025003 -0.86602013 -0.60951136\n",
      "   0.29566677 -0.01473033 -0.61024399  0.36590289 -0.93074789 -0.50849586\n",
      "  -1.05729701  0.05087211  0.59793612]\n",
      " [ 1.19291892  1.45050928  0.0487502   0.05668758  1.3917368  -0.32075283\n",
      "   2.85803475 -0.02416049 -0.3938909  -0.45460899 -0.09369032 -0.48035656\n",
      "  -0.54390455 -0.51144858 -0.74405862]\n",
      " [ 3.07159692 -0.02327263  1.79249453  1.83635713  0.66840423  1.10826716\n",
      "   2.55763859 -0.78235332  0.81288209 -0.48786826  1.05991594  0.12207731\n",
      "   0.21944859 -0.62120353 -0.74891411]\n",
      " [ 1.45051521 -0.95360828  0.98394799 -1.12726536  2.07525017  0.83227459\n",
      "  -0.35501053 -0.31190401  1.01984948  0.61017007  0.65448424  2.23239178\n",
      "   2.57710398 -0.15483626 -0.82155979]\n",
      " [ 0.44435732 -0.28883362 -0.28065816  0.93863376 -0.33370979 -0.54711826\n",
      "  -0.09767704 -0.15132629 -0.27084635 -0.12542481  0.6016049  -0.14547936\n",
      "   0.1644495  -0.63384762  0.9903826 ]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 100}\n",
      "Selected Features: Index(['geopotential_1000_min_PCA_2', 'geopotential_1000_std_PCA_1',\n",
      "       'geopotential_1000_std_PCA_2', 'surface_pressure_std_PCA_4',\n",
      "       'large_scale_snowfall_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 20\n",
      "RMSE Before Tuning: 6.399234563390174, MAE Before Tuning: 4.971760742067031\n",
      "RMSE After Tuning: 4.970377548369065, MAE After Tuning: 4.066479313878751\n",
      "R2 Before Tuning: -1.8525829387044306, R2 After Tuning: -0.7298810801208148\n",
      "Relative Variance on validation set: 0.10893631231587513\n",
      "Relative Variance on training set: 0.14635847210481218\n",
      "Residuals before tuning: [[ -1.49397344  -3.83002419  -3.50615659   2.74234139   6.25360815\n",
      "    4.61746397   0.5871101   -3.76412227  -1.03059271   2.03975974\n",
      "    0.79289483  -6.74123762   0.27798733   2.434858    -9.95215139]\n",
      " [ -4.36300494  14.6758507   -6.76606129   7.05071477  -2.10806009\n",
      "   -4.3809189    1.23817041   3.10811704  -5.6059823   -0.95106665\n",
      "   -9.47809766  -6.22337144  -6.79319304   0.1227035    6.16766284]\n",
      " [  8.07623298  11.07965728   1.01785864   2.75525786   6.96841387\n",
      "   -1.6025253   11.47067021   0.39547138   2.29796697 -20.11681138\n",
      "    0.11449631  -0.60780051  -0.68165648  -6.57846007  -1.57267084]\n",
      " [ 13.38667888  -9.19135383   5.42533269   3.27345739   0.63460152\n",
      "    3.54191153   9.53668433  -8.49853534   3.57956232  -4.66375825\n",
      "    6.40135058  -2.55154949  11.66120805  -4.76173241  -6.33839022]\n",
      " [  6.06228905  -9.6648586    9.23671738  -6.04916741   4.26971423\n",
      "    4.75407357  -4.02014112  -0.75672456   3.17065993   2.80936293\n",
      "    5.86998806  13.65425084  14.86336391  -2.60340904 -13.87144377]\n",
      " [ -5.54365018  -5.33973847  -1.23359355   6.55875873  -2.96346008\n",
      "   -6.56934719   0.21719998  -0.76233694  -0.64938812  -0.52327843\n",
      "    2.5786663   -0.59773759  -3.13653622  -7.21329054  -4.03600584]], Residuals after tuning: [[ 1.64344531  0.56845718 -4.85188451  2.19807374  4.09713308  3.29122915\n",
      "   1.6410957   1.195173   -0.76897695 -2.80988206 -0.63288642 -4.66456221\n",
      "  -4.05691257  6.44506232 -8.99612149]\n",
      " [ 3.99678395  8.49024183 -4.5174136   2.52524594 -4.42348406 -6.28706971\n",
      "   2.8733404   1.96907514 -8.75639581  1.92609819 -4.74970792  0.42647368\n",
      "  -3.75202674  0.42141147  6.44233249]\n",
      " [ 6.77223785  9.1256816   1.70774473  1.28238227  4.80154375 -3.16637761\n",
      "  10.72641133  0.4876688  -3.84752081 -8.36101495 -0.2877845   1.2654905\n",
      "   1.54368913 -3.07272658 -1.62563791]\n",
      " [12.22657603 -0.38580994  9.04783025  4.89440809  1.84909814  6.06705039\n",
      "   9.26959448 -7.50772876  3.64598765 -5.58305642  4.83907946  2.2516045\n",
      "   4.32990732 -4.52853997 -5.6411265 ]\n",
      " [ 4.68083649 -8.60839917  6.43287865 -3.84278848  4.07584178  4.68236107\n",
      "  -0.01248502 -5.62112733  3.42510787  3.58629469  3.10989055  9.91334699\n",
      "  12.04464595 -1.52004456 -3.91208937]\n",
      " [ 3.74982974 -0.40453682 -0.73803386  4.12712765 -2.67369377 -4.64494305\n",
      "   1.70207089 -1.86457082 -3.67556267 -0.93420143  1.31446037 -1.23982362\n",
      "   1.53989734 -6.44131025  5.9056312 ]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 5}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_mean_PCA_2',\n",
      "       'mean_surface_latent_heat_flux_std_PCA_1',\n",
      "       'surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_surface_latent_heat_flux_min_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 20\n",
      "RMSE Before Tuning: 4.703952936348527, MAE Before Tuning: 3.82462028300806\n",
      "RMSE After Tuning: 4.4949777319003505, MAE After Tuning: 3.6902742004151596\n",
      "R2 Before Tuning: -0.4620379910546894, R2 After Tuning: -0.3231035139350246\n",
      "Relative Variance on validation set: 0.10893631231587513\n",
      "Relative Variance on training set: 0.14635847210481218\n",
      "Residuals before tuning: [[ 1.80138877e+00  1.09680751e+00 -3.24855225e+00  2.00342680e+00\n",
      "   4.01416558e+00  3.11418770e+00 -1.08093548e-03  3.00952095e+00\n",
      "   8.89771272e-01 -2.93234270e+00  3.87843084e-01 -2.96426425e+00\n",
      "  -2.12155218e+00  8.18002863e+00 -8.55719238e+00]\n",
      " [ 3.66870584e+00  7.39359870e+00 -5.64436968e+00  1.53787446e+00\n",
      "  -4.52649110e+00 -5.86294417e+00  8.97641132e-01  1.34639189e+00\n",
      "  -6.68223469e+00  3.70306523e+00 -5.11409446e+00 -3.82003080e+00\n",
      "  -6.76722847e+00  2.06093211e+00  5.74235553e+00]\n",
      " [ 4.96550801e+00  8.20236566e+00 -1.04578311e+00  2.13014353e+00\n",
      "   5.30402697e+00 -1.07246828e+00  8.98100061e+00  7.99343083e-01\n",
      "  -1.26057022e+00 -3.58719257e+00 -4.85182467e-01 -1.86330773e+00\n",
      "  -2.22034586e+00 -3.38837453e+00 -2.63970642e+00]\n",
      " [ 8.70877927e+00 -3.15511515e+00  9.34690305e+00  3.41095453e+00\n",
      "   8.91406982e-01  5.22603070e+00  7.36313606e+00 -8.44241200e+00\n",
      "   3.18240642e+00 -4.95874310e+00  3.97134620e+00  1.12885925e+00\n",
      "   3.20657181e+00 -5.95956828e+00 -5.27719410e+00]\n",
      " [ 2.55711555e+00 -7.57932350e+00  7.23012311e+00 -6.14352844e+00\n",
      "   5.17275739e+00  5.12003300e+00 -2.34644247e+00 -3.55567108e+00\n",
      "   4.82890335e+00  5.25889166e+00  3.72956963e+00  1.10975415e+01\n",
      "   1.33634430e+01 -1.08774110e+00 -3.99735647e+00]\n",
      " [ 1.84764224e+00 -9.66356573e-02 -1.32056383e-01  3.01680076e+00\n",
      "  -1.88031375e-01 -3.80104122e+00 -2.01376141e+00  2.63889308e-01\n",
      "  -2.11348322e-02  1.47755621e+00  3.10412086e+00  3.39158121e-01\n",
      "   2.68110683e+00 -4.91922162e+00  5.98039818e+00]], Residuals after tuning: [[ 2.21107482  2.46771361 -3.66183007  2.42224173  4.1769961   3.41652252\n",
      "  -2.84040646  3.39675356  1.11627419 -2.00439931  0.46950895 -5.47241443\n",
      "  -4.34789944  8.51134665 -7.24370114]\n",
      " [ 3.86217725  7.0368356  -5.37356545  1.13393428 -3.99386661 -5.47444833\n",
      "   1.2331222   0.99881443 -5.8762581   3.84424888 -5.28794424 -2.50520204\n",
      "  -5.28373734  1.64035966  4.95905895]\n",
      " [ 4.86711157  7.52284813  1.19103361  1.10798397  5.36935742 -1.02494137\n",
      "   8.1344112   0.75423868 -1.65937727 -3.18815853  0.30547939 -1.06543839\n",
      "  -0.88543188 -2.89901805 -2.91113269]\n",
      " [10.12416707  0.50881586  8.92021274  5.39454473  2.88345942  6.48213067\n",
      "   7.38223255 -5.01040536  4.65430044 -3.80066362  4.67244725  1.2397158\n",
      "   2.22303608 -4.57565892 -2.96898596]\n",
      " [ 4.99567367 -5.12332637  6.36292784 -3.77392841  6.9802361   5.19446803\n",
      "  -1.23129607 -1.87676744  5.20672725  5.01201703  3.66412467 10.66126037\n",
      "  12.01148907 -0.12707287 -3.92159003]\n",
      " [ 1.67629623 -0.75025861 -1.14705658  3.38145472 -1.18972879 -4.09258266\n",
      "  -0.38798003 -0.31015498 -0.92422789  0.59022447  2.6430981  -0.75270061\n",
      "   1.17639821 -4.77101884  6.19919715]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 500}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_mean_PCA_2',\n",
      "       'mean_sea_level_pressure_max_PCA_1', 'surface_pressure_max_PCA_1',\n",
      "       'surface_latent_heat_flux_mean_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 20\n",
      "RMSE Before Tuning: 4.703952936348528, MAE Before Tuning: 3.82462028300806\n",
      "RMSE After Tuning: 4.552663721582057, MAE After Tuning: 3.735460775763146\n",
      "R2 Before Tuning: -0.4620379910546895, R2 After Tuning: -0.3501560248209179\n",
      "Relative Variance on validation set: 0.10893631231587513\n",
      "Relative Variance on training set: 0.14635847210481218\n",
      "Residuals before tuning: [[ 1.80138877e+00  1.09680751e+00 -3.24855225e+00  2.00342680e+00\n",
      "   4.01416558e+00  3.11418770e+00 -1.08093548e-03  3.00952095e+00\n",
      "   8.89771272e-01 -2.93234270e+00  3.87843084e-01 -2.96426425e+00\n",
      "  -2.12155218e+00  8.18002863e+00 -8.55719238e+00]\n",
      " [ 3.66870584e+00  7.39359870e+00 -5.64436968e+00  1.53787446e+00\n",
      "  -4.52649110e+00 -5.86294417e+00  8.97641132e-01  1.34639189e+00\n",
      "  -6.68223469e+00  3.70306523e+00 -5.11409446e+00 -3.82003080e+00\n",
      "  -6.76722847e+00  2.06093211e+00  5.74235553e+00]\n",
      " [ 4.96550801e+00  8.20236566e+00 -1.04578311e+00  2.13014353e+00\n",
      "   5.30402697e+00 -1.07246828e+00  8.98100061e+00  7.99343083e-01\n",
      "  -1.26057022e+00 -3.58719257e+00 -4.85182467e-01 -1.86330773e+00\n",
      "  -2.22034586e+00 -3.38837453e+00 -2.63970642e+00]\n",
      " [ 8.70877927e+00 -3.15511515e+00  9.34690305e+00  3.41095453e+00\n",
      "   8.91406982e-01  5.22603070e+00  7.36313606e+00 -8.44241200e+00\n",
      "   3.18240642e+00 -4.95874310e+00  3.97134620e+00  1.12885925e+00\n",
      "   3.20657181e+00 -5.95956828e+00 -5.27719410e+00]\n",
      " [ 2.55711555e+00 -7.57932350e+00  7.23012311e+00 -6.14352844e+00\n",
      "   5.17275739e+00  5.12003300e+00 -2.34644247e+00 -3.55567108e+00\n",
      "   4.82890335e+00  5.25889166e+00  3.72956963e+00  1.10975415e+01\n",
      "   1.33634430e+01 -1.08774110e+00 -3.99735647e+00]\n",
      " [ 1.84764224e+00 -9.66356573e-02 -1.32056383e-01  3.01680076e+00\n",
      "  -1.88031375e-01 -3.80104122e+00 -2.01376141e+00  2.63889308e-01\n",
      "  -2.11348322e-02  1.47755621e+00  3.10412086e+00  3.39158121e-01\n",
      "   2.68110683e+00 -4.91922162e+00  5.98039818e+00]], Residuals after tuning: [[ 2.06626298  1.79533436 -3.34904156  1.97970485  4.2355291   3.23722837\n",
      "  -2.19873088  2.86883241  1.07453262 -2.6319491   0.71120457 -4.70587424\n",
      "  -3.59163431  7.86921049 -8.03063881]\n",
      " [ 3.86918232  7.19388154 -5.18928577  1.00903887 -3.82811183 -5.48303775\n",
      "   1.40694328  1.27301227 -5.95623033  4.15227663 -5.13616793 -2.09833568\n",
      "  -4.950038    1.77347977  5.05934298]\n",
      " [ 5.34316173  8.26080092  1.17414277  1.40271177  5.81386178 -0.6610364\n",
      "   8.37250826  1.45801632 -1.40594924 -2.72160673  0.36818047 -0.80649842\n",
      "  -0.75261204 -2.4235614  -2.65860661]\n",
      " [ 9.64375783 -0.65826356  9.77120276  4.3023427   2.69902833  6.43109406\n",
      "   7.08045734 -5.85326337  4.42741899 -3.78640655  4.97962671  1.87566459\n",
      "   3.30166228 -5.06472495 -3.55357736]\n",
      " [ 4.18007529 -6.07903253  6.88809822 -4.47417954  6.76308596  4.98072253\n",
      "  -1.694574   -2.68093462  4.9289535   5.12421744  3.89244694 10.94400625\n",
      "  12.55601798 -0.66440878 -3.85981955]\n",
      " [ 1.39172896 -1.27778303 -0.25164473  2.68072819 -1.05335692 -4.22226941\n",
      "  -0.72891031 -0.72703292 -1.07274144  0.62484415  3.14193545  0.17845865\n",
      "   2.37300103 -5.17604442  5.80459722]]\n",
      "Best Params: {'max_depth': 2, 'n_estimators': 100}\n",
      "Selected Features: Index(['10m_u_component_of_wind_max_PCA_1',\n",
      "       'mean_sea_level_pressure_min_PCA_1',\n",
      "       '10m_v_component_of_wind_max_PCA_2',\n",
      "       'mean_sea_level_pressure_max_PCA_2', 'surface_pressure_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 30\n",
      "RMSE Before Tuning: 5.90217136085948, MAE Before Tuning: 4.657823254719799\n",
      "RMSE After Tuning: 4.871184766668655, MAE After Tuning: 3.9932995013382677\n",
      "R2 Before Tuning: -1.4115376559317072, R2 After Tuning: -0.6240642702088504\n",
      "Relative Variance on validation set: 0.10893631231587513\n",
      "Relative Variance on training set: 0.14635847210481218\n",
      "Residuals before tuning: [[ -2.97309369  -2.74633355  -2.85406461   3.77510011   7.30823366\n",
      "    3.63474073  -0.92834324  -2.07934597  -1.17312124  -0.59762372\n",
      "    0.43855523  -6.38054846   1.69417271   1.82999388  -8.93259153]\n",
      " [ -4.04204013   6.69556028  -5.94442509   7.98094777  -5.06025049\n",
      "   -6.45720521   0.91887644  -2.69690234  -6.505692     0.99701913\n",
      "   -4.75384115  -1.39248842  -6.67544288   1.56694789   7.13813899]\n",
      " [  5.1057225    8.74411269   1.11358656   3.63221671   8.33849291\n",
      "   -1.62898214  12.37425755  -0.9586813   -0.67455481 -17.32865869\n",
      "    2.35618599  -0.83021835   1.28316819  -4.28498588  -4.02773561]\n",
      " [ 15.9366762   -4.64384941  11.4987885    2.17597281   3.62632745\n",
      "    4.60590498   5.70769339  -2.53156775   7.04155077  -5.14408776\n",
      "    7.19813021   2.18511432   9.06462564  -6.79238732  -2.78271471]\n",
      " [  7.68142777 -10.07038571   8.75574318  -2.94306352   6.71116626\n",
      "    5.0102591   -0.62760495  -5.83277055   5.85908499   5.51048712\n",
      "    5.61285839  13.56401418  15.19429462  -2.71986031  -2.10480406]\n",
      " [  0.73560474  -3.67935333   1.07827321   2.90674877   0.62171066\n",
      "   -5.45367222  -0.91484958  -1.04435369  -2.31517677  -0.88467331\n",
      "    4.72660026  -1.70828752   1.81784191  -7.41407713   5.9164535 ]], Residuals after tuning: [[  1.31724292   0.51267104  -4.27503171   5.16092813   3.92734091\n",
      "    3.49596395   0.38519436   2.62062619   0.87065432  -1.05491437\n",
      "   -1.10762168  -3.63762281  -0.8788139    6.10448233 -10.5825282 ]\n",
      " [  3.9224622    6.4245928   -5.64308689   4.1066573   -3.87549326\n",
      "   -7.12077752   2.26691797   0.77352803  -6.64037752   2.27049669\n",
      "   -4.49116682  -1.27151292  -4.01761741   1.94135089   7.80457137]\n",
      " [  6.6979161    7.06003257   1.9171182    2.09334304   5.34953455\n",
      "   -1.16604383  12.233541     0.48609523  -3.40933035  -4.92516099\n",
      "    0.85160454   1.07570931   2.66526735  -1.55278716  -1.67722025]\n",
      " [ 12.10391063   1.06050011   7.79747548   4.62636458   1.4455127\n",
      "    5.5668215    8.66317206  -6.07841128   4.26854243  -5.23865792\n",
      "    5.09762057   3.27854389   5.45148554  -4.85560448  -2.77141939]\n",
      " [  4.59319191  -7.34251477   6.64225212  -2.90373399   5.96633899\n",
      "    5.65631241   0.52970553  -2.7647812    3.86329833   6.19739298\n",
      "    4.23315677  10.81396649  11.64216868  -1.76225876  -3.96367171]\n",
      " [  3.64048717  -1.78458557  -0.52866038   4.93808842  -0.7935363\n",
      "   -5.34724407   1.09564847  -1.59003087  -2.41178017   0.32742481\n",
      "    3.31857452   1.1690013    2.66147556  -6.68352446   4.26515497]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 5}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1',\n",
      "       'surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_surface_latent_heat_flux_min_PCA_1', 'surface_pressure_min_PCA_4',\n",
      "       'mean_surface_sensible_heat_flux_min_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 30\n",
      "RMSE Before Tuning: 4.741679899813311, MAE Before Tuning: 3.8172573656358706\n",
      "RMSE After Tuning: 4.513615201596245, MAE After Tuning: 3.6722299823947333\n",
      "R2 Before Tuning: -0.444826857935088, R2 After Tuning: -0.3431847769517573\n",
      "Relative Variance on validation set: 0.10893631231587513\n",
      "Relative Variance on training set: 0.14635847210481218\n",
      "Residuals before tuning: [[ 1.32718651  1.78899222 -3.8836152   1.59302961  4.34130238  4.08120698\n",
      "  -1.44616374  3.87997653  1.33528004 -3.08744157 -0.05122835 -5.23342792\n",
      "  -4.53403125  8.48217587 -8.41099388]\n",
      " [ 4.63198482  8.18966805 -5.63867243  2.36618747 -3.9459318  -5.59564746\n",
      "   1.09177936  1.42215264 -6.07304821  3.82947683 -4.77470182 -3.68320706\n",
      "  -6.44887588  2.01958258  5.82052017]\n",
      " [ 4.68967011  7.34118171  1.29935768  1.01071138  5.29084516 -0.43150469\n",
      "   7.68895969  0.41697717 -1.39174234 -3.07459674  0.47493581 -0.92971358\n",
      "  -0.41877991 -2.78276508 -1.96278244]\n",
      " [10.94977977  1.10733619  8.96235853  5.42288071  3.37014912  6.99478611\n",
      "   8.37709086 -3.81976697  4.55167714 -3.45896003  5.14402286  1.33746321\n",
      "   2.60338428 -3.72887454 -3.51559382]\n",
      " [ 5.22938764 -5.59214514  6.99325487 -3.75176336  7.14593716  5.44603934\n",
      "  -0.54406983 -2.4116919   5.33390585  5.26252089  4.23023943 12.18132391\n",
      "  13.33149878 -0.22952992 -2.87853416]\n",
      " [ 1.99917013 -0.58520298 -0.18715267  3.31970209 -0.18840436 -4.86890259\n",
      "  -0.93423761 -0.70243726 -0.95161865 -0.05844555  3.78209144  0.02619686\n",
      "   2.64278975 -6.06071268  5.12811989]], Residuals after tuning: [[ 1.83927853  2.73058728 -4.09228255  2.77353802  4.07775108  3.52057335\n",
      "  -2.64331188  3.7843457   1.03171749 -1.63801593  0.26563433 -6.00863729\n",
      "  -4.97060006  8.81644794 -6.66613019]\n",
      " [ 4.61218285  7.4914593  -4.99115999  1.4581274  -3.49334138 -5.20819503\n",
      "   1.59899785  1.40459007 -5.72216174  4.16386004 -4.86090448 -1.7179805\n",
      "  -4.56389675  1.9998672   5.11277232]\n",
      " [ 4.93465138  7.32739404  1.65617434  0.82950749  5.48200385 -0.97757842\n",
      "   8.21968154  0.7520364  -1.77065098 -3.07939962  0.53875472 -0.50894141\n",
      "  -0.22240849 -2.87335255 -3.23201448]\n",
      " [10.13971214  0.87650899  8.44173906  5.88101958  2.86870332  6.45651398\n",
      "   7.48124094 -4.6727329   4.59912197 -3.45747997  4.44630851  0.94454582\n",
      "   1.68878133 -4.27431849 -2.29077131]\n",
      " [ 5.42938779 -4.72655132  6.38003586 -3.41614405  7.28503862  5.3487005\n",
      "  -0.80532104 -1.47737216  5.20661518  5.4502749   3.75849574 11.15468404\n",
      "  12.37763718  0.2648466  -3.61118522]\n",
      " [ 2.36142052 -0.55217967 -0.57084196  3.36142917 -0.68372494 -3.86830768\n",
      "   0.12117557 -0.15181268 -0.81183204  0.71682675  3.138578    0.46422131\n",
      "   2.40065672 -4.61256926  5.81043539]]\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 50}\n",
      "Selected Features: Index(['surface_pressure_mean_PCA_1', 'surface_pressure_mean_PCA_2',\n",
      "       '10m_v_component_of_wind_max_PCA_2', '2m_temperature_std_PCA_1',\n",
      "       'mean_surface_sensible_heat_flux_min_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     11\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstorm_indices\u001b[39m\u001b[38;5;124m'\u001b[39m: storm_indices,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransposed_data_20\u001b[39m\u001b[38;5;124m'\u001b[39m: transposed_data_20,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     }\n\u001b[1;32m     27\u001b[0m }\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Run sensitivity analysis\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m sensitivity_results \u001b[38;5;241m=\u001b[39m sensitivity_analysis(\n\u001b[1;32m     31\u001b[0m     seeds\u001b[38;5;241m=\u001b[39mseeds,\n\u001b[1;32m     32\u001b[0m     split_function\u001b[38;5;241m=\u001b[39mextraction_squares\u001b[38;5;241m.\u001b[39msplit_storm_numbers,\n\u001b[1;32m     33\u001b[0m     process_workflow\u001b[38;5;241m=\u001b[39msensitivity_test\u001b[38;5;241m.\u001b[39mprocess_xgboost_workflow,  \u001b[38;5;66;03m# Assuming this is the earlier provided function\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     data_dict\u001b[38;5;241m=\u001b[39mdata_dict\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Analyze the sensitivity\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, selected_features \u001b[38;5;129;01min\u001b[39;00m sensitivity_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36msensitivity_analysis\u001b[0;34m(seeds, split_function, process_workflow, data_dict)\u001b[0m\n\u001b[1;32m     35\u001b[0m y_validation \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m: data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselection_vars\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprocess_y_data(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_all_cdf\u001b[39m\u001b[38;5;124m'\u001b[39m], storm_index_validation),\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselection_vars\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprocess_y_data(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_all_max\u001b[39m\u001b[38;5;124m'\u001b[39m], storm_index_validation),\n\u001b[1;32m     38\u001b[0m }\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Process the workflow for this seed\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m results \u001b[38;5;241m=\u001b[39m process_workflow(\n\u001b[1;32m     42\u001b[0m     X_train_pca\u001b[38;5;241m=\u001b[39mX_train_pca,\n\u001b[1;32m     43\u001b[0m     X_validation_pca\u001b[38;5;241m=\u001b[39mX_validation_pca,\n\u001b[1;32m     44\u001b[0m     y_train\u001b[38;5;241m=\u001b[39my_train,\n\u001b[1;32m     45\u001b[0m     y_validation\u001b[38;5;241m=\u001b[39my_validation,\n\u001b[1;32m     46\u001b[0m     variable_counts\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m],\n\u001b[1;32m     47\u001b[0m     target_types\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# or ['cdf', 'max']\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mdata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_grid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Collect selected features for each variable count and target type\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, res \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/GitHub/master-project-cleaned/util/ml/sensitivity_test.py:137\u001b[0m, in \u001b[0;36mprocess_xgboost_workflow\u001b[0;34m(X_train_pca, X_validation_pca, y_train, y_validation, variable_counts, target_types, param_grid, print_info)\u001b[0m\n\u001b[1;32m    127\u001b[0m results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_params\u001b[39m\u001b[38;5;124m'\u001b[39m: search\u001b[38;5;241m.\u001b[39mbest_params_,\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_after_tuning\u001b[39m\u001b[38;5;124m'\u001b[39m: rmse_tuned,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresiduals_tuned\u001b[39m\u001b[38;5;124m'\u001b[39m: residuals_tuned,\n\u001b[1;32m    134\u001b[0m })\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Feature Selection\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m selected_vars \u001b[38;5;241m=\u001b[39m selection_vars\u001b[38;5;241m.\u001b[39mfeature_selection(\n\u001b[1;32m    138\u001b[0m     X_train_pca[var_count],\n\u001b[1;32m    139\u001b[0m     X_train_np,\n\u001b[1;32m    140\u001b[0m     y_train[target_type],\n\u001b[1;32m    141\u001b[0m     best_model\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    143\u001b[0m results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m selected_vars\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_info \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Log results\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/master-project-cleaned/util/feature_selection/selection_vars.py:85\u001b[0m, in \u001b[0;36mfeature_selection\u001b[0;34m(df_X_all_vars, scaled_X, df_y, model, print_info)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my is already a numpy array\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m sfs\u001b[38;5;241m.\u001b[39mfit(scaled_X, df_y)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Get the selected feature indices\u001b[39;00m\n\u001b[1;32m     88\u001b[0m selected_indices \u001b[38;5;241m=\u001b[39m sfs\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:251\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    249\u001b[0m is_auto_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 251\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_best_new_feature_score(\n\u001b[1;32m    252\u001b[0m         cloned_estimator, X, y, cv, current_mask\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:282\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[1;32m    280\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[1;32m    281\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 282\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m cross_val_score(\n\u001b[1;32m    283\u001b[0m         estimator,\n\u001b[1;32m    284\u001b[0m         X_new,\n\u001b[1;32m    285\u001b[0m         y,\n\u001b[1;32m    286\u001b[0m         cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    287\u001b[0m         scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring,\n\u001b[1;32m    288\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    289\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    290\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    732\u001b[0m )\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    432\u001b[0m         clone(estimator),\n\u001b[1;32m    433\u001b[0m         X,\n\u001b[1;32m    434\u001b[0m         y,\n\u001b[1;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    448\u001b[0m )\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TAKES 71 MINUTES TO RUN (with 10 seeds) otherwise 24 minutes with 4 seeds\n",
    "\n",
    "# Define seeds\n",
    "seeds = [42, 1996, 45319, 43709, 19961106, 28012025, 15012025, 2019, 111194, 19052024]\n",
    "\n",
    "# or generate random seeds\n",
    "#seeds = np.random.randint(0, 100000, 10).tolist()\n",
    "print_info = 'yes'\n",
    "\n",
    "# Define data and required functions in a dictionary for modularity\n",
    "data_dict = {\n",
    "    'storm_indices': storm_indices,\n",
    "    'transposed_data_20': transposed_data_20,\n",
    "    'transposed_data_30': transposed_data_30,\n",
    "    'transposed_data_40': transposed_data_40,\n",
    "    'updated_columns_20': updated_columns_20,\n",
    "    'updated_columns_30': updated_columns_30,\n",
    "    'updated_columns_40': updated_columns_40,\n",
    "    'selection_vars': selection_vars,\n",
    "    'y_all_cdf': y_all_cdf,\n",
    "    'y_all_max': y_all_max,\n",
    "    'param_grid': {\n",
    "        'n_estimators': [5, 10, 20, 50, 100, 200, 500],\n",
    "        'max_depth': [1, 2, 3, 5, 10, 20, 40],\n",
    "        'learning_rate': np.linspace(0.05, 0.2, 8)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run sensitivity analysis\n",
    "sensitivity_results = sensitivity_analysis(\n",
    "    seeds=seeds,\n",
    "    split_function=extraction_squares.split_storm_numbers,\n",
    "    process_workflow=sensitivity_test.process_xgboost_workflow,  # Assuming this is the earlier provided function\n",
    "    data_dict=data_dict\n",
    ")\n",
    "\n",
    "# Analyze the sensitivity\n",
    "for key, selected_features in sensitivity_results.items():\n",
    "    union_features = set.union(*selected_features)\n",
    "    intersection_features = set.intersection(*selected_features)\n",
    "    print(f\"\\nTarget and Variables: {key}\")\n",
    "    print(f\"Selected Features Union: {union_features}\")\n",
    "    print(f\"Selected Features Intersection: {intersection_features}\")\n",
    "    print(f\"Variability: {len(union_features) - len(intersection_features)}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data for the DataFrame\n",
    "results_data = []\n",
    "\n",
    "for key, feature_sets in sensitivity_results.items():\n",
    "    target_type, var_count = key.split('_')  # Extract target type and variable count\n",
    "    all_features = [features for features in feature_sets]  # List of feature sets across seeds\n",
    "\n",
    "    # Compute union and intersection\n",
    "    union_features = set.union(*all_features)\n",
    "    intersection_features = set.intersection(*all_features)\n",
    "    variability = len(union_features) - len(intersection_features)\n",
    "    consistency_score = len(intersection_features) / len(union_features) if len(union_features) > 0 else 0\n",
    "\n",
    "    # Append data to results list\n",
    "    results_data.append({\n",
    "        'Target Type': target_type,\n",
    "        'Variable Count': var_count,\n",
    "        'All Features': all_features,\n",
    "        #'Union Features': union_features,\n",
    "        #'Intersection Features': intersection_features,\n",
    "        #'Variability': variability,\n",
    "        #'Consistency Score': consistency_score\n",
    "    })\n",
    "\n",
    "# Create a DataFrame\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "results_cdf = results_df[results_df['Target Type'] == 'cdf']\n",
    "results_max = results_df[results_df['Target Type'] == 'max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v4'\n",
    "\n",
    "# Extract the results for each dataset (20-30-40 vars) variables\n",
    "results_cdf_20 = pd.DataFrame(results_cdf['All Features'][0])\n",
    "results_cdf_30 = pd.DataFrame(results_cdf['All Features'][1])\n",
    "results_cdf_40 = pd.DataFrame(results_cdf['All Features'][2])\n",
    "\n",
    "# collapse into a single list\n",
    "results_cdf_20 = [item for sublist in results_cdf['All Features'][0] for item in sublist]\n",
    "results_cdf_30 = [item for sublist in results_cdf['All Features'][1] for item in sublist]\n",
    "results_cdf_40 = [item for sublist in results_cdf['All Features'][2] for item in sublist]\n",
    "\n",
    "# combine the 3 lists into one\n",
    "results_cdf_all_vars = results_cdf_20 + results_cdf_30 + results_cdf_40\n",
    "\n",
    "# count the number of times each variable appears in the list\n",
    "results_cdf_count = pd.Series(results_cdf_all_vars).value_counts()\n",
    "\n",
    "# repeat the same for the max dataset\n",
    "results_max_20 = pd.DataFrame(results_max['All Features'][3])\n",
    "results_max_30 = pd.DataFrame(results_max['All Features'][4])\n",
    "results_max_40 = pd.DataFrame(results_max['All Features'][5])\n",
    "\n",
    "# collapse into a single list\n",
    "results_max_20 = [item for sublist in results_max['All Features'][3] for item in sublist]\n",
    "results_max_30 = [item for sublist in results_max['All Features'][4] for item in sublist]\n",
    "results_max_40 = [item for sublist in results_max['All Features'][5] for item in sublist]\n",
    "\n",
    "# combine the 3 lists into one\n",
    "results_max_all_vars = results_max_20 + results_max_30 + results_max_40\n",
    "\n",
    "# count the number of times each variable appears in the list\n",
    "results_max_count = pd.Series(results_max_all_vars).value_counts()\n",
    "\n",
    "# create a new list with the 2 preivous results_target_all_vars and count each variable\n",
    "results_target_all_vars = results_cdf_all_vars + results_max_all_vars\n",
    "results_target_count = pd.Series(results_target_all_vars).value_counts()\n",
    "\n",
    "# export the 3 lists to a csv file\n",
    "results_cdf_count.to_csv(f'pre_processing/feature_selection/fs_mls_ts_tests/cdf_count_{version}.csv')\n",
    "results_max_count.to_csv(f'pre_processing/feature_selection/fs_mls_ts_tests/max_count_{version}.csv')\n",
    "results_target_count.to_csv(f'pre_processing/feature_selection/fs_mls_ts_tests/both_target_count_{version}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top 10 % of the variables\n",
    "\n",
    "percentage = 0.5\n",
    "results_cdf_count_10 = results_cdf_count[results_cdf_count > percentage*len(seeds)]\n",
    "results_max_count_10 = results_max_count[results_max_count > percentage*len(seeds)]\n",
    "results_target_count_10 = results_target_count[results_target_count > percentage*len(seeds)]\n",
    "\n",
    "# export the 3 lists to a csv file\n",
    "\n",
    "results_cdf_count_10.to_csv(f'pre_processing/feature_selection/fs_mls_ts_tests/cdf_count_50_{version}.csv')\n",
    "results_max_count_10.to_csv(f'pre_processing/feature_selection/fs_mls_ts_tests/max_count_50_{version}.csv')\n",
    "results_target_count_10.to_csv(f'pre_processing/feature_selection/fs_mls_ts_tests/both_target_count_50_{version}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selection based on RMSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def combined_workflow_with_best_model(seeds, split_function, data_dict, param_grid_og, print_info='yes'):\n",
    "    def process_workflow(X_train_pca, X_validation_pca, y_train, y_validation, variable_counts, target_types):\n",
    "        results = {}\n",
    "        best_models = {target_type: {'model': None, 'rmse': float('inf'), 'mae': float('inf')} for target_type in target_types}\n",
    "\n",
    "        for target_type in target_types:  # e.g., ['cdf', 'max']\n",
    "            for var_count in variable_counts:  # e.g., [20, 30, 40]\n",
    "                for ml in ['xgboost', 'random_forest']:\n",
    "                    # Convert PCA data to numpy\n",
    "                    X_train_np = X_train_pca[var_count].to_numpy()\n",
    "                    X_validation_np = X_validation_pca[var_count].to_numpy()\n",
    "\n",
    "                    # Initialize and train model\n",
    "                    if ml == 'xgboost':\n",
    "                        model = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "                    elif ml == 'random_forest':\n",
    "                        model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "                    model.fit(X_train_np, y_train[target_type])\n",
    "\n",
    "                    # Predictions\n",
    "                    predictions = model.predict(X_validation_np)\n",
    "\n",
    "                    # Metrics before tuning\n",
    "                    rmse = np.sqrt(mean_squared_error(y_validation[target_type], predictions))\n",
    "                    mae = mean_absolute_error(y_validation[target_type], predictions)\n",
    "\n",
    "                    # Update best model if applicable\n",
    "                    if rmse < best_models[target_type]['rmse'] or (\n",
    "                        rmse == best_models[target_type]['rmse'] and mae < best_models[target_type]['mae']):\n",
    "                        best_models[target_type] = {\n",
    "                            'model': model,\n",
    "                            'rmse': rmse,\n",
    "                            'mae': mae,\n",
    "                            'var_count': var_count,\n",
    "                            'ml': ml,\n",
    "                            'params': None  # Params will be updated after tuning\n",
    "                        }\n",
    "\n",
    "                    # Hyperparameter tuning\n",
    "                    if ml == 'random_forest':\n",
    "                        param_grid = {\n",
    "                            'n_estimators': [5, 10, 20, 50, 100, 200, 500],\n",
    "                            'max_depth': [1, 2, 3, 5, 10, 20, 40]\n",
    "                        }\n",
    "                    else:\n",
    "                        param_grid = param_grid_og\n",
    "\n",
    "                    search = HalvingGridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=0)\n",
    "                    search.fit(X_train_np, y_train[target_type])\n",
    "\n",
    "                    # Get best model after tuning\n",
    "                    best_model = search.best_estimator_\n",
    "\n",
    "                    # Predictions after tuning\n",
    "                    tuned_predictions = best_model.predict(X_validation_np)\n",
    "\n",
    "                    # Metrics after tuning\n",
    "                    rmse_tuned = np.sqrt(mean_squared_error(y_validation[target_type], tuned_predictions))\n",
    "                    mae_tuned = mean_absolute_error(y_validation[target_type], tuned_predictions)\n",
    "\n",
    "                    # Update best model if applicable\n",
    "                    if rmse_tuned < best_models[target_type]['rmse'] or (\n",
    "                        rmse_tuned == best_models[target_type]['rmse'] and mae_tuned < best_models[target_type]['mae']):\n",
    "                        best_models[target_type] = {\n",
    "                            'model': best_model,\n",
    "                            'rmse': rmse_tuned,\n",
    "                            'mae': mae_tuned,\n",
    "                            'var_count': var_count,\n",
    "                            'ml': ml,\n",
    "                            'params': search.best_params_\n",
    "                        }\n",
    "\n",
    "                    # Feature Selection\n",
    "                    selected_vars = data_dict['selection_vars'].feature_selection(\n",
    "                        X_train_pca[var_count],\n",
    "                        X_train_np,\n",
    "                        y_train[target_type],\n",
    "                        best_model\n",
    "                    )\n",
    "\n",
    "                    # Store results\n",
    "                    results[f'{target_type}_{var_count}'] = {\n",
    "                        'model': best_model,\n",
    "                        'rmse_after_tuning': rmse_tuned,\n",
    "                        'mae_after_tuning': mae_tuned,\n",
    "                        'best_params': search.best_params_,\n",
    "                        'selected_features': selected_vars,\n",
    "                    }\n",
    "\n",
    "                    if print_info == 'yes':\n",
    "                        print(f\"Target: {target_type}, Variables: {var_count}\")\n",
    "                        print(f\"ML Model: {ml}\")\n",
    "                        print(f\"RMSE After Tuning: {rmse_tuned}, MAE After Tuning: {mae_tuned}\")\n",
    "                        print(f\"Best Params: {search.best_params_}\")\n",
    "                        print(f\"Selected Features: {selected_vars}\")\n",
    "                        print('-' * 30)\n",
    "\n",
    "        return results, best_models\n",
    "\n",
    "    sensitivity_results = defaultdict(list)\n",
    "    overall_best_models = {target_type: {'model': None, 'rmse': float('inf'), 'mae': float('inf')} for target_type in ['cdf', 'max']}\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"\\nProcessing for seed: {seed}\")\n",
    "\n",
    "        # Split the data\n",
    "        storm_index_training, storm_index_test, storm_index_validation = split_function(\n",
    "            data_dict['storm_indices'], 0.12, seed, 'number'\n",
    "        )\n",
    "        storm_index_training.sort()\n",
    "        storm_index_test.sort()\n",
    "        storm_index_validation.sort()\n",
    "\n",
    "        # Prepare PCA datasets\n",
    "        X_train_pca = {count: data_dict['selection_vars'].prepare_training_data(\n",
    "            data_dict[f'transposed_data_{count}'], storm_index_training, data_dict[f'updated_columns_{count}']\n",
    "        ) for count in [20, 30, 40]}\n",
    "\n",
    "        X_validation_pca = {count: data_dict['selection_vars'].prepare_training_data(\n",
    "            data_dict[f'transposed_data_{count}'], storm_index_validation, data_dict[f'updated_columns_{count}']\n",
    "        ) for count in [20, 30, 40]}\n",
    "\n",
    "        # Prepare y data\n",
    "        y_train = {\n",
    "            'cdf': data_dict['selection_vars'].process_y_data(data_dict['y_all_cdf'], storm_index_training),\n",
    "            'max': data_dict['selection_vars'].process_y_data(data_dict['y_all_max'], storm_index_training),\n",
    "        }\n",
    "        y_validation = {\n",
    "            'cdf': data_dict['selection_vars'].process_y_data(data_dict['y_all_cdf'], storm_index_validation),\n",
    "            'max': data_dict['selection_vars'].process_y_data(data_dict['y_all_max'], storm_index_validation),\n",
    "        }\n",
    "\n",
    "        # Process the workflow for this seed\n",
    "        results, best_models = process_workflow(\n",
    "            X_train_pca=X_train_pca,\n",
    "            X_validation_pca=X_validation_pca,\n",
    "            y_train=y_train,\n",
    "            y_validation=y_validation,\n",
    "            variable_counts=[20, 30, 40],\n",
    "            target_types=['cdf', 'max']\n",
    "        )\n",
    "\n",
    "        # Update sensitivity results\n",
    "        for key, res in results.items():\n",
    "            sensitivity_results[key].append(set(res['selected_features']))\n",
    "\n",
    "        # Update overall best models\n",
    "        for target_type, model_info in best_models.items():\n",
    "            if model_info['rmse'] < overall_best_models[target_type]['rmse'] or (\n",
    "                model_info['rmse'] == overall_best_models[target_type]['rmse'] and\n",
    "                model_info['mae'] < overall_best_models[target_type]['mae']):\n",
    "                overall_best_models[target_type] = model_info\n",
    "\n",
    "    return sensitivity_results, overall_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for seed: 42\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 20\n",
      "ML Model: xgboost\n",
      "RMSE After Tuning: 1.1320325711600632, MAE After Tuning: 0.8733677808698516\n",
      "Best Params: {'learning_rate': 0.15714285714285717, 'max_depth': 1, 'n_estimators': 10}\n",
      "Selected Features: Index(['mean_surface_latent_heat_flux_std_PCA_3',\n",
      "       'surface_latent_heat_flux_std_PCA_3',\n",
      "       'mean_sea_level_pressure_max_PCA_2', 'surface_pressure_max_PCA_2',\n",
      "       'geopotential_1000_std_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 20\n",
      "ML Model: random_forest\n",
      "RMSE After Tuning: 1.0084506667883624, MAE After Tuning: 0.7687004366559859\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 500}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'geopotential_500_mean_PCA_2',\n",
      "       'surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_sea_level_pressure_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 30\n",
      "ML Model: xgboost\n",
      "RMSE After Tuning: 1.053840508239838, MAE After Tuning: 0.8330130512468313\n",
      "Best Params: {'learning_rate': 0.15714285714285717, 'max_depth': 1, 'n_estimators': 20}\n",
      "Selected Features: Index(['mean_surface_latent_heat_flux_std_PCA_3',\n",
      "       'surface_latent_heat_flux_std_PCA_3',\n",
      "       'mean_sea_level_pressure_max_PCA_2', 'surface_pressure_max_PCA_2',\n",
      "       'geopotential_1000_std_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 30\n",
      "ML Model: random_forest\n",
      "RMSE After Tuning: 0.9706445167893885, MAE After Tuning: 0.7318177829667335\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 20}\n",
      "Selected Features: Index(['2m_dewpoint_temperature_std_PCA_2',\n",
      "       'mean_surface_sensible_heat_flux_std_PCA_2', '2m_temperature_std_PCA_1',\n",
      "       'surface_pressure_min_PCA_1',\n",
      "       'mean_surface_sensible_heat_flux_min_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 40\n",
      "ML Model: xgboost\n",
      "RMSE After Tuning: 1.1998591674449874, MAE After Tuning: 0.9394516949328524\n",
      "Best Params: {'learning_rate': 0.15714285714285717, 'max_depth': 1, 'n_estimators': 5}\n",
      "Selected Features: Index(['2m_temperature_std_PCA_1', 'surface_pressure_min_PCA_4',\n",
      "       'surface_pressure_std_PCA_4', '2m_dewpoint_temperature_max_PCA_1',\n",
      "       'mean_surface_sensible_heat_flux_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 40\n",
      "ML Model: random_forest\n",
      "RMSE After Tuning: 1.001436147580132, MAE After Tuning: 0.7550547893062668\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 50}\n",
      "Selected Features: Index(['mean_sea_level_pressure_max_PCA_2', 'geopotential_1000_std_PCA_1',\n",
      "       'geopotential_1000_std_PCA_2', 'surface_pressure_std_PCA_4',\n",
      "       'large_scale_snowfall_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 20\n",
      "ML Model: xgboost\n",
      "RMSE After Tuning: 4.940131006734706, MAE After Tuning: 4.013771238260251\n",
      "Best Params: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 10}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_mean_PCA_2',\n",
      "       'mean_surface_latent_heat_flux_std_PCA_1',\n",
      "       'surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_surface_latent_heat_flux_min_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 20\n",
      "ML Model: random_forest\n",
      "RMSE After Tuning: 4.473603959279899, MAE After Tuning: 3.6376420335336195\n",
      "Best Params: {'max_depth': 3, 'n_estimators': 50}\n",
      "Selected Features: Index(['10m_u_component_of_wind_max_PCA_1', 'surface_pressure_mean_PCA_1',\n",
      "       '10m_v_component_of_wind_max_PCA_2',\n",
      "       'mean_surface_latent_heat_flux_min_PCA_3',\n",
      "       'mean_sea_level_pressure_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 30\n",
      "ML Model: xgboost\n",
      "RMSE After Tuning: 4.791997736545044, MAE After Tuning: 3.977212318975392\n",
      "Best Params: {'learning_rate': 0.15714285714285717, 'max_depth': 1, 'n_estimators': 10}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1',\n",
      "       'surface_latent_heat_flux_min_PCA_1',\n",
      "       'mean_surface_latent_heat_flux_min_PCA_1', 'surface_pressure_min_PCA_4',\n",
      "       'mean_surface_sensible_heat_flux_min_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 30\n",
      "ML Model: random_forest\n",
      "RMSE After Tuning: 4.477599619063577, MAE After Tuning: 3.675116265932918\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 500}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_mean_PCA_2',\n",
      "       'convective_precipitation_mean_PCA_1',\n",
      "       'surface_latent_heat_flux_mean_PCA_1', 'surface_pressure_min_PCA_4'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 40\n",
      "ML Model: xgboost\n",
      "RMSE After Tuning: 5.0329951967119, MAE After Tuning: 4.113636189117018\n",
      "Best Params: {'learning_rate': 0.07142857142857144, 'max_depth': 1, 'n_estimators': 20}\n",
      "Selected Features: Index(['mean_sea_level_pressure_min_PCA_1', 'surface_pressure_min_PCA_4',\n",
      "       'mean_surface_sensible_heat_flux_min_PCA_1',\n",
      "       '10m_v_component_of_wind_mean_PCA_1', 'surface_pressure_std_PCA_4'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: max, Variables: 40\n",
      "ML Model: random_forest\n",
      "RMSE After Tuning: 4.546556143244367, MAE After Tuning: 3.6987668274593264\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 100}\n",
      "Selected Features: Index(['surface_pressure_mean_PCA_1', 'surface_pressure_max_PCA_1',\n",
      "       'mean_surface_sensible_heat_flux_min_PCA_1',\n",
      "       'surface_pressure_std_PCA_4', 'large_scale_snowfall_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "\n",
      "Processing for seed: 1996\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 20\n",
      "ML Model: xgboost\n",
      "RMSE After Tuning: 1.4565424347853897, MAE After Tuning: 1.0325000072918864\n",
      "Best Params: {'learning_rate': 0.15714285714285717, 'max_depth': 1, 'n_estimators': 10}\n",
      "Selected Features: Index(['10m_u_component_of_wind_std_PCA_2', 'surface_pressure_mean_PCA_2',\n",
      "       'geopotential_500_mean_PCA_2',\n",
      "       'mean_surface_latent_heat_flux_std_PCA_3',\n",
      "       '10m_v_component_of_wind_max_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 20\n",
      "ML Model: random_forest\n",
      "RMSE After Tuning: 1.2816503403396264, MAE After Tuning: 0.8584815272470157\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 100}\n",
      "Selected Features: Index(['10m_u_component_of_wind_max_PCA_1',\n",
      "       '10m_v_component_of_wind_max_PCA_2',\n",
      "       'surface_latent_heat_flux_min_PCA_3', 'geopotential_1000_std_PCA_1',\n",
      "       'convective_precipitation_mean_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 30\n",
      "ML Model: xgboost\n",
      "RMSE After Tuning: 1.5330502648323396, MAE After Tuning: 1.0889627110513345\n",
      "Best Params: {'learning_rate': 0.13571428571428573, 'max_depth': 1, 'n_estimators': 20}\n",
      "Selected Features: Index(['10m_u_component_of_wind_std_PCA_2',\n",
      "       'mean_surface_latent_heat_flux_std_PCA_3',\n",
      "       '10m_v_component_of_wind_max_PCA_2',\n",
      "       'surface_latent_heat_flux_min_PCA_1', 'surface_pressure_min_PCA_2'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "y is already a numpy array\n",
      "Target: cdf, Variables: 30\n",
      "ML Model: random_forest\n",
      "RMSE After Tuning: 1.335678419419996, MAE After Tuning: 0.9086136261383347\n",
      "Best Params: {'max_depth': 1, 'n_estimators': 100}\n",
      "Selected Features: Index(['10m_u_component_of_wind_max_PCA_1',\n",
      "       '10m_v_component_of_wind_max_PCA_2', 'geopotential_1000_std_PCA_1',\n",
      "       'convective_precipitation_mean_PCA_1',\n",
      "       '10m_u_component_of_wind_min_PCA_1'],\n",
      "      dtype='object')\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 28\u001b[0m\n\u001b[1;32m      9\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstorm_indices\u001b[39m\u001b[38;5;124m'\u001b[39m: storm_indices,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransposed_data_20\u001b[39m\u001b[38;5;124m'\u001b[39m: transposed_data_20,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     }\n\u001b[1;32m     25\u001b[0m }\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Run sensitivity analysis and extract best models\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m sensitivity_results, overall_best_models \u001b[38;5;241m=\u001b[39m combined_workflow_with_best_model(\n\u001b[1;32m     29\u001b[0m     seeds\u001b[38;5;241m=\u001b[39mseeds,\n\u001b[1;32m     30\u001b[0m     split_function\u001b[38;5;241m=\u001b[39mextraction_squares\u001b[38;5;241m.\u001b[39msplit_storm_numbers,\n\u001b[1;32m     31\u001b[0m     data_dict\u001b[38;5;241m=\u001b[39mdata_dict,\n\u001b[1;32m     32\u001b[0m     param_grid_og\u001b[38;5;241m=\u001b[39mdata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_grid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     33\u001b[0m     print_info\u001b[38;5;241m=\u001b[39mprint_info\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Analyze sensitivity results\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, selected_features \u001b[38;5;129;01min\u001b[39;00m sensitivity_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[8], line 137\u001b[0m, in \u001b[0;36mcombined_workflow_with_best_model\u001b[0;34m(seeds, split_function, data_dict, param_grid_og, print_info)\u001b[0m\n\u001b[1;32m    131\u001b[0m y_validation \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m: data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselection_vars\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprocess_y_data(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_all_cdf\u001b[39m\u001b[38;5;124m'\u001b[39m], storm_index_validation),\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselection_vars\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprocess_y_data(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_all_max\u001b[39m\u001b[38;5;124m'\u001b[39m], storm_index_validation),\n\u001b[1;32m    134\u001b[0m }\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Process the workflow for this seed\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m results, best_models \u001b[38;5;241m=\u001b[39m process_workflow(\n\u001b[1;32m    138\u001b[0m     X_train_pca\u001b[38;5;241m=\u001b[39mX_train_pca,\n\u001b[1;32m    139\u001b[0m     X_validation_pca\u001b[38;5;241m=\u001b[39mX_validation_pca,\n\u001b[1;32m    140\u001b[0m     y_train\u001b[38;5;241m=\u001b[39my_train,\n\u001b[1;32m    141\u001b[0m     y_validation\u001b[38;5;241m=\u001b[39my_validation,\n\u001b[1;32m    142\u001b[0m     variable_counts\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m],\n\u001b[1;32m    143\u001b[0m     target_types\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Update sensitivity results\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, res \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[8], line 52\u001b[0m, in \u001b[0;36mcombined_workflow_with_best_model.<locals>.process_workflow\u001b[0;34m(X_train_pca, X_validation_pca, y_train, y_validation, variable_counts, target_types)\u001b[0m\n\u001b[1;32m     49\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m param_grid_og\n\u001b[1;32m     51\u001b[0m search \u001b[38;5;241m=\u001b[39m HalvingGridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(X_train_np, y_train[target_type])\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Get best model after tuning\u001b[39;00m\n\u001b[1;32m     55\u001b[0m best_model \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_search_successive_halving.py:251\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_parameters(\n\u001b[1;32m    246\u001b[0m     X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, split_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit\n\u001b[1;32m    247\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples_orig \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_index_]\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_search_successive_halving.py:355\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    348\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checked_cv_orig\n\u001b[1;32m    350\u001b[0m more_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m\"\u001b[39m: [itr] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_resources\u001b[39m\u001b[38;5;124m\"\u001b[39m: [n_resources] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[1;32m    353\u001b[0m }\n\u001b[0;32m--> 355\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate_candidates(\n\u001b[1;32m    356\u001b[0m     candidate_params, cv, more_results\u001b[38;5;241m=\u001b[39mmore_results\n\u001b[1;32m    357\u001b[0m )\n\u001b[1;32m    359\u001b[0m n_candidates_to_keep \u001b[38;5;241m=\u001b[39m ceil(n_candidates \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactor)\n\u001b[1;32m    360\u001b[0m candidate_params \u001b[38;5;241m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    918\u001b[0m         clone(base_estimator),\n\u001b[1;32m    919\u001b[0m         X,\n\u001b[1;32m    920\u001b[0m         y,\n\u001b[1;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m )\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define seeds\n",
    "seeds = [42, 1996, 45319, 43709, 19961106, 28012025, 15012025, 2019, 111194, 19052024]\n",
    "\n",
    "# or generate random seeds\n",
    "# seeds = np.random.randint(0, 100000, 10).tolist()\n",
    "print_info = 'yes'\n",
    "\n",
    "# Define data and required functions in a dictionary for modularity\n",
    "data_dict = {\n",
    "    'storm_indices': storm_indices,\n",
    "    'transposed_data_20': transposed_data_20,\n",
    "    'transposed_data_30': transposed_data_30,\n",
    "    'transposed_data_40': transposed_data_40,\n",
    "    'updated_columns_20': updated_columns_20,\n",
    "    'updated_columns_30': updated_columns_30,\n",
    "    'updated_columns_40': updated_columns_40,\n",
    "    'selection_vars': selection_vars,\n",
    "    'y_all_cdf': y_all_cdf,\n",
    "    'y_all_max': y_all_max,\n",
    "    'param_grid': {\n",
    "        'n_estimators': [5, 10, 20, 50, 100, 200, 500],\n",
    "        'max_depth': [1, 2, 3, 5, 10, 20, 40],\n",
    "        'learning_rate': np.linspace(0.05, 0.2, 8)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run sensitivity analysis and extract best models\n",
    "sensitivity_results, overall_best_models = combined_workflow_with_best_model(\n",
    "    seeds=seeds,\n",
    "    split_function=extraction_squares.split_storm_numbers,\n",
    "    data_dict=data_dict,\n",
    "    param_grid_og=data_dict['param_grid'],\n",
    "    print_info=print_info\n",
    ")\n",
    "\n",
    "# Analyze sensitivity results\n",
    "for key, selected_features in sensitivity_results.items():\n",
    "    union_features = set.union(*selected_features)\n",
    "    intersection_features = set.intersection(*selected_features)\n",
    "    print(f\"\\nTarget and Variables: {key}\")\n",
    "    print(f\"Selected Features Union: {union_features}\")\n",
    "    print(f\"Selected Features Intersection: {intersection_features}\")\n",
    "    print(f\"Variability: {len(union_features) - len(intersection_features)}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "# Display best models\n",
    "print(\"\\nBest Models Summary:\")\n",
    "for target_type, model_info in overall_best_models.items():\n",
    "    print(f\"\\nTarget Type: {target_type}\")\n",
    "    print(f\"Best Model: {model_info['ml']} with Variable Count: {model_info['var_count']}\")\n",
    "    print(f\"RMSE: {model_info['rmse']}, MAE: {model_info['mae']}\")\n",
    "    print(f\"Best Params: {model_info['params']}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selection based on r2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_to_pickle(data,savepath):\n",
    "\n",
    "    with open(savepath, 'wb') as handle:\n",
    "\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return None\n",
    "\n",
    "def combined_workflow_with_best_model(seeds, split_function, data_dict, param_grid_og, print_info='yes'):\n",
    "    def process_workflow(X_train_pca, X_validation_pca, X_test_pca, y_train, y_validation, y_test, variable_counts, target_types, seed):\n",
    "        results = {}\n",
    "        best_models = {target_type: {'model': None, 'r2': float('-inf')} for target_type in target_types}\n",
    "        # create folder for the seed\n",
    "        os.makedirs(f'pre_processing/new_feature_selection/seed_{seed}', exist_ok=True)\n",
    "        for target_type in target_types:  # e.g., ['cdf', 'max']\n",
    "            for var_count in variable_counts:  # e.g., [20, 30, 40]\n",
    "                                    # save the x_train and x_validation\n",
    "                pd.DataFrame(X_train_pca[var_count]).to_csv(f'ml_scripts/new_feature_selection/seed_{seed}/X_train_{var_count}.csv', index=False) \n",
    "                pd.DataFrame(X_validation_pca[var_count]).to_csv(f'ml_scripts/new_feature_selection/seed_{seed}/X_validation_{var_count}.csv', index=False)\n",
    "                pd.DataFrame(X_test_pca[var_count]).to_csv(f'ml_scripts/new_feature_selection/seed_{seed}/X_test_{var_count}.csv', index=False)\n",
    "\n",
    "                # save y_train and y_validation\n",
    "                pd.DataFrame(y_train[target_type]).to_csv(f'ml_scripts/new_feature_selection/seed_{seed}/y_train_{target_type}.csv', index=False)\n",
    "                pd.DataFrame(y_validation[target_type]).to_csv(f'ml_scripts/new_feature_selection/seed_{seed}/y_validation_{target_type}.csv', index=False)\n",
    "                pd.DataFrame(y_test[target_type]).to_csv(f'ml_scripts/new_feature_selection/seed_{seed}/y_test_{target_type}.csv', index=False)\n",
    "\n",
    "                if 1+1 == 2:\n",
    "\n",
    "                    for ml in ['xgboost', 'random_forest']:\n",
    "                        # create folder for the model\n",
    "                        os.makedirs(f'ml_scripts/new_feature_selection/seed_{seed}/model_{ml}', exist_ok=True)\n",
    "\n",
    "                        # Convert PCA data to numpy\n",
    "                        X_train_np = X_train_pca[var_count].to_numpy()\n",
    "                        X_validation_np = X_validation_pca[var_count].to_numpy()\n",
    "\n",
    "                        # Initialize and train model\n",
    "                        if ml == 'xgboost':\n",
    "                            model = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "                        elif ml == 'random_forest':\n",
    "                            model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "                        model.fit(X_train_np, y_train[target_type])\n",
    "\n",
    "                        # Predictions\n",
    "                        predictions = model.predict(X_validation_np)\n",
    "                        perdictions_train = model.predict(X_train_np)\n",
    "\n",
    "                        # Calculate R²\n",
    "                        y_mean = np.mean(y_validation[target_type])\n",
    "                        ss_res = np.sum((y_validation[target_type] - predictions) ** 2)\n",
    "                        ss_tot = np.sum((y_validation[target_type] - y_mean) ** 2)\n",
    "                        r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "                        y_mean_train = np.mean(y_train[target_type])\n",
    "                        ss_res_train = np.sum((y_train[target_type] - perdictions_train) ** 2)\n",
    "                        ss_tot_train = np.sum((y_train[target_type] - y_mean_train) ** 2)\n",
    "                        r2_train = 1 - (ss_res_train / ss_tot_train)\n",
    "\n",
    "                        ss_tot_test = np.sum((y_test[target_type] - y_mean) ** 2)\n",
    "\n",
    "                        # Update best model if R² is higher\n",
    "                        if r2 > best_models[target_type]['r2']:\n",
    "                            best_models[target_type] = {\n",
    "                                'model': model,\n",
    "                                'r2': r2,\n",
    "                                'r2_train': r2_train,\n",
    "                                'var_count': var_count,\n",
    "                                'ml': ml,\n",
    "                                'params': None  # Params will be updated after tuning\n",
    "                            }\n",
    "\n",
    "                        # Hyperparameter tuning\n",
    "                        if ml == 'random_forest':\n",
    "                            param_grid = {\n",
    "                                'n_estimators': [5, 10, 20, 50, 100, 200, 500],\n",
    "                                'max_depth': [1, 2, 3, 5, 10, 20, 40]\n",
    "                            }\n",
    "                        else:\n",
    "                            param_grid = param_grid_og\n",
    "\n",
    "                        search = HalvingGridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=0)\n",
    "                        search.fit(X_train_np, y_train[target_type])\n",
    "\n",
    "                        # Get best model after tuning\n",
    "                        best_model = search.best_estimator_\n",
    "\n",
    "                        # save the model with savepickle\n",
    "                        save_to_pickle(best_model, f'pre_processing/new_feature_selection/seed_{seed}/model_{ml}/model_{target_type}_{var_count}.pkl')\n",
    "\n",
    "                        # Predictions after tuning\n",
    "                        tuned_predictions = best_model.predict(X_validation_np)\n",
    "                        tuned_predictions_train = best_model.predict(X_train_np)\n",
    "                        tuned_predictions_test = best_model.predict(X_test_pca[var_count].to_numpy())\n",
    "\n",
    "                        # Calculate R² after tuning\n",
    "                        ss_res_tuned = np.sum((y_validation[target_type] - tuned_predictions) ** 2)\n",
    "                        r2_tuned = 1 - (ss_res_tuned / ss_tot)\n",
    "\n",
    "                        ss_res_tuned_train = np.sum((y_train[target_type] - tuned_predictions_train) ** 2)\n",
    "                        r2_tuned_train = 1 - (ss_res_tuned_train / ss_tot_train)\n",
    "\n",
    "                        ss_res_tuned_test = np.sum((y_test[target_type] - tuned_predictions_test) ** 2)\n",
    "                        r2_tuned_test = 1 - (ss_res_tuned_test / ss_tot_test)\n",
    "\n",
    "                        # Update best model if R² after tuning is higher\n",
    "                        if r2_tuned > best_models[target_type]['r2']:\n",
    "                            best_models[target_type] = {\n",
    "                                'model': best_model,\n",
    "                                'r2': r2_tuned,\n",
    "                                'r2_train': r2_tuned_train,\n",
    "                                'r2_test': r2_tuned_test,\n",
    "                                'var_count': var_count,\n",
    "                                'ml': ml,\n",
    "                                'params': search.best_params_\n",
    "                            }\n",
    "\n",
    "                        # Feature Selection\n",
    "                        selected_vars = data_dict['selection_vars'].feature_selection(\n",
    "                            X_train_pca[var_count],\n",
    "                            X_train_np,\n",
    "                            y_train[target_type],\n",
    "                            best_model\n",
    "                        )\n",
    "\n",
    "                        # Store results\n",
    "                        results[f'{target_type}_{var_count}'] = {\n",
    "                            'model': best_model,\n",
    "                            'r2_after_tuning': r2_tuned,\n",
    "                            'r2_after_tuning_train': r2_tuned_train,\n",
    "                            'r2_after_tuning_test': r2_tuned_test,\n",
    "                            'best_params': search.best_params_,\n",
    "                            'selected_features': selected_vars,\n",
    "                        }\n",
    "\n",
    "                        if print_info == 'yes':\n",
    "                            print(f\"Target: {target_type}, Variables: {var_count}\")\n",
    "                            print(f\"ML Model: {ml}\")\n",
    "                            print(f\"R² After Tuning: {r2_tuned}\")\n",
    "                            print(f\"R² Train After Tuning: {r2_tuned_train}\")\n",
    "                            print(f\"R² Test After Tuning: {r2_tuned_test}\")\n",
    "                            print(f\"Best Params: {search.best_params_}\")\n",
    "                            print(f\"Selected Features: {selected_vars}\")\n",
    "                            print('-' * 30)\n",
    "\n",
    "        return results, best_models\n",
    "\n",
    "    sensitivity_results = defaultdict(list)\n",
    "    overall_best_models = {target_type: {'model': None, 'r2': float('-inf')} for target_type in ['cdf', 'max']}\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"\\nProcessing for seed: {seed}\")\n",
    "\n",
    "        # Split the data\n",
    "        storm_index_training, storm_index_test, storm_index_validation = split_function(\n",
    "            data_dict['storm_indices'], 0.12, seed, 'number'\n",
    "        )\n",
    "        storm_index_training.sort()\n",
    "        storm_index_test.sort()\n",
    "        storm_index_validation.sort()\n",
    "\n",
    "        # Prepare PCA datasets\n",
    "        X_train_pca = {count: data_dict['selection_vars'].prepare_training_data(\n",
    "            data_dict[f'transposed_data_{count}'], storm_index_training, data_dict[f'updated_columns_{count}']\n",
    "        ) for count in [20, 30, 40]}\n",
    "\n",
    "        X_validation_pca = {count: data_dict['selection_vars'].prepare_training_data(\n",
    "            data_dict[f'transposed_data_{count}'], storm_index_validation, data_dict[f'updated_columns_{count}']\n",
    "        ) for count in [20, 30, 40]}\n",
    "\n",
    "        X_test_pca = {count: data_dict['selection_vars'].prepare_training_data(\n",
    "            data_dict[f'transposed_data_{count}'], storm_index_test, data_dict[f'updated_columns_{count}']\n",
    "        ) for count in [20, 30, 40]}\n",
    "\n",
    "        # Prepare y data\n",
    "        y_train = {\n",
    "            'cdf': data_dict['selection_vars'].process_y_data(data_dict['y_all_cdf'], storm_index_training),\n",
    "            'max': data_dict['selection_vars'].process_y_data(data_dict['y_all_max'], storm_index_training),\n",
    "        }\n",
    "        y_validation = {\n",
    "            'cdf': data_dict['selection_vars'].process_y_data(data_dict['y_all_cdf'], storm_index_validation),\n",
    "            'max': data_dict['selection_vars'].process_y_data(data_dict['y_all_max'], storm_index_validation),\n",
    "        }\n",
    "        y_test = {\n",
    "            'cdf': data_dict['selection_vars'].process_y_data(data_dict['y_all_cdf'], storm_index_test),\n",
    "            'max': data_dict['selection_vars'].process_y_data(data_dict['y_all_max'], storm_index_test),\n",
    "        }\n",
    "\n",
    "        # Process the workflow for this seed\n",
    "        results, best_models = process_workflow(\n",
    "            X_train_pca=X_train_pca,\n",
    "            X_validation_pca=X_validation_pca,\n",
    "            X_test_pca=X_test_pca,\n",
    "            y_train=y_train,\n",
    "            y_validation=y_validation,\n",
    "            y_test=y_test,\n",
    "            variable_counts=[20, 30, 40],\n",
    "            target_types=['cdf', 'max'],\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "        # Update sensitivity results\n",
    "        for key, res in results.items():\n",
    "            sensitivity_results[key].append(set(res['selected_features']))\n",
    "\n",
    "        # Update overall best models\n",
    "        for target_type, model_info in best_models.items():\n",
    "            if model_info['r2'] > overall_best_models[target_type]['r2']:\n",
    "                overall_best_models[target_type] = model_info\n",
    "\n",
    "    return sensitivity_results, overall_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for seed: 42\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Processing for seed: 1996\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Processing for seed: 45319\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Processing for seed: 43709\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Processing for seed: 19961106\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Processing for seed: 28012025\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Processing for seed: 15012025\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Processing for seed: 2019\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Processing for seed: 111194\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Processing for seed: 19052024\n",
      "To keep 50 storms in the training set, storms 45 and 87 are removed from the test set.\n",
      "\n",
      "Best Models Summary:\n",
      "\n",
      "Target Type: cdf\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_type, model_info \u001b[38;5;129;01min\u001b[39;00m overall_best_models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTarget Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with Variable Count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR² Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR² Train Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_train\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ml'"
     ]
    }
   ],
   "source": [
    "# Define seeds\n",
    "seeds = [42, 1996, 45319, 43709, 19961106, 28012025, 15012025, 2019, 111194, 19052024]\n",
    "\n",
    "# or generate random seeds\n",
    "# seeds = np.random.randint(0, 100000, 10).tolist()\n",
    "print_info = 'yes'\n",
    "\n",
    "# Define data and required functions in a dictionary for modularity\n",
    "data_dict = {\n",
    "    'storm_indices': storm_indices,\n",
    "    'transposed_data_20': transposed_data_20,\n",
    "    'transposed_data_30': transposed_data_30,\n",
    "    'transposed_data_40': transposed_data_40,\n",
    "    'updated_columns_20': updated_columns_20,\n",
    "    'updated_columns_30': updated_columns_30,\n",
    "    'updated_columns_40': updated_columns_40,\n",
    "    'selection_vars': selection_vars,\n",
    "    'y_all_cdf': y_all_cdf,\n",
    "    'y_all_max': y_all_max,\n",
    "    'param_grid': {\n",
    "        'n_estimators': [5, 10, 20, 50, 100, 200, 500],\n",
    "        'max_depth': [1, 2, 3, 5, 10, 20, 40],\n",
    "        'learning_rate': np.linspace(0.05, 0.2, 8)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run sensitivity analysis and extract best models\n",
    "sensitivity_results, overall_best_models = combined_workflow_with_best_model(\n",
    "    seeds=seeds,\n",
    "    split_function=extraction_squares.split_storm_numbers,\n",
    "    data_dict=data_dict,\n",
    "    param_grid_og=data_dict['param_grid'],\n",
    "    print_info=print_info\n",
    ")\n",
    "\n",
    "# Analyze sensitivity results\n",
    "for key, selected_features in sensitivity_results.items():\n",
    "    union_features = set.union(*selected_features)\n",
    "    intersection_features = set.intersection(*selected_features)\n",
    "    print(f\"\\nTarget and Variables: {key}\")\n",
    "    print(f\"Selected Features Union: {union_features}\")\n",
    "    print(f\"Selected Features Intersection: {intersection_features}\")\n",
    "    print(f\"Variability: {len(union_features) - len(intersection_features)}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "# Display best models\n",
    "print(\"\\nBest Models Summary:\")\n",
    "for target_type, model_info in overall_best_models.items():\n",
    "    print(f\"\\nTarget Type: {target_type}\")\n",
    "    print(f\"Best Model: {model_info['ml']} with Variable Count: {model_info['var_count']}\")\n",
    "    print(f\"R² Score: {model_info['r2']}\")\n",
    "    print(f\"R² Train Score: {model_info['r2_train']}\")\n",
    "    print(f\"R² Test Score: {model_info['r2_test']}\")\n",
    "    print(f\"Best Params: {model_info['params']}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data for the DataFrame\n",
    "results_data = []\n",
    "\n",
    "for key, feature_sets in sensitivity_results.items():\n",
    "    target_type, var_count = key.split('_')  # Extract target type and variable count\n",
    "    all_features = [features for features in feature_sets]  # List of feature sets across seeds\n",
    "\n",
    "    # Compute union and intersection\n",
    "    union_features = set.union(*all_features)\n",
    "    intersection_features = set.intersection(*all_features)\n",
    "    variability = len(union_features) - len(intersection_features)\n",
    "    consistency_score = len(intersection_features) / len(union_features) if len(union_features) > 0 else 0\n",
    "\n",
    "    # Append data to results list\n",
    "    results_data.append({\n",
    "        'Target Type': target_type,\n",
    "        'Variable Count': var_count,\n",
    "        'All Features': all_features,\n",
    "        #'Union Features': union_features,\n",
    "        #'Intersection Features': intersection_features,\n",
    "        #'Variability': variability,\n",
    "        #'Consistency Score': consistency_score\n",
    "    })\n",
    "\n",
    "# Create a DataFrame\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "results_cdf = results_df[results_df['Target Type'] == 'cdf']\n",
    "results_max = results_df[results_df['Target Type'] == 'max']\n",
    "\n",
    "version = 'v5'\n",
    "\n",
    "# Extract the results for each dataset (20-30-40 vars) variables\n",
    "results_cdf_20 = pd.DataFrame(results_cdf['All Features'][0])\n",
    "results_cdf_30 = pd.DataFrame(results_cdf['All Features'][1])\n",
    "results_cdf_40 = pd.DataFrame(results_cdf['All Features'][2])\n",
    "\n",
    "# collapse into a single list\n",
    "results_cdf_20 = [item for sublist in results_cdf['All Features'][0] for item in sublist]\n",
    "results_cdf_30 = [item for sublist in results_cdf['All Features'][1] for item in sublist]\n",
    "results_cdf_40 = [item for sublist in results_cdf['All Features'][2] for item in sublist]\n",
    "\n",
    "# combine the 3 lists into one\n",
    "results_cdf_all_vars = results_cdf_20 + results_cdf_30 + results_cdf_40\n",
    "\n",
    "# count the number of times each variable appears in the list\n",
    "results_cdf_count = pd.Series(results_cdf_all_vars).value_counts()\n",
    "\n",
    "# repeat the same for the max dataset\n",
    "results_max_20 = pd.DataFrame(results_max['All Features'][3])\n",
    "results_max_30 = pd.DataFrame(results_max['All Features'][4])\n",
    "results_max_40 = pd.DataFrame(results_max['All Features'][5])\n",
    "\n",
    "# collapse into a single list\n",
    "results_max_20 = [item for sublist in results_max['All Features'][3] for item in sublist]\n",
    "results_max_30 = [item for sublist in results_max['All Features'][4] for item in sublist]\n",
    "results_max_40 = [item for sublist in results_max['All Features'][5] for item in sublist]\n",
    "\n",
    "# combine the 3 lists into one\n",
    "results_max_all_vars = results_max_20 + results_max_30 + results_max_40\n",
    "\n",
    "# count the number of times each variable appears in the list\n",
    "results_max_count = pd.Series(results_max_all_vars).value_counts()\n",
    "\n",
    "# create a new list with the 2 preivous results_target_all_vars and count each variable\n",
    "results_target_all_vars = results_cdf_all_vars + results_max_all_vars\n",
    "results_target_count = pd.Series(results_target_all_vars).value_counts()\n",
    "\n",
    "# export the 3 lists to a csv file\n",
    "results_cdf_count.to_csv(f'pre_processing/feature_selection/fs_mls_ts_tests/cdf_count_{version}.csv')\n",
    "results_max_count.to_csv(f'pre_processing/feature_selection/fs_mls_ts_tests/max_count_{version}.csv')\n",
    "results_target_count.to_csv(f'pre_processing/feature_selection/fs_mls_ts_tests/both_target_count_{version}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
