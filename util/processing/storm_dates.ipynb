{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_eu = pd.read_csv('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/pre_processing/maps/QGIS/square_europe_updated.csv')\n",
    "storm_dates = pd.read_csv('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/pre_processing/tracks/storms_dates_work.csv',\n",
    "                          delimiter = ';')\n",
    "name_storm = pd.read_csv('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/pre_processing/tracks/C3S_StormTracks_era5_19792021_0100_v3.csv',\n",
    "                         delimiter=';')\n",
    "\n",
    "landfall_eu = sq_eu.drop_duplicates(subset=['layer'], keep='first')\n",
    "landfall_eu = landfall_eu.drop(columns=['lon_east', 'lon_west', 'lat_north', 'lat_south', 'path','center_lon','center_lat'])\n",
    "\n",
    "name_storm_index = name_storm[name_storm['Time&Longitude&Latitude'].str.startswith('TRACK_ID')]\n",
    "name_storm = name_storm[name_storm['Time&Longitude&Latitude'].str.startswith('TRACK_ID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m all_storms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(name_storm)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m storm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,all_storms):\n\u001b[0;32m----> 9\u001b[0m     match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_ID (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+).*?ENSMBLE_MEMB 0 (.+)\u001b[39m\u001b[38;5;124m'\u001b[39m, line[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime&Longitude&Latitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[storm])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[1;32m     12\u001b[0m     track_id_value \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.11/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.11/site-packages/pandas/core/indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.11/site-packages/pandas/core/indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mxs(label, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.11/site-packages/pandas/core/generic.py:4298\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4296\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   4297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4298\u001b[0m     loc \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4301\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensor_flow/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input string\n",
    "line = name_storm[name_storm['Time&Longitude&Latitude'].str.startswith('TRACK_ID')]\n",
    "\n",
    "# Use regex to find the number after TRACK_ID and the text after 0\n",
    "all_storms = len(name_storm)\n",
    "for storm in range(0,all_storms):\n",
    "    match = re.search(r'TRACK_ID (\\d+).*?ENSMBLE_MEMB 0 (.+)', line['Time&Longitude&Latitude'].loc[storm])\n",
    "\n",
    "if match:\n",
    "    track_id_value = match.group(1)\n",
    "    after_zero = match.group(2)\n",
    "\n",
    "    print(\"TRACK_ID value:\", track_id_value)\n",
    "    print(\"Text after 0:\", after_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the column 'layer' rename each fid_reproj_tc_irad_i_interp by storm_i\n",
    "\n",
    "landfall_eu = landfall_eu.rename(columns={'layer': 'storm_index'})\n",
    "landfall_eu['storm_index'] = landfall_eu['storm_index'].str.replace('fid_reproj_tc_irad_', '')\n",
    "landfall_eu['storm_index'] = landfall_eu['storm_index'].str.replace('_interp', '')\n",
    "\n",
    "# clean the storm_dates dataframe\n",
    "\n",
    "storm_eu_dates = storm_dates.drop(columns=['end_date', '3_hour_steps', '1_hour_steps'])\n",
    "landfall_eu['storm_index'] = pd.to_numeric(landfall_eu['storm_index'], errors='coerce')\n",
    "\n",
    "# keep only the name of the storms\n",
    "\n",
    "name_storm = name_storm['Time&Longitude&Latitude'].str.split(' 0 ', n=1).str[1].str.strip()\n",
    "name_storm = name_storm.apply(lambda x: x.replace('NAME', '', 1).strip() if x.startswith('NAME') else x)\n",
    "name_storm.reset_index(drop=True, inplace=True)\n",
    "name_storm = pd.DataFrame(name_storm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test = storm_eu_dates['start_date'][0+1]\\nhours_to_add = landfall_eu.loc[landfall_eu['storm_index'] == 1]\\nhours_to_add = int(hours_to_add['fid'].values[0])\\ndate_time_obj = datetime.strptime(test, '%Y-%m-%dT%H:%M:%S')\\ndate_time_obj = date_time_obj + timedelta(hours=hours_to_add)\\n\\n# convert back to string\\n\\ndate_time_obj.strftime('%Y-%m-%dT%H:%M:%S')\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test = storm_eu_dates['start_date'][0+1]\n",
    "hours_to_add = landfall_eu.loc[landfall_eu['storm_index'] == 1]\n",
    "hours_to_add = int(hours_to_add['fid'].values[0])\n",
    "date_time_obj = datetime.strptime(test, '%Y-%m-%dT%H:%M:%S')\n",
    "date_time_obj = date_time_obj + timedelta(hours=hours_to_add)\n",
    "\n",
    "# convert back to string\n",
    "\n",
    "date_time_obj.strftime('%Y-%m-%dT%H:%M:%S')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storm 90 not found\n"
     ]
    }
   ],
   "source": [
    "storm_eu_arrivals = []\n",
    "steps_added = []\n",
    "\n",
    "for i in range(len(storm_eu_dates)):\n",
    "    try:\n",
    "        start = storm_eu_dates['start_date'][i]\n",
    "        hours_to_add = landfall_eu.loc[landfall_eu['storm_index'] == i+1]\n",
    "        hours_to_add = int(hours_to_add['fid'].values[0])\n",
    "        start_reformat = datetime.strptime(start, '%Y-%m-%dT%H:%M:%S')\n",
    "        start_reformat = start_reformat + timedelta(hours=hours_to_add)\n",
    "        storm_eu_arrivals.append(start_reformat.strftime('%Y-%m-%dT%H:%M:%S'))\n",
    "        steps_added.append(hours_to_add)\n",
    "    except:\n",
    "        print(f'storm {i} not found')\n",
    "        storm_eu_arrivals.append(-1)\n",
    "        steps_added.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the column 'arrival_date' to storm_dates\n",
    "\n",
    "storm_dates['eu_landfall_date'] = storm_eu_arrivals\n",
    "storm_dates['nb_steps_before_eu_landfall_1_hour'] = steps_added\n",
    "storm_dates['storm_name'] = name_storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    storm_index_match    storm_eu_arrivals  steps_added  \\\n",
      "0                   1  1990-01-23T17:00:00           62   \n",
      "1                   2  1990-01-25T05:00:00           50   \n",
      "2                   3  1990-02-01T13:00:00           91   \n",
      "3                   4  1990-02-02T16:00:00           40   \n",
      "4                   5  1990-02-20T18:00:00           54   \n",
      "..                ...                  ...          ...   \n",
      "91                 92  2020-02-09T07:00:00           10   \n",
      "92                 93  2020-02-15T15:00:00           54   \n",
      "93                 94  2020-10-01T21:00:00           21   \n",
      "94                 95  2020-10-31T04:00:00           46   \n",
      "95                 96  2021-03-23T19:00:00           49   \n",
      "\n",
      "                     storm_name  \n",
      "0         C3S_STORM_TRACKS_ERA5  \n",
      "1                         DARIA  \n",
      "2         C3S_STORM_TRACKS_ERA5  \n",
      "3         C3S_STORM_TRACKS_ERA5  \n",
      "4                        VIVIAN  \n",
      "..                          ...  \n",
      "91                       CIARA2  \n",
      "92                       DENNIS  \n",
      "93                         ALEX  \n",
      "94  AIDEN C3S_STORM_TRACKS_ERA5  \n",
      "95        C3S_STORM_TRACKS_ERA5  \n",
      "\n",
      "[96 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "matched_data = []\n",
    "df_storm_eu_arrivals= []\n",
    "df_steps_added = []\n",
    "\n",
    "df_storm_eu_arrivals = pd.DataFrame(storm_eu_arrivals)\n",
    "df_steps_added = pd.DataFrame(steps_added)\n",
    "\n",
    "# Loop through storm_dates and find matches\n",
    "for idx in range(0,96+1):\n",
    "    if idx in name_storm.index:\n",
    "        matched_storm_name = name_storm['Time&Longitude&Latitude'].loc[idx]\n",
    "        matched_storm_eu_arrivals = df_storm_eu_arrivals.loc[idx][0]\n",
    "        matched_steps_added = df_steps_added.loc[idx][0]\n",
    "        matched_data.append([idx+1, matched_storm_eu_arrivals,matched_steps_added, matched_storm_name])\n",
    "\n",
    "# Convert matched data to a new DataFrame\n",
    "matched_df = pd.DataFrame(matched_data, columns=['storm_index_match','storm_eu_arrivals', 'steps_added','storm_name'])\n",
    "print(matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([storm_dates, matched_df], axis=1)\n",
    "final_df = final_df.drop(columns=['Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new storm_dates\n",
    "\n",
    "final_df.to_csv('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/pre_processing/tracks/storms_dates_steps_index_landfall_corrected.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
