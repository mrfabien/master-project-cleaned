{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_eu = pd.read_csv('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/pre_processing/maps/QGIS/square_europe_updated.csv')\n",
    "storm_dates = pd.read_csv('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/pre_processing/tracks/storms_dates_with_steps_and_index.csv')\n",
    "name_storm = pd.read_csv('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/pre_processing/tracks/C3S_StormTracks_era5_19792021_0100_v3.csv',\n",
    "                         delimiter=';')\n",
    "\n",
    "landfall_eu = sq_eu.drop_duplicates(subset=['layer'], keep='first')\n",
    "landfall_eu = landfall_eu.drop(columns=['lon_east', 'lon_west', 'lat_north', 'lat_south', 'path','center_lon','center_lat'])\n",
    "\n",
    "name_storm = name_storm[name_storm['Time&Longitude&Latitude'].str.startswith('TRACK_ID')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the column 'layer' rename each fid_reproj_tc_irad_i_interp by storm_i\n",
    "\n",
    "landfall_eu = landfall_eu.rename(columns={'layer': 'storm_index'})\n",
    "landfall_eu['storm_index'] = landfall_eu['storm_index'].str.replace('fid_reproj_tc_irad_', '')\n",
    "landfall_eu['storm_index'] = landfall_eu['storm_index'].str.replace('_interp', '')\n",
    "\n",
    "# clean the storm_dates dataframe\n",
    "\n",
    "storm_eu_dates = storm_dates.drop(columns=['end_date', '3_hour_steps', '1_hour_steps', 'Unnamed: 0'])\n",
    "landfall_eu['storm_index'] = pd.to_numeric(landfall_eu['storm_index'], errors='coerce')\n",
    "\n",
    "# keep only the name of the storms\n",
    "\n",
    "name_storm = name_storm['Time&Longitude&Latitude'].str.split(' 0 ', n=1).str[1].str.strip()\n",
    "name_storm = name_storm.apply(lambda x: x.replace('NAME', '', 1).strip() if x.startswith('NAME') else x)\n",
    "name_storm.reset_index(drop=True, inplace=True)\n",
    "name_storm = pd.DataFrame(name_storm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test = storm_eu_dates['start_date'][0+1]\\nhours_to_add = landfall_eu.loc[landfall_eu['storm_index'] == 1]\\nhours_to_add = int(hours_to_add['fid'].values[0])\\ndate_time_obj = datetime.strptime(test, '%Y-%m-%dT%H:%M:%S')\\ndate_time_obj = date_time_obj + timedelta(hours=hours_to_add)\\n\\n# convert back to string\\n\\ndate_time_obj.strftime('%Y-%m-%dT%H:%M:%S')\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test = storm_eu_dates['start_date'][0+1]\n",
    "hours_to_add = landfall_eu.loc[landfall_eu['storm_index'] == 1]\n",
    "hours_to_add = int(hours_to_add['fid'].values[0])\n",
    "date_time_obj = datetime.strptime(test, '%Y-%m-%dT%H:%M:%S')\n",
    "date_time_obj = date_time_obj + timedelta(hours=hours_to_add)\n",
    "\n",
    "# convert back to string\n",
    "\n",
    "date_time_obj.strftime('%Y-%m-%dT%H:%M:%S')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storm 90 not found\n"
     ]
    }
   ],
   "source": [
    "storm_eu_arrivals = []\n",
    "steps_added = []\n",
    "\n",
    "for i in range(len(storm_eu_dates)):\n",
    "    try:\n",
    "        start = storm_eu_dates['start_date'][i]\n",
    "        hours_to_add = landfall_eu.loc[landfall_eu['storm_index'] == i+1]\n",
    "        hours_to_add = int(hours_to_add['fid'].values[0])\n",
    "        start_reformat = datetime.strptime(start, '%Y-%m-%dT%H:%M:%S')\n",
    "        start_reformat = start_reformat + timedelta(hours=hours_to_add)\n",
    "        storm_eu_arrivals.append(start_reformat.strftime('%Y-%m-%dT%H:%M:%S'))\n",
    "        steps_added.append(hours_to_add)\n",
    "    except:\n",
    "        print(f'storm {i} not found')\n",
    "        storm_eu_arrivals.append(-1)\n",
    "        steps_added.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the column 'arrival_date' to storm_dates\n",
    "\n",
    "storm_dates['eu_landfall_date'] = storm_eu_arrivals\n",
    "storm_dates['nb_steps_before_eu_landfall_1_hour'] = steps_added\n",
    "storm_dates['storm_name'] = name_storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new storm_dates\n",
    "\n",
    "storm_dates.to_csv('/Users/fabienaugsburger/Documents/GitHub/master-project-cleaned/pre_processing/tracks/storms_dates_with_steps_and_index.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
